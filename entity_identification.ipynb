{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = pd.read_csv('./sentences.csv')\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sentence_number       word     tag\n",
       "0                0          O   OTHER\n",
       "1                0        que   OTHER\n",
       "2                0  aconteceu   OTHER\n",
       "3                0        nos   OTHER\n",
       "4                0    últimos  C-TIME"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>que</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>aconteceu</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>nos</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>últimos</td>\n",
       "      <td>C-TIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "vocab = set(data['word'])\n",
    "vocab_list = list(vocab)\n",
    "\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "\n",
    "for idx, word in enumerate(vocab_list):\n",
    "    word2idx[word] = idx\n",
    "    idx2word[idx] = word\n",
    "\n",
    "tags = set(data['tag'])\n",
    "tags_list = list(tags)\n",
    "\n",
    "tag2idx = {}\n",
    "idx2tag = {}\n",
    "\n",
    "for idx, tag in enumerate(tags_list):\n",
    "    tag2idx[tag] = idx\n",
    "    idx2tag[idx] = tag"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "converted_data = data.copy()\n",
    "\n",
    "converted_data['word'] = converted_data['word'].transform(lambda word: word2idx[word])\n",
    "converted_data['tag'] = converted_data['tag'].transform(lambda tag: tag2idx[tag])\n",
    "converted_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sentence_number  word  tag\n",
       "0                0    23   12\n",
       "1                0    26   12\n",
       "2                0    12   12\n",
       "3                0     0   12\n",
       "4                0     9    2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "list_data = converted_data.groupby(['sentence_number'])['word', 'tag'].agg(lambda i: list(i))\n",
    "list_data.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-1584793e4124>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  list_data = converted_data.groupby(['sentence_number'])['word', 'tag'].agg(lambda i: list(i))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                       word  \\\n",
       "sentence_number                                               \n",
       "0                [23, 26, 12, 0, 9, 13, 26, 29, 34, 30, 18]   \n",
       "1                     [4, 16, 29, 25, 36, 1, 33, 2, 27, 24]   \n",
       "2                                        [7, 20, 14, 10, 5]   \n",
       "3                                    [6, 37, 19, 8, 21, 28]   \n",
       "4                                   [7, 29, 15, 22, 17, 31]   \n",
       "\n",
       "                                                      tag  \n",
       "sentence_number                                            \n",
       "0                [12, 12, 12, 12, 2, 2, 12, 12, 7, 12, 3]  \n",
       "1                   [12, 12, 12, 12, 12, 8, 12, 7, 0, 11]  \n",
       "2                                     [12, 10, 12, 12, 4]  \n",
       "3                                  [12, 6, 12, 10, 12, 1]  \n",
       "4                                   [12, 12, 5, 7, 12, 7]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[23, 26, 12, 0, 9, 13, 26, 29, 34, 30, 18]</td>\n",
       "      <td>[12, 12, 12, 12, 2, 2, 12, 12, 7, 12, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 16, 29, 25, 36, 1, 33, 2, 27, 24]</td>\n",
       "      <td>[12, 12, 12, 12, 12, 8, 12, 7, 0, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7, 20, 14, 10, 5]</td>\n",
       "      <td>[12, 10, 12, 12, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[6, 37, 19, 8, 21, 28]</td>\n",
       "      <td>[12, 6, 12, 10, 12, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7, 29, 15, 22, 17, 31]</td>\n",
       "      <td>[12, 12, 5, 7, 12, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "max_len = list_data['word'].map(len).max()\n",
    "max_len"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "pad_tokens = tf.keras.preprocessing.sequence.pad_sequences(list_data['word'])\n",
    "pad_tags = tf.keras.preprocessing.sequence.pad_sequences(list_data['tag'])\n",
    "pad_tags = [tf.keras.utils.to_categorical(tag, num_classes=len(tags)) for tag in pad_tags]\n",
    "\n",
    "train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "input_dim = len(vocab)\n",
    "input_length = max_len\n",
    "\n",
    "def objective(trial):\n",
    "    embedding_output_dim = trial.suggest_int(\"embedding_output_dim\", 16, 256)\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=input_dim, output_dim=embedding_output_dim, input_length=input_length),\n",
    "        Bidirectional(LSTM(units=embedding_output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode='concat'),\n",
    "        LSTM(units=embedding_output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5),\n",
    "        TimeDistributed(Dense(len(tags), activation='relu'))\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 5, 150)\n",
    "\n",
    "    model.fit(train_tokens, np.array(train_tags), verbose=1, epochs=num_epochs)\n",
    "\n",
    "    return model.evaluate(test_tokens, np.array(test_tags), return_dict=True)['accuracy']\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:25:48,981]\u001b[0m A new study created in memory with name: no-name-5c6439f6-8ff3-4b11-883b-5e555c6bff16\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/91\n",
      "1/1 [==============================] - 10s 10s/step - loss: 6.0082 - accuracy: 0.0682\n",
      "Epoch 2/91\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 3.2190 - accuracy: 0.4318\n",
      "Epoch 3/91\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 3.1495 - accuracy: 0.4545\n",
      "Epoch 4/91\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 3.0294 - accuracy: 0.4545\n",
      "Epoch 5/91\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 3.0090 - accuracy: 0.4773\n",
      "Epoch 6/91\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.9952 - accuracy: 0.4545\n",
      "Epoch 7/91\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 2.9730 - accuracy: 0.5227\n",
      "Epoch 8/91\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 2.9495 - accuracy: 0.5000\n",
      "Epoch 9/91\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 2.9101 - accuracy: 0.4773\n",
      "Epoch 10/91\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 2.8987 - accuracy: 0.5000\n",
      "Epoch 11/91\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 2.8784 - accuracy: 0.5455\n",
      "Epoch 12/91\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 2.8610 - accuracy: 0.5227\n",
      "Epoch 13/91\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 2.8549 - accuracy: 0.5909\n",
      "Epoch 14/91\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 2.8177 - accuracy: 0.5909\n",
      "Epoch 15/91\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 2.8238 - accuracy: 0.5909\n",
      "Epoch 16/91\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 2.8021 - accuracy: 0.6136\n",
      "Epoch 17/91\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 2.7949 - accuracy: 0.6136\n",
      "Epoch 18/91\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.7629 - accuracy: 0.6591\n",
      "Epoch 19/91\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 2.7540 - accuracy: 0.6364\n",
      "Epoch 20/91\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 2.7388 - accuracy: 0.6364\n",
      "Epoch 21/91\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 2.7001 - accuracy: 0.6136\n",
      "Epoch 22/91\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 2.6774 - accuracy: 0.6364\n",
      "Epoch 23/91\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 2.6689 - accuracy: 0.6591\n",
      "Epoch 24/91\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.6235 - accuracy: 0.6364\n",
      "Epoch 25/91\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 2.6202 - accuracy: 0.6364\n",
      "Epoch 26/91\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 2.5772 - accuracy: 0.6591\n",
      "Epoch 27/91\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 2.5759 - accuracy: 0.6591\n",
      "Epoch 28/91\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 2.5579 - accuracy: 0.5909\n",
      "Epoch 29/91\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 2.5296 - accuracy: 0.7045\n",
      "Epoch 30/91\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 2.8505 - accuracy: 0.7273\n",
      "Epoch 31/91\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 2.8293 - accuracy: 0.6818\n",
      "Epoch 32/91\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 2.7900 - accuracy: 0.7045\n",
      "Epoch 33/91\n",
      "1/1 [==============================] - 0s 360ms/step - loss: nan - accuracy: 0.6364\n",
      "Epoch 34/91\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 35/91\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 36/91\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 37/91\n",
      "1/1 [==============================] - 0s 318ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 38/91\n",
      "1/1 [==============================] - 0s 325ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/91\n",
      "1/1 [==============================] - 0s 321ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/91\n",
      "1/1 [==============================] - 0s 277ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/91\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/91\n",
      "1/1 [==============================] - 0s 360ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/91\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/91\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/91\n",
      "1/1 [==============================] - 0s 354ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/91\n",
      "1/1 [==============================] - 0s 402ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/91\n",
      "1/1 [==============================] - 0s 350ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/91\n",
      "1/1 [==============================] - 0s 347ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/91\n",
      "1/1 [==============================] - 0s 361ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/91\n",
      "1/1 [==============================] - 0s 416ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/91\n",
      "1/1 [==============================] - 0s 348ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/91\n",
      "1/1 [==============================] - 0s 379ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/91\n",
      "1/1 [==============================] - 0s 319ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/91\n",
      "1/1 [==============================] - 0s 368ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/91\n",
      "1/1 [==============================] - 0s 289ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/91\n",
      "1/1 [==============================] - 0s 313ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/91\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/91\n",
      "1/1 [==============================] - 0s 299ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/91\n",
      "1/1 [==============================] - 0s 303ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/91\n",
      "1/1 [==============================] - 0s 297ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/91\n",
      "1/1 [==============================] - 0s 325ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/91\n",
      "1/1 [==============================] - 0s 344ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/91\n",
      "1/1 [==============================] - 0s 244ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/91\n",
      "1/1 [==============================] - 0s 247ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/91\n",
      "1/1 [==============================] - 0s 278ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/91\n",
      "1/1 [==============================] - 0s 297ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/91\n",
      "1/1 [==============================] - 0s 342ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/91\n",
      "1/1 [==============================] - 0s 322ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/91\n",
      "1/1 [==============================] - 0s 283ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/91\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/91\n",
      "1/1 [==============================] - 0s 305ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/91\n",
      "1/1 [==============================] - 0s 303ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/91\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/91\n",
      "1/1 [==============================] - 0s 312ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/91\n",
      "1/1 [==============================] - 0s 306ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/91\n",
      "1/1 [==============================] - 0s 348ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/91\n",
      "1/1 [==============================] - 0s 419ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/91\n",
      "1/1 [==============================] - 0s 334ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/91\n",
      "1/1 [==============================] - 0s 286ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/91\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/91\n",
      "1/1 [==============================] - 0s 305ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/91\n",
      "1/1 [==============================] - 0s 361ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/91\n",
      "1/1 [==============================] - 0s 408ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/91\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/91\n",
      "1/1 [==============================] - 0s 316ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/91\n",
      "1/1 [==============================] - 0s 307ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/91\n",
      "1/1 [==============================] - 0s 398ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/91\n",
      "1/1 [==============================] - 0s 390ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/91\n",
      "1/1 [==============================] - 0s 493ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 90/91\n",
      "1/1 [==============================] - 0s 369ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 91/91\n",
      "1/1 [==============================] - 0s 363ms/step - loss: nan - accuracy: 0.2727\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:26:32,286]\u001b[0m Trial 0 finished with value: 0.5 and parameters: {'embedding_output_dim': 218, 'num_epochs': 91}. Best is trial 0 with value: 0.5.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/11\n",
      "1/1 [==============================] - 11s 11s/step - loss: 9.7169 - accuracy: 0.0909\n",
      "Epoch 2/11\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 6.2516 - accuracy: 0.4318\n",
      "Epoch 3/11\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 5.8819 - accuracy: 0.4318\n",
      "Epoch 4/11\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 6.1306 - accuracy: 0.4318\n",
      "Epoch 5/11\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 5.3418 - accuracy: 0.4318\n",
      "Epoch 6/11\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 2.3152 - accuracy: 0.4318\n",
      "Epoch 7/11\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 2.2182 - accuracy: 0.4318\n",
      "Epoch 8/11\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 2.1955 - accuracy: 0.4318\n",
      "Epoch 9/11\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.1947 - accuracy: 0.4318\n",
      "Epoch 10/11\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 2.2400 - accuracy: 0.3636\n",
      "Epoch 11/11\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.2012 - accuracy: 0.5227\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.6546 - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:26:47,661]\u001b[0m Trial 1 finished with value: 0.5 and parameters: {'embedding_output_dim': 179, 'num_epochs': 11}. Best is trial 0 with value: 0.5.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/74\n",
      "1/1 [==============================] - 10s 10s/step - loss: 10.3619 - accuracy: 0.0455\n",
      "Epoch 2/74\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.6055 - accuracy: 0.5455\n",
      "Epoch 3/74\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.1870 - accuracy: 0.6136\n",
      "Epoch 4/74\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 2.0535 - accuracy: 0.6818\n",
      "Epoch 5/74\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 2.0798 - accuracy: 0.5909\n",
      "Epoch 6/74\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 1.7540 - accuracy: 0.5909\n",
      "Epoch 7/74\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.7501 - accuracy: 0.6136\n",
      "Epoch 8/74\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.6877 - accuracy: 0.6364\n",
      "Epoch 9/74\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.6944 - accuracy: 0.6136\n",
      "Epoch 10/74\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.6536 - accuracy: 0.6364\n",
      "Epoch 11/74\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.6739 - accuracy: 0.6364\n",
      "Epoch 12/74\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.5973 - accuracy: 0.6136\n",
      "Epoch 13/74\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.5914 - accuracy: 0.6136\n",
      "Epoch 14/74\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.6044 - accuracy: 0.6136\n",
      "Epoch 15/74\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.5384 - accuracy: 0.6364\n",
      "Epoch 16/74\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 1.5060 - accuracy: 0.5909\n",
      "Epoch 17/74\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.4696 - accuracy: 0.5682\n",
      "Epoch 18/74\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.4514 - accuracy: 0.5682\n",
      "Epoch 19/74\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.4496 - accuracy: 0.6364\n",
      "Epoch 20/74\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 1.3929 - accuracy: 0.6136\n",
      "Epoch 21/74\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.3623 - accuracy: 0.6136\n",
      "Epoch 22/74\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.3589 - accuracy: 0.6364\n",
      "Epoch 23/74\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.3407 - accuracy: 0.6136\n",
      "Epoch 24/74\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.2944 - accuracy: 0.6364\n",
      "Epoch 25/74\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.3326 - accuracy: 0.5682\n",
      "Epoch 26/74\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.3019 - accuracy: 0.6136\n",
      "Epoch 27/74\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.2734 - accuracy: 0.6136\n",
      "Epoch 28/74\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.2588 - accuracy: 0.6136\n",
      "Epoch 29/74\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.2494 - accuracy: 0.5909\n",
      "Epoch 30/74\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.2467 - accuracy: 0.6136\n",
      "Epoch 31/74\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.2098 - accuracy: 0.6136\n",
      "Epoch 32/74\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.2205 - accuracy: 0.5909\n",
      "Epoch 33/74\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.2021 - accuracy: 0.6364\n",
      "Epoch 34/74\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.1920 - accuracy: 0.6364\n",
      "Epoch 35/74\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.1655 - accuracy: 0.6591\n",
      "Epoch 36/74\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.1437 - accuracy: 0.6591\n",
      "Epoch 37/74\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.1343 - accuracy: 0.6364\n",
      "Epoch 38/74\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.1439 - accuracy: 0.6364\n",
      "Epoch 39/74\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.0999 - accuracy: 0.6591\n",
      "Epoch 40/74\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0903 - accuracy: 0.6591\n",
      "Epoch 41/74\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.0740 - accuracy: 0.6591\n",
      "Epoch 42/74\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.0650 - accuracy: 0.6591\n",
      "Epoch 43/74\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.0183 - accuracy: 0.6591\n",
      "Epoch 44/74\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.0201 - accuracy: 0.6818\n",
      "Epoch 45/74\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 1.0507 - accuracy: 0.6818\n",
      "Epoch 46/74\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9881 - accuracy: 0.6818\n",
      "Epoch 47/74\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9781 - accuracy: 0.6818\n",
      "Epoch 48/74\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9772 - accuracy: 0.7273\n",
      "Epoch 49/74\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.9684 - accuracy: 0.6818\n",
      "Epoch 50/74\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.9657 - accuracy: 0.6818\n",
      "Epoch 51/74\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 1.0128 - accuracy: 0.7273\n",
      "Epoch 52/74\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9404 - accuracy: 0.7045\n",
      "Epoch 53/74\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.9370 - accuracy: 0.6591\n",
      "Epoch 54/74\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.9239 - accuracy: 0.6818\n",
      "Epoch 55/74\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8963 - accuracy: 0.7045\n",
      "Epoch 56/74\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9253 - accuracy: 0.6818\n",
      "Epoch 57/74\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8902 - accuracy: 0.6818\n",
      "Epoch 58/74\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8810 - accuracy: 0.7273\n",
      "Epoch 59/74\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8572 - accuracy: 0.6818\n",
      "Epoch 60/74\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8619 - accuracy: 0.7273\n",
      "Epoch 61/74\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.8644 - accuracy: 0.6818\n",
      "Epoch 62/74\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.8306 - accuracy: 0.7273\n",
      "Epoch 63/74\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8401 - accuracy: 0.7273\n",
      "Epoch 64/74\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.8462 - accuracy: 0.7273\n",
      "Epoch 65/74\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.2039 - accuracy: 0.7045\n",
      "Epoch 66/74\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.8478 - accuracy: 0.7500\n",
      "Epoch 67/74\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.8679 - accuracy: 0.7045\n",
      "Epoch 68/74\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9459 - accuracy: 0.6818\n",
      "Epoch 69/74\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 1.2581 - accuracy: 0.7045\n",
      "Epoch 70/74\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8455 - accuracy: 0.6818\n",
      "Epoch 71/74\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8888 - accuracy: 0.7273\n",
      "Epoch 72/74\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9305 - accuracy: 0.6818\n",
      "Epoch 73/74\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8946 - accuracy: 0.6818\n",
      "Epoch 74/74\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8896 - accuracy: 0.7045\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0887 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:27:14,265]\u001b[0m Trial 2 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 128, 'num_epochs': 74}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/138\n",
      "1/1 [==============================] - 10s 10s/step - loss: 11.4337 - accuracy: 0.0682\n",
      "Epoch 2/138\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 3.3414 - accuracy: 0.1364\n",
      "Epoch 3/138\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 2.5942 - accuracy: 0.2955\n",
      "Epoch 4/138\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.8483 - accuracy: 0.3864\n",
      "Epoch 5/138\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.7910 - accuracy: 0.4545\n",
      "Epoch 6/138\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.7188 - accuracy: 0.5000\n",
      "Epoch 7/138\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.6966 - accuracy: 0.5455\n",
      "Epoch 8/138\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.5770 - accuracy: 0.6364\n",
      "Epoch 9/138\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 1.5408 - accuracy: 0.6364\n",
      "Epoch 10/138\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.5003 - accuracy: 0.6591\n",
      "Epoch 11/138\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 1.4400 - accuracy: 0.6136\n",
      "Epoch 12/138\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.4063 - accuracy: 0.6136\n",
      "Epoch 13/138\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.3815 - accuracy: 0.6591\n",
      "Epoch 14/138\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.3008 - accuracy: 0.6591\n",
      "Epoch 15/138\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 1.2826 - accuracy: 0.6591\n",
      "Epoch 16/138\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 1.0068 - accuracy: 0.6591\n",
      "Epoch 17/138\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.9587 - accuracy: 0.6591\n",
      "Epoch 18/138\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.9427 - accuracy: 0.6136\n",
      "Epoch 19/138\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 1.0202 - accuracy: 0.6591\n",
      "Epoch 20/138\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.9448 - accuracy: 0.6591\n",
      "Epoch 21/138\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.8953 - accuracy: 0.6591\n",
      "Epoch 22/138\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.8885 - accuracy: 0.6818\n",
      "Epoch 23/138\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.8508 - accuracy: 0.6591\n",
      "Epoch 24/138\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.8290 - accuracy: 0.6818\n",
      "Epoch 25/138\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7892 - accuracy: 0.6818\n",
      "Epoch 26/138\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7547 - accuracy: 0.6818\n",
      "Epoch 27/138\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.7697 - accuracy: 0.6591\n",
      "Epoch 28/138\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.7410 - accuracy: 0.6818\n",
      "Epoch 29/138\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 1.0455 - accuracy: 0.6591\n",
      "Epoch 30/138\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.6747 - accuracy: 0.7045\n",
      "Epoch 31/138\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.6950 - accuracy: 0.6818\n",
      "Epoch 32/138\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.6687 - accuracy: 0.6818\n",
      "Epoch 33/138\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.6653 - accuracy: 0.6591\n",
      "Epoch 34/138\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.9927 - accuracy: 0.6591\n",
      "Epoch 35/138\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.7184 - accuracy: 0.6364\n",
      "Epoch 36/138\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.9927 - accuracy: 0.6818\n",
      "Epoch 37/138\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.0389 - accuracy: 0.6364\n",
      "Epoch 38/138\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.0247 - accuracy: 0.6364\n",
      "Epoch 39/138\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 1.0201 - accuracy: 0.6364\n",
      "Epoch 40/138\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 1.0276 - accuracy: 0.6364\n",
      "Epoch 41/138\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 1.0301 - accuracy: 0.6364\n",
      "Epoch 42/138\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.0081 - accuracy: 0.6591\n",
      "Epoch 43/138\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.9956 - accuracy: 0.6591\n",
      "Epoch 44/138\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.9778 - accuracy: 0.6364\n",
      "Epoch 45/138\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9708 - accuracy: 0.6364\n",
      "Epoch 46/138\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.9576 - accuracy: 0.6591\n",
      "Epoch 47/138\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.9536 - accuracy: 0.6818\n",
      "Epoch 48/138\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.9552 - accuracy: 0.6591\n",
      "Epoch 49/138\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.9272 - accuracy: 0.6818\n",
      "Epoch 50/138\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.9360 - accuracy: 0.7045\n",
      "Epoch 51/138\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.9118 - accuracy: 0.6591\n",
      "Epoch 52/138\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.9208 - accuracy: 0.6818\n",
      "Epoch 53/138\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.9213 - accuracy: 0.6591\n",
      "Epoch 54/138\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.9013 - accuracy: 0.6818\n",
      "Epoch 55/138\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.8741 - accuracy: 0.7045\n",
      "Epoch 56/138\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.8787 - accuracy: 0.6818\n",
      "Epoch 57/138\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8622 - accuracy: 0.6818\n",
      "Epoch 58/138\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.8912 - accuracy: 0.6591\n",
      "Epoch 59/138\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8697 - accuracy: 0.6818\n",
      "Epoch 60/138\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8513 - accuracy: 0.7273\n",
      "Epoch 61/138\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.8421 - accuracy: 0.7045\n",
      "Epoch 62/138\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8216 - accuracy: 0.7045\n",
      "Epoch 63/138\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.8201 - accuracy: 0.7045\n",
      "Epoch 64/138\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8158 - accuracy: 0.7273\n",
      "Epoch 65/138\n",
      "1/1 [==============================] - 0s 162ms/step - loss: nan - accuracy: 0.6818\n",
      "Epoch 66/138\n",
      "1/1 [==============================] - 0s 270ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/138\n",
      "1/1 [==============================] - 0s 263ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/138\n",
      "1/1 [==============================] - 0s 322ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/138\n",
      "1/1 [==============================] - 0s 262ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/138\n",
      "1/1 [==============================] - 0s 295ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/138\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/138\n",
      "1/1 [==============================] - 0s 264ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/138\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/138\n",
      "1/1 [==============================] - 0s 295ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/138\n",
      "1/1 [==============================] - 0s 284ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/138\n",
      "1/1 [==============================] - 0s 287ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/138\n",
      "1/1 [==============================] - 0s 286ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/138\n",
      "1/1 [==============================] - 0s 390ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/138\n",
      "1/1 [==============================] - 0s 340ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/138\n",
      "1/1 [==============================] - 0s 247ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/138\n",
      "1/1 [==============================] - 0s 421ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/138\n",
      "1/1 [==============================] - 0s 190ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/138\n",
      "1/1 [==============================] - 0s 273ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/138\n",
      "1/1 [==============================] - 0s 288ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/138\n",
      "1/1 [==============================] - 0s 308ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/138\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/138\n",
      "1/1 [==============================] - 0s 470ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/138\n",
      "1/1 [==============================] - 0s 342ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/138\n",
      "1/1 [==============================] - 0s 289ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 90/138\n",
      "1/1 [==============================] - 0s 385ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 91/138\n",
      "1/1 [==============================] - 0s 256ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 92/138\n",
      "1/1 [==============================] - 0s 335ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 93/138\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 94/138\n",
      "1/1 [==============================] - 0s 320ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 95/138\n",
      "1/1 [==============================] - 0s 366ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 96/138\n",
      "1/1 [==============================] - 0s 405ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 97/138\n",
      "1/1 [==============================] - 0s 329ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 98/138\n",
      "1/1 [==============================] - 0s 335ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 99/138\n",
      "1/1 [==============================] - 0s 338ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 100/138\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 101/138\n",
      "1/1 [==============================] - 0s 370ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 102/138\n",
      "1/1 [==============================] - 0s 491ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 103/138\n",
      "1/1 [==============================] - 0s 473ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 104/138\n",
      "1/1 [==============================] - 0s 483ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 105/138\n",
      "1/1 [==============================] - 0s 390ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 106/138\n",
      "1/1 [==============================] - 0s 468ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 107/138\n",
      "1/1 [==============================] - 1s 567ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 108/138\n",
      "1/1 [==============================] - 0s 432ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 109/138\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 110/138\n",
      "1/1 [==============================] - 0s 269ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 111/138\n",
      "1/1 [==============================] - 0s 415ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 112/138\n",
      "1/1 [==============================] - 0s 442ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 113/138\n",
      "1/1 [==============================] - 0s 305ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 114/138\n",
      "1/1 [==============================] - 0s 498ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 115/138\n",
      "1/1 [==============================] - 0s 470ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 116/138\n",
      "1/1 [==============================] - 0s 403ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 117/138\n",
      "1/1 [==============================] - 0s 329ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 118/138\n",
      "1/1 [==============================] - 0s 350ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 119/138\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 120/138\n",
      "1/1 [==============================] - 0s 295ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 121/138\n",
      "1/1 [==============================] - 0s 431ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 122/138\n",
      "1/1 [==============================] - 0s 351ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 123/138\n",
      "1/1 [==============================] - 0s 432ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 124/138\n",
      "1/1 [==============================] - 0s 461ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 125/138\n",
      "1/1 [==============================] - 0s 463ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 126/138\n",
      "1/1 [==============================] - 1s 538ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 127/138\n",
      "1/1 [==============================] - 0s 390ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 128/138\n",
      "1/1 [==============================] - 1s 507ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 129/138\n",
      "1/1 [==============================] - 0s 420ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 130/138\n",
      "1/1 [==============================] - 0s 437ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 131/138\n",
      "1/1 [==============================] - 0s 366ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 132/138\n",
      "1/1 [==============================] - 0s 288ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 133/138\n",
      "1/1 [==============================] - 0s 299ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 134/138\n",
      "1/1 [==============================] - 0s 261ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 135/138\n",
      "1/1 [==============================] - 0s 413ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 136/138\n",
      "1/1 [==============================] - 0s 354ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 137/138\n",
      "1/1 [==============================] - 0s 400ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 138/138\n",
      "1/1 [==============================] - 0s 348ms/step - loss: nan - accuracy: 0.2727\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:28:10,604]\u001b[0m Trial 3 finished with value: 0.5 and parameters: {'embedding_output_dim': 192, 'num_epochs': 138}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/88\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.8092 - accuracy: 0.0455\n",
      "Epoch 2/88\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 4.4282 - accuracy: 0.4773\n",
      "Epoch 3/88\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 4.2388 - accuracy: 0.5000\n",
      "Epoch 4/88\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 4.5643 - accuracy: 0.4545\n",
      "Epoch 5/88\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 4.2539 - accuracy: 0.5000\n",
      "Epoch 6/88\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 4.2722 - accuracy: 0.5000\n",
      "Epoch 7/88\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 3.3423 - accuracy: 0.5455\n",
      "Epoch 8/88\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.0389 - accuracy: 0.5909\n",
      "Epoch 9/88\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 3.0165 - accuracy: 0.6136\n",
      "Epoch 10/88\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 3.0338 - accuracy: 0.6136\n",
      "Epoch 11/88\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.0494 - accuracy: 0.6591\n",
      "Epoch 12/88\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 3.0457 - accuracy: 0.6591\n",
      "Epoch 13/88\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 3.0339 - accuracy: 0.6591\n",
      "Epoch 14/88\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 3.0180 - accuracy: 0.6364\n",
      "Epoch 15/88\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 3.0411 - accuracy: 0.6364\n",
      "Epoch 16/88\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 3.0366 - accuracy: 0.5909\n",
      "Epoch 17/88\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.9830 - accuracy: 0.5682\n",
      "Epoch 18/88\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.9969 - accuracy: 0.6364\n",
      "Epoch 19/88\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.9542 - accuracy: 0.7045\n",
      "Epoch 20/88\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.9102 - accuracy: 0.6364\n",
      "Epoch 21/88\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.9035 - accuracy: 0.6591\n",
      "Epoch 22/88\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.9017 - accuracy: 0.6591\n",
      "Epoch 23/88\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.9006 - accuracy: 0.6591\n",
      "Epoch 24/88\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.8355 - accuracy: 0.6364\n",
      "Epoch 25/88\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.8088 - accuracy: 0.6818\n",
      "Epoch 26/88\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 2.8100 - accuracy: 0.7045\n",
      "Epoch 27/88\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.7698 - accuracy: 0.6364\n",
      "Epoch 28/88\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.7508 - accuracy: 0.6818\n",
      "Epoch 29/88\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.7271 - accuracy: 0.6364\n",
      "Epoch 30/88\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.7005 - accuracy: 0.6364\n",
      "Epoch 31/88\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.6910 - accuracy: 0.6591\n",
      "Epoch 32/88\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.6764 - accuracy: 0.6364\n",
      "Epoch 33/88\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.6688 - accuracy: 0.6136\n",
      "Epoch 34/88\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.6307 - accuracy: 0.6591\n",
      "Epoch 35/88\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.6474 - accuracy: 0.6591\n",
      "Epoch 36/88\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.6365 - accuracy: 0.6364\n",
      "Epoch 37/88\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.6146 - accuracy: 0.6818\n",
      "Epoch 38/88\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5989 - accuracy: 0.6591\n",
      "Epoch 39/88\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.6217 - accuracy: 0.6364\n",
      "Epoch 40/88\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.6048 - accuracy: 0.6364\n",
      "Epoch 41/88\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.5810 - accuracy: 0.6818\n",
      "Epoch 42/88\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.5854 - accuracy: 0.6591\n",
      "Epoch 43/88\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.6292 - accuracy: 0.6591\n",
      "Epoch 44/88\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.5562 - accuracy: 0.6591\n",
      "Epoch 45/88\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.5714 - accuracy: 0.6818\n",
      "Epoch 46/88\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.5691 - accuracy: 0.6818\n",
      "Epoch 47/88\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.5473 - accuracy: 0.7045\n",
      "Epoch 48/88\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.5477 - accuracy: 0.6818\n",
      "Epoch 49/88\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.5622 - accuracy: 0.6818\n",
      "Epoch 50/88\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.5215 - accuracy: 0.7045\n",
      "Epoch 51/88\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 2.5091 - accuracy: 0.7273\n",
      "Epoch 52/88\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.8644 - accuracy: 0.6818\n",
      "Epoch 53/88\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.4971 - accuracy: 0.6818\n",
      "Epoch 54/88\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 2.5112 - accuracy: 0.7045\n",
      "Epoch 55/88\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.5200 - accuracy: 0.6818\n",
      "Epoch 56/88\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - accuracy: 0.6818\n",
      "Epoch 57/88\n",
      "1/1 [==============================] - 0s 140ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/88\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/88\n",
      "1/1 [==============================] - 0s 200ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/88\n",
      "1/1 [==============================] - 0s 196ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/88\n",
      "1/1 [==============================] - 0s 235ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/88\n",
      "1/1 [==============================] - 0s 212ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/88\n",
      "1/1 [==============================] - 0s 288ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/88\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/88\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/88\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/88\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/88\n",
      "1/1 [==============================] - 0s 298ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/88\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/88\n",
      "1/1 [==============================] - 0s 251ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/88\n",
      "1/1 [==============================] - 0s 257ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/88\n",
      "1/1 [==============================] - 0s 277ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/88\n",
      "1/1 [==============================] - 0s 168ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/88\n",
      "1/1 [==============================] - 0s 190ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/88\n",
      "1/1 [==============================] - 0s 195ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/88\n",
      "1/1 [==============================] - 0s 140ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/88\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/88\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/88\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/88\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/88\n",
      "1/1 [==============================] - 0s 149ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/88\n",
      "1/1 [==============================] - 0s 118ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/88\n",
      "1/1 [==============================] - 0s 136ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/88\n",
      "1/1 [==============================] - 0s 215ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/88\n",
      "1/1 [==============================] - 0s 149ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/88\n",
      "1/1 [==============================] - 0s 225ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/88\n",
      "1/1 [==============================] - 0s 209ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/88\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560b8be50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:28:38,082]\u001b[0m Trial 4 finished with value: 0.5 and parameters: {'embedding_output_dim': 86, 'num_epochs': 88}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/77\n",
      "1/1 [==============================] - 10s 10s/step - loss: 10.4416 - accuracy: 0.0227\n",
      "Epoch 2/77\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 3.8016 - accuracy: 0.4773\n",
      "Epoch 3/77\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 3.6295 - accuracy: 0.4318\n",
      "Epoch 4/77\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 2.6300 - accuracy: 0.4318\n",
      "Epoch 5/77\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 2.5856 - accuracy: 0.4091\n",
      "Epoch 6/77\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 2.6158 - accuracy: 0.3409\n",
      "Epoch 7/77\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 2.6319 - accuracy: 0.3182\n",
      "Epoch 8/77\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 2.6856 - accuracy: 0.3636\n",
      "Epoch 9/77\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 2.6170 - accuracy: 0.3864\n",
      "Epoch 10/77\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 2.6393 - accuracy: 0.3636\n",
      "Epoch 11/77\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 2.6293 - accuracy: 0.3182\n",
      "Epoch 12/77\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 2.6528 - accuracy: 0.2955\n",
      "Epoch 13/77\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 2.6095 - accuracy: 0.3636\n",
      "Epoch 14/77\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 2.5849 - accuracy: 0.3636\n",
      "Epoch 15/77\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.5334 - accuracy: 0.4545\n",
      "Epoch 16/77\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 2.4960 - accuracy: 0.4773\n",
      "Epoch 17/77\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 2.4590 - accuracy: 0.5000\n",
      "Epoch 18/77\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 2.4706 - accuracy: 0.5000\n",
      "Epoch 19/77\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 2.4204 - accuracy: 0.5455\n",
      "Epoch 20/77\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 2.4239 - accuracy: 0.4545\n",
      "Epoch 21/77\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 2.3972 - accuracy: 0.5455\n",
      "Epoch 22/77\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 2.3776 - accuracy: 0.5227\n",
      "Epoch 23/77\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 2.3340 - accuracy: 0.5909\n",
      "Epoch 24/77\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 2.3269 - accuracy: 0.5682\n",
      "Epoch 25/77\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.2936 - accuracy: 0.6136\n",
      "Epoch 26/77\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 2.2590 - accuracy: 0.5909\n",
      "Epoch 27/77\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.2768 - accuracy: 0.5909\n",
      "Epoch 28/77\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 2.2239 - accuracy: 0.6136\n",
      "Epoch 29/77\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.2217 - accuracy: 0.6364\n",
      "Epoch 30/77\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 2.1881 - accuracy: 0.6364\n",
      "Epoch 31/77\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 2.1753 - accuracy: 0.6136\n",
      "Epoch 32/77\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 2.1581 - accuracy: 0.6364\n",
      "Epoch 33/77\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.1583 - accuracy: 0.6591\n",
      "Epoch 34/77\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 2.1607 - accuracy: 0.6591\n",
      "Epoch 35/77\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 2.1212 - accuracy: 0.6136\n",
      "Epoch 36/77\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 2.1232 - accuracy: 0.6364\n",
      "Epoch 37/77\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 2.0954 - accuracy: 0.6591\n",
      "Epoch 38/77\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 2.0821 - accuracy: 0.6591\n",
      "Epoch 39/77\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 2.0737 - accuracy: 0.6591\n",
      "Epoch 40/77\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 2.0794 - accuracy: 0.6364\n",
      "Epoch 41/77\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 2.0511 - accuracy: 0.6364\n",
      "Epoch 42/77\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.0411 - accuracy: 0.6591\n",
      "Epoch 43/77\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 2.0154 - accuracy: 0.6364\n",
      "Epoch 44/77\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.0107 - accuracy: 0.6364\n",
      "Epoch 45/77\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1.9950 - accuracy: 0.6591\n",
      "Epoch 46/77\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.9771 - accuracy: 0.6591\n",
      "Epoch 47/77\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 1.9778 - accuracy: 0.6591\n",
      "Epoch 48/77\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 1.9852 - accuracy: 0.6136\n",
      "Epoch 49/77\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.9620 - accuracy: 0.6364\n",
      "Epoch 50/77\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.9469 - accuracy: 0.6364\n",
      "Epoch 51/77\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.9541 - accuracy: 0.6364\n",
      "Epoch 52/77\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 1.9361 - accuracy: 0.6364\n",
      "Epoch 53/77\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.9342 - accuracy: 0.6136\n",
      "Epoch 54/77\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.9501 - accuracy: 0.6364\n",
      "Epoch 55/77\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.9361 - accuracy: 0.6818\n",
      "Epoch 56/77\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.9324 - accuracy: 0.6136\n",
      "Epoch 57/77\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.9247 - accuracy: 0.6364\n",
      "Epoch 58/77\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.9167 - accuracy: 0.6591\n",
      "Epoch 59/77\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 1.9222 - accuracy: 0.6818\n",
      "Epoch 60/77\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 1.9124 - accuracy: 0.6818\n",
      "Epoch 61/77\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 1.9070 - accuracy: 0.6818\n",
      "Epoch 62/77\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.9160 - accuracy: 0.6818\n",
      "Epoch 63/77\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 1.8960 - accuracy: 0.6818\n",
      "Epoch 64/77\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 1.8771 - accuracy: 0.7045\n",
      "Epoch 65/77\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 1.8912 - accuracy: 0.6818\n",
      "Epoch 66/77\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.8721 - accuracy: 0.7045\n",
      "Epoch 67/77\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.8750 - accuracy: 0.7045\n",
      "Epoch 68/77\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 1.8462 - accuracy: 0.7045\n",
      "Epoch 69/77\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 1.8642 - accuracy: 0.6818\n",
      "Epoch 70/77\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 1.8554 - accuracy: 0.7273\n",
      "Epoch 71/77\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 1.8555 - accuracy: 0.7273\n",
      "Epoch 72/77\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1.8453 - accuracy: 0.7500\n",
      "Epoch 73/77\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 1.8289 - accuracy: 0.7273\n",
      "Epoch 74/77\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 1.8272 - accuracy: 0.7273\n",
      "Epoch 75/77\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.8286 - accuracy: 0.7273\n",
      "Epoch 76/77\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 1.8128 - accuracy: 0.7045\n",
      "Epoch 77/77\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 2.1572 - accuracy: 0.7273\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560cab820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:29:19,271]\u001b[0m Trial 5 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 218, 'num_epochs': 77}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/81\n",
      "1/1 [==============================] - 10s 10s/step - loss: 7.1954 - accuracy: 0.1591\n",
      "Epoch 2/81\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 6.2324 - accuracy: 0.2727\n",
      "Epoch 3/81\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 5.4671 - accuracy: 0.2727\n",
      "Epoch 4/81\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.8129 - accuracy: 0.2955\n",
      "Epoch 5/81\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.3670 - accuracy: 0.3636\n",
      "Epoch 6/81\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.3482 - accuracy: 0.3636\n",
      "Epoch 7/81\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.9278 - accuracy: 0.5227\n",
      "Epoch 8/81\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.9291 - accuracy: 0.5455\n",
      "Epoch 9/81\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.8642 - accuracy: 0.6364\n",
      "Epoch 10/81\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.8524 - accuracy: 0.6364\n",
      "Epoch 11/81\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.7817 - accuracy: 0.6136\n",
      "Epoch 12/81\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.5800 - accuracy: 0.5909\n",
      "Epoch 13/81\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.7789 - accuracy: 0.5682\n",
      "Epoch 14/81\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.4453 - accuracy: 0.5227\n",
      "Epoch 15/81\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.4487 - accuracy: 0.5227\n",
      "Epoch 16/81\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.3811 - accuracy: 0.5227\n",
      "Epoch 17/81\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.4182 - accuracy: 0.4773\n",
      "Epoch 18/81\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.3877 - accuracy: 0.5227\n",
      "Epoch 19/81\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.3695 - accuracy: 0.5455\n",
      "Epoch 20/81\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1.3752 - accuracy: 0.5227\n",
      "Epoch 21/81\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.3556 - accuracy: 0.5227\n",
      "Epoch 22/81\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.3064 - accuracy: 0.5455\n",
      "Epoch 23/81\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.2923 - accuracy: 0.5909\n",
      "Epoch 24/81\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.2623 - accuracy: 0.5682\n",
      "Epoch 25/81\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.2740 - accuracy: 0.5455\n",
      "Epoch 26/81\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 1.2493 - accuracy: 0.5909\n",
      "Epoch 27/81\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.2140 - accuracy: 0.6136\n",
      "Epoch 28/81\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.1823 - accuracy: 0.6136\n",
      "Epoch 29/81\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 1.1877 - accuracy: 0.6364\n",
      "Epoch 30/81\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.1777 - accuracy: 0.6364\n",
      "Epoch 31/81\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.1373 - accuracy: 0.6364\n",
      "Epoch 32/81\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.1335 - accuracy: 0.6364\n",
      "Epoch 33/81\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.1121 - accuracy: 0.6591\n",
      "Epoch 34/81\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.0998 - accuracy: 0.6591\n",
      "Epoch 35/81\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.0982 - accuracy: 0.6591\n",
      "Epoch 36/81\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.0587 - accuracy: 0.6364\n",
      "Epoch 37/81\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.0451 - accuracy: 0.6591\n",
      "Epoch 38/81\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.0455 - accuracy: 0.6364\n",
      "Epoch 39/81\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.0098 - accuracy: 0.6818\n",
      "Epoch 40/81\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9822 - accuracy: 0.6591\n",
      "Epoch 41/81\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.0064 - accuracy: 0.6591\n",
      "Epoch 42/81\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9538 - accuracy: 0.7045\n",
      "Epoch 43/81\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9676 - accuracy: 0.7045\n",
      "Epoch 44/81\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9475 - accuracy: 0.6591\n",
      "Epoch 45/81\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9223 - accuracy: 0.6818\n",
      "Epoch 46/81\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.2574 - accuracy: 0.6591\n",
      "Epoch 47/81\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8779 - accuracy: 0.7045\n",
      "Epoch 48/81\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.2077 - accuracy: 0.7045\n",
      "Epoch 49/81\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.2280 - accuracy: 0.7045\n",
      "Epoch 50/81\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.1765 - accuracy: 0.7045\n",
      "Epoch 51/81\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.1251 - accuracy: 0.7500\n",
      "Epoch 52/81\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.8270 - accuracy: 0.6818\n",
      "Epoch 53/81\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.0951 - accuracy: 0.7045\n",
      "Epoch 54/81\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.4611 - accuracy: 0.6818\n",
      "Epoch 55/81\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - accuracy: 0.7500\n",
      "Epoch 56/81\n",
      "1/1 [==============================] - 0s 244ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/81\n",
      "1/1 [==============================] - 0s 213ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/81\n",
      "1/1 [==============================] - 0s 193ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/81\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/81\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/81\n",
      "1/1 [==============================] - 0s 312ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/81\n",
      "1/1 [==============================] - 0s 137ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/81\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/81\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/81\n",
      "1/1 [==============================] - 0s 188ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/81\n",
      "1/1 [==============================] - 0s 233ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/81\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/81\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/81\n",
      "1/1 [==============================] - 0s 264ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/81\n",
      "1/1 [==============================] - 0s 196ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/81\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/81\n",
      "1/1 [==============================] - 0s 239ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/81\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/81\n",
      "1/1 [==============================] - 0s 239ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/81\n",
      "1/1 [==============================] - 0s 174ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/81\n",
      "1/1 [==============================] - 0s 272ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/81\n",
      "1/1 [==============================] - 0s 144ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/81\n",
      "1/1 [==============================] - 0s 254ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/81\n",
      "1/1 [==============================] - 0s 200ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/81\n",
      "1/1 [==============================] - 0s 260ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/81\n",
      "1/1 [==============================] - 0s 150ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560b421f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:29:46,765]\u001b[0m Trial 6 finished with value: 0.5 and parameters: {'embedding_output_dim': 125, 'num_epochs': 81}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/69\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.5581 - accuracy: 0.1818\n",
      "Epoch 2/69\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 6.1531 - accuracy: 0.4318\n",
      "Epoch 3/69\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.9685 - accuracy: 0.4318\n",
      "Epoch 4/69\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.6395 - accuracy: 0.4318\n",
      "Epoch 5/69\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 3.1245 - accuracy: 0.5000\n",
      "Epoch 6/69\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 3.1411 - accuracy: 0.6364\n",
      "Epoch 7/69\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 3.0710 - accuracy: 0.6136\n",
      "Epoch 8/69\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 3.0401 - accuracy: 0.6136\n",
      "Epoch 9/69\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.9912 - accuracy: 0.5909\n",
      "Epoch 10/69\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.9852 - accuracy: 0.5909\n",
      "Epoch 11/69\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.9812 - accuracy: 0.6364\n",
      "Epoch 12/69\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.6879 - accuracy: 0.6136\n",
      "Epoch 13/69\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.9495 - accuracy: 0.6136\n",
      "Epoch 14/69\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.9073 - accuracy: 0.6364\n",
      "Epoch 15/69\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.6307 - accuracy: 0.6364\n",
      "Epoch 16/69\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.6157 - accuracy: 0.6364\n",
      "Epoch 17/69\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.6177 - accuracy: 0.6136\n",
      "Epoch 18/69\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.6260 - accuracy: 0.6364\n",
      "Epoch 19/69\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.5969 - accuracy: 0.6364\n",
      "Epoch 20/69\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.5763 - accuracy: 0.6818\n",
      "Epoch 21/69\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 2.5438 - accuracy: 0.5909\n",
      "Epoch 22/69\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.5142 - accuracy: 0.6591\n",
      "Epoch 23/69\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.5291 - accuracy: 0.6136\n",
      "Epoch 24/69\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.5220 - accuracy: 0.6136\n",
      "Epoch 25/69\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.7869 - accuracy: 0.6136\n",
      "Epoch 26/69\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.4441 - accuracy: 0.5909\n",
      "Epoch 27/69\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.7578 - accuracy: 0.5909\n",
      "Epoch 28/69\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.4461 - accuracy: 0.6136\n",
      "Epoch 29/69\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.7168 - accuracy: 0.6136\n",
      "Epoch 30/69\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.7288 - accuracy: 0.6364\n",
      "Epoch 31/69\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.3934 - accuracy: 0.6591\n",
      "Epoch 32/69\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.3801 - accuracy: 0.6364\n",
      "Epoch 33/69\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.3749 - accuracy: 0.6591\n",
      "Epoch 34/69\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.3560 - accuracy: 0.6818\n",
      "Epoch 35/69\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.3374 - accuracy: 0.6591\n",
      "Epoch 36/69\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.3053 - accuracy: 0.6364\n",
      "Epoch 37/69\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2.3012 - accuracy: 0.6364\n",
      "Epoch 38/69\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.6127 - accuracy: 0.7045\n",
      "Epoch 39/69\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.2779 - accuracy: 0.6818\n",
      "Epoch 40/69\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.2890 - accuracy: 0.6591\n",
      "Epoch 41/69\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.2929 - accuracy: 0.6591\n",
      "Epoch 42/69\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.2734 - accuracy: 0.6591\n",
      "Epoch 43/69\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.2175 - accuracy: 0.6591\n",
      "Epoch 44/69\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.2505 - accuracy: 0.6591\n",
      "Epoch 45/69\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.2103 - accuracy: 0.6818\n",
      "Epoch 46/69\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.2051 - accuracy: 0.6818\n",
      "Epoch 47/69\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.1816 - accuracy: 0.7045\n",
      "Epoch 48/69\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.1987 - accuracy: 0.7045\n",
      "Epoch 49/69\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.2131 - accuracy: 0.6818\n",
      "Epoch 50/69\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.1822 - accuracy: 0.6818\n",
      "Epoch 51/69\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.1967 - accuracy: 0.6591\n",
      "Epoch 52/69\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.1827 - accuracy: 0.6364\n",
      "Epoch 53/69\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.1375 - accuracy: 0.7273\n",
      "Epoch 54/69\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.1542 - accuracy: 0.7045\n",
      "Epoch 55/69\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.1671 - accuracy: 0.6818\n",
      "Epoch 56/69\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.4926 - accuracy: 0.6818\n",
      "Epoch 57/69\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 2.1324 - accuracy: 0.7045\n",
      "Epoch 58/69\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.4841 - accuracy: 0.7045\n",
      "Epoch 59/69\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 2.4665 - accuracy: 0.7045\n",
      "Epoch 60/69\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.5252 - accuracy: 0.6818\n",
      "Epoch 61/69\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4542 - accuracy: 0.7273\n",
      "Epoch 62/69\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 63/69\n",
      "1/1 [==============================] - 0s 119ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/69\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/69\n",
      "1/1 [==============================] - 0s 59ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/69\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/69\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/69\n",
      "1/1 [==============================] - 0s 68ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/69\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560da7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:30:07,817]\u001b[0m Trial 7 finished with value: 0.5 and parameters: {'embedding_output_dim': 75, 'num_epochs': 69}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/67\n",
      "1/1 [==============================] - 10s 10s/step - loss: 10.7510 - accuracy: 0.0682\n",
      "Epoch 2/67\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 9.3488 - accuracy: 0.1364\n",
      "Epoch 3/67\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 7.1981 - accuracy: 0.0909\n",
      "Epoch 4/67\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.1923 - accuracy: 0.0909\n",
      "Epoch 5/67\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.3944 - accuracy: 0.1136\n",
      "Epoch 6/67\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.9732 - accuracy: 0.2500\n",
      "Epoch 7/67\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.5614 - accuracy: 0.1818\n",
      "Epoch 8/67\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.1945 - accuracy: 0.3409\n",
      "Epoch 9/67\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.6933 - accuracy: 0.4318\n",
      "Epoch 10/67\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.1963 - accuracy: 0.5227\n",
      "Epoch 11/67\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.0320 - accuracy: 0.5000\n",
      "Epoch 12/67\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.1430 - accuracy: 0.5227\n",
      "Epoch 13/67\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.0470 - accuracy: 0.5455\n",
      "Epoch 14/67\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.9773 - accuracy: 0.6136\n",
      "Epoch 15/67\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.9736 - accuracy: 0.5909\n",
      "Epoch 16/67\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.0258 - accuracy: 0.6364\n",
      "Epoch 17/67\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.0303 - accuracy: 0.6364\n",
      "Epoch 18/67\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.9936 - accuracy: 0.6136\n",
      "Epoch 19/67\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.9871 - accuracy: 0.6818\n",
      "Epoch 20/67\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.9305 - accuracy: 0.6364\n",
      "Epoch 21/67\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.9643 - accuracy: 0.6136\n",
      "Epoch 22/67\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 2.0054 - accuracy: 0.6364\n",
      "Epoch 23/67\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.9053 - accuracy: 0.6591\n",
      "Epoch 24/67\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.8871 - accuracy: 0.6818\n",
      "Epoch 25/67\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.9321 - accuracy: 0.6136\n",
      "Epoch 26/67\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.8594 - accuracy: 0.6364\n",
      "Epoch 27/67\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.8332 - accuracy: 0.6818\n",
      "Epoch 28/67\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.8615 - accuracy: 0.6818\n",
      "Epoch 29/67\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.8227 - accuracy: 0.6364\n",
      "Epoch 30/67\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.8231 - accuracy: 0.5682\n",
      "Epoch 31/67\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.8025 - accuracy: 0.6364\n",
      "Epoch 32/67\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.8170 - accuracy: 0.6591\n",
      "Epoch 33/67\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.7921 - accuracy: 0.6591\n",
      "Epoch 34/67\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.7623 - accuracy: 0.6364\n",
      "Epoch 35/67\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.7689 - accuracy: 0.6591\n",
      "Epoch 36/67\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.7569 - accuracy: 0.6364\n",
      "Epoch 37/67\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.7354 - accuracy: 0.6364\n",
      "Epoch 38/67\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 1.7606 - accuracy: 0.6136\n",
      "Epoch 39/67\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.7187 - accuracy: 0.5227\n",
      "Epoch 40/67\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.7589 - accuracy: 0.5682\n",
      "Epoch 41/67\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.7103 - accuracy: 0.6136\n",
      "Epoch 42/67\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.7255 - accuracy: 0.6136\n",
      "Epoch 43/67\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.7052 - accuracy: 0.6364\n",
      "Epoch 44/67\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.6817 - accuracy: 0.6364\n",
      "Epoch 45/67\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.6716 - accuracy: 0.5909\n",
      "Epoch 46/67\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 1.6504 - accuracy: 0.6364\n",
      "Epoch 47/67\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.6814 - accuracy: 0.6818\n",
      "Epoch 48/67\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.6691 - accuracy: 0.6136\n",
      "Epoch 49/67\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.6457 - accuracy: 0.6591\n",
      "Epoch 50/67\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.6349 - accuracy: 0.5455\n",
      "Epoch 51/67\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.7547 - accuracy: 0.6364\n",
      "Epoch 52/67\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 1.6061 - accuracy: 0.6136\n",
      "Epoch 53/67\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.6164 - accuracy: 0.6591\n",
      "Epoch 54/67\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 1.6236 - accuracy: 0.6364\n",
      "Epoch 55/67\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.5923 - accuracy: 0.6591\n",
      "Epoch 56/67\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.6456 - accuracy: 0.6136\n",
      "Epoch 57/67\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.6217 - accuracy: 0.6136\n",
      "Epoch 58/67\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.5644 - accuracy: 0.6364\n",
      "Epoch 59/67\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.5701 - accuracy: 0.6591\n",
      "Epoch 60/67\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.6078 - accuracy: 0.6364\n",
      "Epoch 61/67\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.5775 - accuracy: 0.6364\n",
      "Epoch 62/67\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.5541 - accuracy: 0.6591\n",
      "Epoch 63/67\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.5253 - accuracy: 0.6591\n",
      "Epoch 64/67\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.5157 - accuracy: 0.6591\n",
      "Epoch 65/67\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.5544 - accuracy: 0.6364\n",
      "Epoch 66/67\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.5190 - accuracy: 0.6364\n",
      "Epoch 67/67\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.5235 - accuracy: 0.6364\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560face50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1851 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:30:30,485]\u001b[0m Trial 8 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 57, 'num_epochs': 67}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/75\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.6398 - accuracy: 0.0455\n",
      "Epoch 2/75\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 4.0474 - accuracy: 0.4318\n",
      "Epoch 3/75\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 4.1581 - accuracy: 0.4318\n",
      "Epoch 4/75\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 4.1004 - accuracy: 0.4318\n",
      "Epoch 5/75\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 4.0345 - accuracy: 0.4318\n",
      "Epoch 6/75\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 4.0103 - accuracy: 0.4318\n",
      "Epoch 7/75\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 3.9847 - accuracy: 0.4318\n",
      "Epoch 8/75\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 3.9762 - accuracy: 0.4318\n",
      "Epoch 9/75\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 3.9733 - accuracy: 0.4318\n",
      "Epoch 10/75\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 3.9427 - accuracy: 0.4318\n",
      "Epoch 11/75\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 3.9515 - accuracy: 0.4318\n",
      "Epoch 12/75\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 3.9438 - accuracy: 0.4545\n",
      "Epoch 13/75\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 3.9214 - accuracy: 0.4545\n",
      "Epoch 14/75\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 3.9233 - accuracy: 0.4318\n",
      "Epoch 15/75\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 3.9433 - accuracy: 0.4318\n",
      "Epoch 16/75\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 3.9111 - accuracy: 0.4545\n",
      "Epoch 17/75\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 3.9208 - accuracy: 0.4318\n",
      "Epoch 18/75\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 3.9020 - accuracy: 0.4318\n",
      "Epoch 19/75\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 3.9025 - accuracy: 0.4318\n",
      "Epoch 20/75\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 3.8871 - accuracy: 0.5000\n",
      "Epoch 21/75\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 3.8754 - accuracy: 0.4773\n",
      "Epoch 22/75\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 3.8579 - accuracy: 0.5227\n",
      "Epoch 23/75\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 3.8520 - accuracy: 0.5227\n",
      "Epoch 24/75\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 3.8494 - accuracy: 0.5000\n",
      "Epoch 25/75\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 3.8442 - accuracy: 0.5227\n",
      "Epoch 26/75\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 3.8367 - accuracy: 0.5227\n",
      "Epoch 27/75\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 3.8392 - accuracy: 0.5227\n",
      "Epoch 28/75\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 3.8193 - accuracy: 0.5000\n",
      "Epoch 29/75\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 3.8074 - accuracy: 0.5455\n",
      "Epoch 30/75\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 3.7791 - accuracy: 0.6136\n",
      "Epoch 31/75\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 3.7870 - accuracy: 0.5909\n",
      "Epoch 32/75\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 3.7614 - accuracy: 0.6591\n",
      "Epoch 33/75\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 3.7418 - accuracy: 0.6364\n",
      "Epoch 34/75\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 3.7504 - accuracy: 0.6364\n",
      "Epoch 35/75\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 3.7276 - accuracy: 0.6818\n",
      "Epoch 36/75\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 3.7270 - accuracy: 0.6591\n",
      "Epoch 37/75\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 3.7142 - accuracy: 0.6136\n",
      "Epoch 38/75\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 3.6969 - accuracy: 0.6136\n",
      "Epoch 39/75\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 3.6662 - accuracy: 0.6591\n",
      "Epoch 40/75\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 3.6452 - accuracy: 0.6136\n",
      "Epoch 41/75\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 3.6303 - accuracy: 0.7045\n",
      "Epoch 42/75\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 4.0153 - accuracy: 0.6364\n",
      "Epoch 43/75\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 3.6324 - accuracy: 0.6818\n",
      "Epoch 44/75\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 3.9973 - accuracy: 0.6364\n",
      "Epoch 45/75\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 3.9600 - accuracy: 0.6136\n",
      "Epoch 46/75\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 3.9464 - accuracy: 0.6136\n",
      "Epoch 47/75\n",
      "1/1 [==============================] - 0s 305ms/step - loss: nan - accuracy: 0.6364\n",
      "Epoch 48/75\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/75\n",
      "1/1 [==============================] - 0s 360ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/75\n",
      "1/1 [==============================] - 0s 377ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/75\n",
      "1/1 [==============================] - 0s 305ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/75\n",
      "1/1 [==============================] - 0s 394ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/75\n",
      "1/1 [==============================] - 0s 420ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/75\n",
      "1/1 [==============================] - 0s 379ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/75\n",
      "1/1 [==============================] - 0s 364ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/75\n",
      "1/1 [==============================] - 0s 400ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/75\n",
      "1/1 [==============================] - 0s 300ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/75\n",
      "1/1 [==============================] - 0s 287ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/75\n",
      "1/1 [==============================] - 0s 336ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/75\n",
      "1/1 [==============================] - 0s 407ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/75\n",
      "1/1 [==============================] - 0s 383ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/75\n",
      "1/1 [==============================] - 0s 341ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/75\n",
      "1/1 [==============================] - 0s 372ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/75\n",
      "1/1 [==============================] - 0s 444ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/75\n",
      "1/1 [==============================] - 0s 422ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/75\n",
      "1/1 [==============================] - 0s 361ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/75\n",
      "1/1 [==============================] - 0s 338ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/75\n",
      "1/1 [==============================] - 0s 466ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/75\n",
      "1/1 [==============================] - 0s 456ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/75\n",
      "1/1 [==============================] - 0s 492ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/75\n",
      "1/1 [==============================] - 0s 442ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/75\n",
      "1/1 [==============================] - 0s 374ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/75\n",
      "1/1 [==============================] - 1s 558ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/75\n",
      "1/1 [==============================] - 1s 636ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/75\n",
      "1/1 [==============================] - 1s 516ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff540119ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:31:10,759]\u001b[0m Trial 9 finished with value: 0.5 and parameters: {'embedding_output_dim': 234, 'num_epochs': 75}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/28\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.9059 - accuracy: 0.1136\n",
      "Epoch 2/28\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.4294 - accuracy: 0.0682\n",
      "Epoch 3/28\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 3.2311 - accuracy: 0.3864\n",
      "Epoch 4/28\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.1172 - accuracy: 0.4545\n",
      "Epoch 5/28\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.7990 - accuracy: 0.5000\n",
      "Epoch 6/28\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.6623 - accuracy: 0.4318\n",
      "Epoch 7/28\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.6821 - accuracy: 0.5227\n",
      "Epoch 8/28\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.6201 - accuracy: 0.2955\n",
      "Epoch 9/28\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 2.9210 - accuracy: 0.4545\n",
      "Epoch 10/28\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.6681 - accuracy: 0.4545\n",
      "Epoch 11/28\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.8050 - accuracy: 0.4545\n",
      "Epoch 12/28\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.5311 - accuracy: 0.4091\n",
      "Epoch 13/28\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.4869 - accuracy: 0.5455\n",
      "Epoch 14/28\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.7576 - accuracy: 0.5000\n",
      "Epoch 15/28\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.4769 - accuracy: 0.4318\n",
      "Epoch 16/28\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.4449 - accuracy: 0.5455\n",
      "Epoch 17/28\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.7055 - accuracy: 0.4773\n",
      "Epoch 18/28\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.3853 - accuracy: 0.5227\n",
      "Epoch 19/28\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.4207 - accuracy: 0.4318\n",
      "Epoch 20/28\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.6699 - accuracy: 0.4545\n",
      "Epoch 21/28\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 2.4233 - accuracy: 0.4773\n",
      "Epoch 22/28\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.7065 - accuracy: 0.4318\n",
      "Epoch 23/28\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.3773 - accuracy: 0.4091\n",
      "Epoch 24/28\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.3824 - accuracy: 0.4773\n",
      "Epoch 25/28\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.1060 - accuracy: 0.5227\n",
      "Epoch 26/28\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.3575 - accuracy: 0.4318\n",
      "Epoch 27/28\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.4501 - accuracy: 0.4318\n",
      "Epoch 28/28\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.1198 - accuracy: 0.4545\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8e42940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5434 - accuracy: 0.5455\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:31:26,142]\u001b[0m Trial 10 finished with value: 0.5454545617103577 and parameters: {'embedding_output_dim': 18, 'num_epochs': 28}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/46\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.7043 - accuracy: 0.1591\n",
      "Epoch 2/46\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 5.5986 - accuracy: 0.1818\n",
      "Epoch 3/46\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.9714 - accuracy: 0.4318\n",
      "Epoch 4/46\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 4.1037 - accuracy: 0.5682\n",
      "Epoch 5/46\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 4.1678 - accuracy: 0.5682\n",
      "Epoch 6/46\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.8070 - accuracy: 0.4773\n",
      "Epoch 7/46\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 3.7005 - accuracy: 0.5682\n",
      "Epoch 8/46\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 3.8688 - accuracy: 0.5682\n",
      "Epoch 9/46\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 3.4705 - accuracy: 0.5455\n",
      "Epoch 10/46\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.2370 - accuracy: 0.5000\n",
      "Epoch 11/46\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 3.5220 - accuracy: 0.5682\n",
      "Epoch 12/46\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 3.5137 - accuracy: 0.5909\n",
      "Epoch 13/46\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 3.4803 - accuracy: 0.5682\n",
      "Epoch 14/46\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.9365 - accuracy: 0.5682\n",
      "Epoch 15/46\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 3.1755 - accuracy: 0.5682\n",
      "Epoch 16/46\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 3.1702 - accuracy: 0.5455\n",
      "Epoch 17/46\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.9189 - accuracy: 0.5682\n",
      "Epoch 18/46\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 3.2214 - accuracy: 0.5682\n",
      "Epoch 19/46\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.2136 - accuracy: 0.5455\n",
      "Epoch 20/46\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.8666 - accuracy: 0.5455\n",
      "Epoch 21/46\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.5426 - accuracy: 0.5682\n",
      "Epoch 22/46\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6282 - accuracy: 0.5682\n",
      "Epoch 23/46\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.8596 - accuracy: 0.5682\n",
      "Epoch 24/46\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.6317 - accuracy: 0.5227\n",
      "Epoch 25/46\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5198 - accuracy: 0.5909\n",
      "Epoch 26/46\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.5669 - accuracy: 0.5455\n",
      "Epoch 27/46\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.3022 - accuracy: 0.5455\n",
      "Epoch 28/46\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.5984 - accuracy: 0.5909\n",
      "Epoch 29/46\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 2.5744 - accuracy: 0.5909\n",
      "Epoch 30/46\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.4048 - accuracy: 0.5682\n",
      "Epoch 31/46\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.2258 - accuracy: 0.6136\n",
      "Epoch 32/46\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.2444 - accuracy: 0.5909\n",
      "Epoch 33/46\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.2297 - accuracy: 0.5909\n",
      "Epoch 34/46\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.2537 - accuracy: 0.6136\n",
      "Epoch 35/46\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.3065 - accuracy: 0.5909\n",
      "Epoch 36/46\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.3330 - accuracy: 0.6136\n",
      "Epoch 37/46\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.2883 - accuracy: 0.5682\n",
      "Epoch 38/46\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.3639 - accuracy: 0.5455\n",
      "Epoch 39/46\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.3500 - accuracy: 0.5682\n",
      "Epoch 40/46\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4376 - accuracy: 0.5455\n",
      "Epoch 41/46\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.3527 - accuracy: 0.5455\n",
      "Epoch 42/46\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.3657 - accuracy: 0.5455\n",
      "Epoch 43/46\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.6598 - accuracy: 0.5682\n",
      "Epoch 44/46\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 2.3881 - accuracy: 0.5909\n",
      "Epoch 45/46\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.6998 - accuracy: 0.5455\n",
      "Epoch 46/46\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.3540 - accuracy: 0.5909\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c26b820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2170 - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:31:43,447]\u001b[0m Trial 11 finished with value: 0.5 and parameters: {'embedding_output_dim': 20, 'num_epochs': 46}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/121\n",
      "1/1 [==============================] - 11s 11s/step - loss: 8.2857 - accuracy: 0.0455\n",
      "Epoch 2/121\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6332 - accuracy: 0.4318\n",
      "Epoch 3/121\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.7713 - accuracy: 0.4318\n",
      "Epoch 4/121\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.4621 - accuracy: 0.4318\n",
      "Epoch 5/121\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.4482 - accuracy: 0.4318\n",
      "Epoch 6/121\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.1711 - accuracy: 0.4318\n",
      "Epoch 7/121\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 3.0616 - accuracy: 0.4545\n",
      "Epoch 8/121\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.0937 - accuracy: 0.4318\n",
      "Epoch 9/121\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 3.0535 - accuracy: 0.4318\n",
      "Epoch 10/121\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.9998 - accuracy: 0.4318\n",
      "Epoch 11/121\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.9791 - accuracy: 0.4773\n",
      "Epoch 12/121\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.9701 - accuracy: 0.4318\n",
      "Epoch 13/121\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.9905 - accuracy: 0.4318\n",
      "Epoch 14/121\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.9317 - accuracy: 0.4773\n",
      "Epoch 15/121\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.9439 - accuracy: 0.5455\n",
      "Epoch 16/121\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.9741 - accuracy: 0.5227\n",
      "Epoch 17/121\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.9346 - accuracy: 0.5227\n",
      "Epoch 18/121\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.9673 - accuracy: 0.5227\n",
      "Epoch 19/121\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.9495 - accuracy: 0.4773\n",
      "Epoch 20/121\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.8879 - accuracy: 0.6364\n",
      "Epoch 21/121\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.8915 - accuracy: 0.5909\n",
      "Epoch 22/121\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.9128 - accuracy: 0.5455\n",
      "Epoch 23/121\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.8712 - accuracy: 0.5682\n",
      "Epoch 24/121\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.8930 - accuracy: 0.6136\n",
      "Epoch 25/121\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.8980 - accuracy: 0.5909\n",
      "Epoch 26/121\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.8337 - accuracy: 0.6364\n",
      "Epoch 27/121\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.8563 - accuracy: 0.5909\n",
      "Epoch 28/121\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.8630 - accuracy: 0.5682\n",
      "Epoch 29/121\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.8489 - accuracy: 0.5909\n",
      "Epoch 30/121\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.8575 - accuracy: 0.5682\n",
      "Epoch 31/121\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.8409 - accuracy: 0.5682\n",
      "Epoch 32/121\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.8260 - accuracy: 0.5682\n",
      "Epoch 33/121\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.7897 - accuracy: 0.6364\n",
      "Epoch 34/121\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.8195 - accuracy: 0.5455\n",
      "Epoch 35/121\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.7909 - accuracy: 0.6136\n",
      "Epoch 36/121\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.7681 - accuracy: 0.6136\n",
      "Epoch 37/121\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.7768 - accuracy: 0.6364\n",
      "Epoch 38/121\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.7783 - accuracy: 0.6591\n",
      "Epoch 39/121\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.7756 - accuracy: 0.6364\n",
      "Epoch 40/121\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.7424 - accuracy: 0.6591\n",
      "Epoch 41/121\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.7546 - accuracy: 0.6364\n",
      "Epoch 42/121\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.7732 - accuracy: 0.6364\n",
      "Epoch 43/121\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.7366 - accuracy: 0.6591\n",
      "Epoch 44/121\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.7389 - accuracy: 0.6591\n",
      "Epoch 45/121\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.7417 - accuracy: 0.6136\n",
      "Epoch 46/121\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.7165 - accuracy: 0.6591\n",
      "Epoch 47/121\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.7452 - accuracy: 0.6591\n",
      "Epoch 48/121\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.7272 - accuracy: 0.6136\n",
      "Epoch 49/121\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.7074 - accuracy: 0.6591\n",
      "Epoch 50/121\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.7196 - accuracy: 0.6591\n",
      "Epoch 51/121\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.6969 - accuracy: 0.6364\n",
      "Epoch 52/121\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.6971 - accuracy: 0.6364\n",
      "Epoch 53/121\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.6909 - accuracy: 0.6591\n",
      "Epoch 54/121\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.6861 - accuracy: 0.6364\n",
      "Epoch 55/121\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.6833 - accuracy: 0.6591\n",
      "Epoch 56/121\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.6580 - accuracy: 0.6364\n",
      "Epoch 57/121\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.6321 - accuracy: 0.6591\n",
      "Epoch 58/121\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.6540 - accuracy: 0.6364\n",
      "Epoch 59/121\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6329 - accuracy: 0.6364\n",
      "Epoch 60/121\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.6384 - accuracy: 0.6364\n",
      "Epoch 61/121\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.6342 - accuracy: 0.6364\n",
      "Epoch 62/121\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.6012 - accuracy: 0.6136\n",
      "Epoch 63/121\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.6177 - accuracy: 0.6591\n",
      "Epoch 64/121\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.6217 - accuracy: 0.6591\n",
      "Epoch 65/121\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6272 - accuracy: 0.6818\n",
      "Epoch 66/121\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6049 - accuracy: 0.6591\n",
      "Epoch 67/121\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.6085 - accuracy: 0.6591\n",
      "Epoch 68/121\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.6294 - accuracy: 0.6136\n",
      "Epoch 69/121\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2.5836 - accuracy: 0.6136\n",
      "Epoch 70/121\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.5987 - accuracy: 0.6136\n",
      "Epoch 71/121\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.5815 - accuracy: 0.6591\n",
      "Epoch 72/121\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.5739 - accuracy: 0.6591\n",
      "Epoch 73/121\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.5760 - accuracy: 0.6818\n",
      "Epoch 74/121\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.5570 - accuracy: 0.7045\n",
      "Epoch 75/121\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5645 - accuracy: 0.7045\n",
      "Epoch 76/121\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5724 - accuracy: 0.6591\n",
      "Epoch 77/121\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.5679 - accuracy: 0.6364\n",
      "Epoch 78/121\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5402 - accuracy: 0.6591\n",
      "Epoch 79/121\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.5462 - accuracy: 0.6818\n",
      "Epoch 80/121\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.5311 - accuracy: 0.6818\n",
      "Epoch 81/121\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.5511 - accuracy: 0.7045\n",
      "Epoch 82/121\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.5727 - accuracy: 0.7045\n",
      "Epoch 83/121\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5372 - accuracy: 0.6818\n",
      "Epoch 84/121\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.5556 - accuracy: 0.6818\n",
      "Epoch 85/121\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.5518 - accuracy: 0.6818\n",
      "Epoch 86/121\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5260 - accuracy: 0.6818\n",
      "Epoch 87/121\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.5092 - accuracy: 0.7045\n",
      "Epoch 88/121\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5081 - accuracy: 0.7045\n",
      "Epoch 89/121\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5207 - accuracy: 0.7045\n",
      "Epoch 90/121\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.5101 - accuracy: 0.7045\n",
      "Epoch 91/121\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5128 - accuracy: 0.7045\n",
      "Epoch 92/121\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.5302 - accuracy: 0.7045\n",
      "Epoch 93/121\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.5281 - accuracy: 0.6591\n",
      "Epoch 94/121\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5030 - accuracy: 0.7045\n",
      "Epoch 95/121\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.5299 - accuracy: 0.7045\n",
      "Epoch 96/121\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.5367 - accuracy: 0.6818\n",
      "Epoch 97/121\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.5074 - accuracy: 0.6591\n",
      "Epoch 98/121\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.4918 - accuracy: 0.7045\n",
      "Epoch 99/121\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.4936 - accuracy: 0.7045\n",
      "Epoch 100/121\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5080 - accuracy: 0.6818\n",
      "Epoch 101/121\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.4853 - accuracy: 0.7045\n",
      "Epoch 102/121\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.4841 - accuracy: 0.7045\n",
      "Epoch 103/121\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.4939 - accuracy: 0.7045\n",
      "Epoch 104/121\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.5310 - accuracy: 0.6591\n",
      "Epoch 105/121\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.4875 - accuracy: 0.7045\n",
      "Epoch 106/121\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4963 - accuracy: 0.7500\n",
      "Epoch 107/121\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.4764 - accuracy: 0.6818\n",
      "Epoch 108/121\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.4686 - accuracy: 0.7273\n",
      "Epoch 109/121\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 2.4702 - accuracy: 0.7273\n",
      "Epoch 110/121\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.4847 - accuracy: 0.7045\n",
      "Epoch 111/121\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.4661 - accuracy: 0.7273\n",
      "Epoch 112/121\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.4502 - accuracy: 0.7727\n",
      "Epoch 113/121\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.4692 - accuracy: 0.7273\n",
      "Epoch 114/121\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.4529 - accuracy: 0.7045\n",
      "Epoch 115/121\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.8051 - accuracy: 0.7273\n",
      "Epoch 116/121\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.4730 - accuracy: 0.7045\n",
      "Epoch 117/121\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4414 - accuracy: 0.7500\n",
      "Epoch 118/121\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4467 - accuracy: 0.7045\n",
      "Epoch 119/121\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.7514 - accuracy: 0.7273\n",
      "Epoch 120/121\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 121/121\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff57017e310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:32:09,809]\u001b[0m Trial 12 finished with value: 0.5 and parameters: {'embedding_output_dim': 63, 'num_epochs': 121}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/53\n",
      "1/1 [==============================] - 9s 9s/step - loss: 6.0783 - accuracy: 0.2045\n",
      "Epoch 2/53\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.9834 - accuracy: 0.4318\n",
      "Epoch 3/53\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 3.0332 - accuracy: 0.4318\n",
      "Epoch 4/53\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.6966 - accuracy: 0.5227\n",
      "Epoch 5/53\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.6245 - accuracy: 0.5682\n",
      "Epoch 6/53\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.6738 - accuracy: 0.5909\n",
      "Epoch 7/53\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.6140 - accuracy: 0.5909\n",
      "Epoch 8/53\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.5637 - accuracy: 0.6364\n",
      "Epoch 9/53\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.5871 - accuracy: 0.6591\n",
      "Epoch 10/53\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.6241 - accuracy: 0.6136\n",
      "Epoch 11/53\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.5349 - accuracy: 0.6364\n",
      "Epoch 12/53\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.5709 - accuracy: 0.6591\n",
      "Epoch 13/53\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.5185 - accuracy: 0.6591\n",
      "Epoch 14/53\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.5033 - accuracy: 0.6818\n",
      "Epoch 15/53\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.5077 - accuracy: 0.6591\n",
      "Epoch 16/53\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.4444 - accuracy: 0.6591\n",
      "Epoch 17/53\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.4136 - accuracy: 0.6364\n",
      "Epoch 18/53\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 2.3976 - accuracy: 0.6364\n",
      "Epoch 19/53\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.3727 - accuracy: 0.6591\n",
      "Epoch 20/53\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.3501 - accuracy: 0.6591\n",
      "Epoch 21/53\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.3403 - accuracy: 0.6818\n",
      "Epoch 22/53\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.3282 - accuracy: 0.6591\n",
      "Epoch 23/53\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.3279 - accuracy: 0.6591\n",
      "Epoch 24/53\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.3071 - accuracy: 0.6136\n",
      "Epoch 25/53\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.3072 - accuracy: 0.6591\n",
      "Epoch 26/53\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.3044 - accuracy: 0.6591\n",
      "Epoch 27/53\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.2661 - accuracy: 0.6591\n",
      "Epoch 28/53\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.2821 - accuracy: 0.6591\n",
      "Epoch 29/53\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.2813 - accuracy: 0.6591\n",
      "Epoch 30/53\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.2473 - accuracy: 0.6591\n",
      "Epoch 31/53\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.2597 - accuracy: 0.6818\n",
      "Epoch 32/53\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.2339 - accuracy: 0.7045\n",
      "Epoch 33/53\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.2154 - accuracy: 0.6818\n",
      "Epoch 34/53\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.2062 - accuracy: 0.6818\n",
      "Epoch 35/53\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.1987 - accuracy: 0.7045\n",
      "Epoch 36/53\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.1651 - accuracy: 0.7273\n",
      "Epoch 37/53\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.1993 - accuracy: 0.7045\n",
      "Epoch 38/53\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.1672 - accuracy: 0.7273\n",
      "Epoch 39/53\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.8007 - accuracy: 0.7045\n",
      "Epoch 40/53\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.5560 - accuracy: 0.6818\n",
      "Epoch 41/53\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.5494 - accuracy: 0.6591\n",
      "Epoch 42/53\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.1895 - accuracy: 0.7045\n",
      "Epoch 43/53\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.2114 - accuracy: 0.7045\n",
      "Epoch 44/53\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.5348 - accuracy: 0.6591\n",
      "Epoch 45/53\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.5478 - accuracy: 0.7045\n",
      "Epoch 46/53\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.9254 - accuracy: 0.6818\n",
      "Epoch 47/53\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.5354 - accuracy: 0.6818\n",
      "Epoch 48/53\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.4967 - accuracy: 0.7045\n",
      "Epoch 49/53\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.5500 - accuracy: 0.7045\n",
      "Epoch 50/53\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.1422 - accuracy: 0.7045\n",
      "Epoch 51/53\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.4880 - accuracy: 0.7273\n",
      "Epoch 52/53\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.4900 - accuracy: 0.7045\n",
      "Epoch 53/53\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.4954 - accuracy: 0.6591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff56126f9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7170 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:32:30,788]\u001b[0m Trial 13 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 128, 'num_epochs': 53}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/122\n",
      "1/1 [==============================] - 10s 10s/step - loss: 6.7321 - accuracy: 0.0682\n",
      "Epoch 2/122\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 4.1620 - accuracy: 0.4318\n",
      "Epoch 3/122\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 4.6116 - accuracy: 0.4318\n",
      "Epoch 4/122\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 3.6353 - accuracy: 0.4318\n",
      "Epoch 5/122\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 3.3408 - accuracy: 0.4545\n",
      "Epoch 6/122\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.5743 - accuracy: 0.5000\n",
      "Epoch 7/122\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.2450 - accuracy: 0.5000\n",
      "Epoch 8/122\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3.2471 - accuracy: 0.5682\n",
      "Epoch 9/122\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3.2564 - accuracy: 0.5682\n",
      "Epoch 10/122\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 3.2693 - accuracy: 0.5682\n",
      "Epoch 11/122\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 3.2565 - accuracy: 0.6364\n",
      "Epoch 12/122\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3.2425 - accuracy: 0.6591\n",
      "Epoch 13/122\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 3.2286 - accuracy: 0.6364\n",
      "Epoch 14/122\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 3.2323 - accuracy: 0.6136\n",
      "Epoch 15/122\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 3.1974 - accuracy: 0.7045\n",
      "Epoch 16/122\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 3.1799 - accuracy: 0.6364\n",
      "Epoch 17/122\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 3.1719 - accuracy: 0.6364\n",
      "Epoch 18/122\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 3.1896 - accuracy: 0.6364\n",
      "Epoch 19/122\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 3.1418 - accuracy: 0.6591\n",
      "Epoch 20/122\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 3.1470 - accuracy: 0.6591\n",
      "Epoch 21/122\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 3.1266 - accuracy: 0.6364\n",
      "Epoch 22/122\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 3.1303 - accuracy: 0.6591\n",
      "Epoch 23/122\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3.1196 - accuracy: 0.6591\n",
      "Epoch 24/122\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.1028 - accuracy: 0.6591\n",
      "Epoch 25/122\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3.0637 - accuracy: 0.6364\n",
      "Epoch 26/122\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 3.0712 - accuracy: 0.6136\n",
      "Epoch 27/122\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 3.0419 - accuracy: 0.6136\n",
      "Epoch 28/122\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 3.0342 - accuracy: 0.6591\n",
      "Epoch 29/122\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.0021 - accuracy: 0.6364\n",
      "Epoch 30/122\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 3.0136 - accuracy: 0.6364\n",
      "Epoch 31/122\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.9945 - accuracy: 0.6364\n",
      "Epoch 32/122\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.9910 - accuracy: 0.6364\n",
      "Epoch 33/122\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.9754 - accuracy: 0.6591\n",
      "Epoch 34/122\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.9515 - accuracy: 0.6364\n",
      "Epoch 35/122\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.9505 - accuracy: 0.6364\n",
      "Epoch 36/122\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.9670 - accuracy: 0.6364\n",
      "Epoch 37/122\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.9430 - accuracy: 0.6364\n",
      "Epoch 38/122\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 2.9490 - accuracy: 0.6364\n",
      "Epoch 39/122\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.9436 - accuracy: 0.6364\n",
      "Epoch 40/122\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.9466 - accuracy: 0.6591\n",
      "Epoch 41/122\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.9370 - accuracy: 0.6591\n",
      "Epoch 42/122\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.9255 - accuracy: 0.6364\n",
      "Epoch 43/122\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.9204 - accuracy: 0.6591\n",
      "Epoch 44/122\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.9069 - accuracy: 0.6591\n",
      "Epoch 45/122\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.2408 - accuracy: 0.6591\n",
      "Epoch 46/122\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.8845 - accuracy: 0.6818\n",
      "Epoch 47/122\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.8914 - accuracy: 0.6591\n",
      "Epoch 48/122\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 2.8837 - accuracy: 0.6591\n",
      "Epoch 49/122\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 2.8729 - accuracy: 0.6591\n",
      "Epoch 50/122\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 2.8795 - accuracy: 0.6818\n",
      "Epoch 51/122\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.8939 - accuracy: 0.6591\n",
      "Epoch 52/122\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.8535 - accuracy: 0.6818\n",
      "Epoch 53/122\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.8588 - accuracy: 0.7045\n",
      "Epoch 54/122\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.8578 - accuracy: 0.7045\n",
      "Epoch 55/122\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 2.8475 - accuracy: 0.7045\n",
      "Epoch 56/122\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 2.8521 - accuracy: 0.6818\n",
      "Epoch 57/122\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.8491 - accuracy: 0.7273\n",
      "Epoch 58/122\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 2.8286 - accuracy: 0.7045\n",
      "Epoch 59/122\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 2.8265 - accuracy: 0.7045\n",
      "Epoch 60/122\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.8281 - accuracy: 0.7045\n",
      "Epoch 61/122\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.7975 - accuracy: 0.7045\n",
      "Epoch 62/122\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.8020 - accuracy: 0.6818\n",
      "Epoch 63/122\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.7941 - accuracy: 0.7045\n",
      "Epoch 64/122\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 2.7861 - accuracy: 0.6591\n",
      "Epoch 65/122\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.7741 - accuracy: 0.7045\n",
      "Epoch 66/122\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.7814 - accuracy: 0.7045\n",
      "Epoch 67/122\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - accuracy: 0.7273\n",
      "Epoch 68/122\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/122\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/122\n",
      "1/1 [==============================] - 0s 223ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/122\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/122\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/122\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/122\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/122\n",
      "1/1 [==============================] - 0s 195ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/122\n",
      "1/1 [==============================] - 0s 275ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/122\n",
      "1/1 [==============================] - 0s 179ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/122\n",
      "1/1 [==============================] - 0s 196ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/122\n",
      "1/1 [==============================] - 0s 237ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/122\n",
      "1/1 [==============================] - 0s 187ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/122\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/122\n",
      "1/1 [==============================] - 0s 194ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/122\n",
      "1/1 [==============================] - 0s 179ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/122\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/122\n",
      "1/1 [==============================] - 0s 251ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/122\n",
      "1/1 [==============================] - 0s 263ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/122\n",
      "1/1 [==============================] - 0s 237ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/122\n",
      "1/1 [==============================] - 0s 266ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/122\n",
      "1/1 [==============================] - 0s 164ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 90/122\n",
      "1/1 [==============================] - 0s 285ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 91/122\n",
      "1/1 [==============================] - 0s 209ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 92/122\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 93/122\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 94/122\n",
      "1/1 [==============================] - 0s 272ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 95/122\n",
      "1/1 [==============================] - 0s 238ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 96/122\n",
      "1/1 [==============================] - 0s 210ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 97/122\n",
      "1/1 [==============================] - 0s 201ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 98/122\n",
      "1/1 [==============================] - 0s 252ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 99/122\n",
      "1/1 [==============================] - 0s 250ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 100/122\n",
      "1/1 [==============================] - 0s 285ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 101/122\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 102/122\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 103/122\n",
      "1/1 [==============================] - 0s 229ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 104/122\n",
      "1/1 [==============================] - 0s 303ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 105/122\n",
      "1/1 [==============================] - 0s 303ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 106/122\n",
      "1/1 [==============================] - 0s 197ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 107/122\n",
      "1/1 [==============================] - 0s 294ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 108/122\n",
      "1/1 [==============================] - 0s 253ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 109/122\n",
      "1/1 [==============================] - 0s 163ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 110/122\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 111/122\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 112/122\n",
      "1/1 [==============================] - 0s 237ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 113/122\n",
      "1/1 [==============================] - 0s 207ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 114/122\n",
      "1/1 [==============================] - 0s 221ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 115/122\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 116/122\n",
      "1/1 [==============================] - 0s 158ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 117/122\n",
      "1/1 [==============================] - 0s 235ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 118/122\n",
      "1/1 [==============================] - 0s 232ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 119/122\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 120/122\n",
      "1/1 [==============================] - 0s 207ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 121/122\n",
      "1/1 [==============================] - 0s 188ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 122/122\n",
      "1/1 [==============================] - 0s 262ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c611f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:33:08,000]\u001b[0m Trial 14 finished with value: 0.5 and parameters: {'embedding_output_dim': 157, 'num_epochs': 122}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/104\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.2780 - accuracy: 0.0455\n",
      "Epoch 2/104\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.8556 - accuracy: 0.3182\n",
      "Epoch 3/104\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.2180 - accuracy: 0.4318\n",
      "Epoch 4/104\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 3.2190 - accuracy: 0.4318\n",
      "Epoch 5/104\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 3.3941 - accuracy: 0.4773\n",
      "Epoch 6/104\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.0207 - accuracy: 0.5455\n",
      "Epoch 7/104\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 3.0148 - accuracy: 0.4773\n",
      "Epoch 8/104\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 3.0101 - accuracy: 0.5682\n",
      "Epoch 9/104\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.9832 - accuracy: 0.5455\n",
      "Epoch 10/104\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.9559 - accuracy: 0.5682\n",
      "Epoch 11/104\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.9395 - accuracy: 0.5682\n",
      "Epoch 12/104\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.9294 - accuracy: 0.5000\n",
      "Epoch 13/104\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.9122 - accuracy: 0.5682\n",
      "Epoch 14/104\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2.8942 - accuracy: 0.5455\n",
      "Epoch 15/104\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.8768 - accuracy: 0.5909\n",
      "Epoch 16/104\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.8441 - accuracy: 0.5682\n",
      "Epoch 17/104\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.8506 - accuracy: 0.5909\n",
      "Epoch 18/104\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.8182 - accuracy: 0.6136\n",
      "Epoch 19/104\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.8150 - accuracy: 0.6136\n",
      "Epoch 20/104\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.8191 - accuracy: 0.6136\n",
      "Epoch 21/104\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.8006 - accuracy: 0.6364\n",
      "Epoch 22/104\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.7731 - accuracy: 0.6591\n",
      "Epoch 23/104\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.7333 - accuracy: 0.6591\n",
      "Epoch 24/104\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.7249 - accuracy: 0.6591\n",
      "Epoch 25/104\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.7238 - accuracy: 0.6136\n",
      "Epoch 26/104\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.6870 - accuracy: 0.6364\n",
      "Epoch 27/104\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.6870 - accuracy: 0.6136\n",
      "Epoch 28/104\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.6966 - accuracy: 0.6591\n",
      "Epoch 29/104\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.6516 - accuracy: 0.6591\n",
      "Epoch 30/104\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.6458 - accuracy: 0.6364\n",
      "Epoch 31/104\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.6244 - accuracy: 0.6364\n",
      "Epoch 32/104\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.5930 - accuracy: 0.6364\n",
      "Epoch 33/104\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.5915 - accuracy: 0.6364\n",
      "Epoch 34/104\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.5860 - accuracy: 0.6364\n",
      "Epoch 35/104\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.5838 - accuracy: 0.6591\n",
      "Epoch 36/104\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.5788 - accuracy: 0.6818\n",
      "Epoch 37/104\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.5486 - accuracy: 0.7045\n",
      "Epoch 38/104\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.5548 - accuracy: 0.6818\n",
      "Epoch 39/104\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.5510 - accuracy: 0.6591\n",
      "Epoch 40/104\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.5421 - accuracy: 0.7045\n",
      "Epoch 41/104\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 2.5441 - accuracy: 0.6818\n",
      "Epoch 42/104\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.5071 - accuracy: 0.6818\n",
      "Epoch 43/104\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.5343 - accuracy: 0.6818\n",
      "Epoch 44/104\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.5075 - accuracy: 0.6818\n",
      "Epoch 45/104\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.5240 - accuracy: 0.7045\n",
      "Epoch 46/104\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.4890 - accuracy: 0.6591\n",
      "Epoch 47/104\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.5121 - accuracy: 0.6818\n",
      "Epoch 48/104\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.5447 - accuracy: 0.7273\n",
      "Epoch 49/104\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.4679 - accuracy: 0.7045\n",
      "Epoch 50/104\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.4937 - accuracy: 0.7045\n",
      "Epoch 51/104\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.4614 - accuracy: 0.7273\n",
      "Epoch 52/104\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.5487 - accuracy: 0.7045\n",
      "Epoch 53/104\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.5355 - accuracy: 0.6818\n",
      "Epoch 54/104\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 2.5892 - accuracy: 0.6591\n",
      "Epoch 55/104\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.6222 - accuracy: 0.6591\n",
      "Epoch 56/104\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 2.6780 - accuracy: 0.6591\n",
      "Epoch 57/104\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 2.7357 - accuracy: 0.5909\n",
      "Epoch 58/104\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.7497 - accuracy: 0.6136\n",
      "Epoch 59/104\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.7114 - accuracy: 0.6364\n",
      "Epoch 60/104\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.7058 - accuracy: 0.6364\n",
      "Epoch 61/104\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.7201 - accuracy: 0.6364\n",
      "Epoch 62/104\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.6800 - accuracy: 0.6818\n",
      "Epoch 63/104\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.6963 - accuracy: 0.6136\n",
      "Epoch 64/104\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 2.6516 - accuracy: 0.6136\n",
      "Epoch 65/104\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.6264 - accuracy: 0.6364\n",
      "Epoch 66/104\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 2.6016 - accuracy: 0.7273\n",
      "Epoch 67/104\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.6017 - accuracy: 0.6818\n",
      "Epoch 68/104\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.5788 - accuracy: 0.7045\n",
      "Epoch 69/104\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.5547 - accuracy: 0.7045\n",
      "Epoch 70/104\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.5612 - accuracy: 0.6818\n",
      "Epoch 71/104\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.5243 - accuracy: 0.7045\n",
      "Epoch 72/104\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.5520 - accuracy: 0.6818\n",
      "Epoch 73/104\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.5253 - accuracy: 0.6818\n",
      "Epoch 74/104\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.5160 - accuracy: 0.7273\n",
      "Epoch 75/104\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 2.4910 - accuracy: 0.7273\n",
      "Epoch 76/104\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.4973 - accuracy: 0.7273\n",
      "Epoch 77/104\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.4994 - accuracy: 0.7273\n",
      "Epoch 78/104\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.4787 - accuracy: 0.7273\n",
      "Epoch 79/104\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.5074 - accuracy: 0.6818\n",
      "Epoch 80/104\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.4888 - accuracy: 0.6818\n",
      "Epoch 81/104\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 2.4889 - accuracy: 0.7045\n",
      "Epoch 82/104\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 2.4865 - accuracy: 0.6591\n",
      "Epoch 83/104\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.1851 - accuracy: 0.7045\n",
      "Epoch 84/104\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.4745 - accuracy: 0.7045\n",
      "Epoch 85/104\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.1588 - accuracy: 0.7045\n",
      "Epoch 86/104\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.1787 - accuracy: 0.7273\n",
      "Epoch 87/104\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.1340 - accuracy: 0.7045\n",
      "Epoch 88/104\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.1105 - accuracy: 0.7500\n",
      "Epoch 89/104\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.1100 - accuracy: 0.7273\n",
      "Epoch 90/104\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.1456 - accuracy: 0.7500\n",
      "Epoch 91/104\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.1074 - accuracy: 0.7727\n",
      "Epoch 92/104\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - accuracy: 0.7273\n",
      "Epoch 93/104\n",
      "1/1 [==============================] - 0s 137ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 94/104\n",
      "1/1 [==============================] - 0s 136ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 95/104\n",
      "1/1 [==============================] - 0s 127ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 96/104\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 97/104\n",
      "1/1 [==============================] - 0s 225ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 98/104\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 99/104\n",
      "1/1 [==============================] - 0s 181ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 100/104\n",
      "1/1 [==============================] - 0s 174ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 101/104\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 102/104\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 103/104\n",
      "1/1 [==============================] - 0s 159ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 104/104\n",
      "1/1 [==============================] - 0s 160ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff578b82ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:33:37,647]\u001b[0m Trial 15 finished with value: 0.5 and parameters: {'embedding_output_dim': 101, 'num_epochs': 104}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/54\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.0957 - accuracy: 0.0909\n",
      "Epoch 2/54\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.7530 - accuracy: 0.3636\n",
      "Epoch 3/54\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.7732 - accuracy: 0.3636\n",
      "Epoch 4/54\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.7175 - accuracy: 0.4318\n",
      "Epoch 5/54\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 3.6852 - accuracy: 0.5455\n",
      "Epoch 6/54\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 3.6171 - accuracy: 0.6136\n",
      "Epoch 7/54\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.6463 - accuracy: 0.5909\n",
      "Epoch 8/54\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 3.6188 - accuracy: 0.5000\n",
      "Epoch 9/54\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.6082 - accuracy: 0.5682\n",
      "Epoch 10/54\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 3.5921 - accuracy: 0.6364\n",
      "Epoch 11/54\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 3.5691 - accuracy: 0.6364\n",
      "Epoch 12/54\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.5776 - accuracy: 0.5455\n",
      "Epoch 13/54\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.5641 - accuracy: 0.5455\n",
      "Epoch 14/54\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 3.5553 - accuracy: 0.5227\n",
      "Epoch 15/54\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.5775 - accuracy: 0.4773\n",
      "Epoch 16/54\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 3.5347 - accuracy: 0.5227\n",
      "Epoch 17/54\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 3.5090 - accuracy: 0.5909\n",
      "Epoch 18/54\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.5094 - accuracy: 0.5682\n",
      "Epoch 19/54\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 3.5280 - accuracy: 0.5909\n",
      "Epoch 20/54\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 3.4970 - accuracy: 0.6591\n",
      "Epoch 21/54\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 3.4811 - accuracy: 0.6136\n",
      "Epoch 22/54\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.4779 - accuracy: 0.6591\n",
      "Epoch 23/54\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 3.4856 - accuracy: 0.5682\n",
      "Epoch 24/54\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.4581 - accuracy: 0.5909\n",
      "Epoch 25/54\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.4628 - accuracy: 0.6136\n",
      "Epoch 26/54\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.4569 - accuracy: 0.5455\n",
      "Epoch 27/54\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.4464 - accuracy: 0.5909\n",
      "Epoch 28/54\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.4513 - accuracy: 0.5455\n",
      "Epoch 29/54\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 3.4473 - accuracy: 0.6591\n",
      "Epoch 30/54\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.4191 - accuracy: 0.6591\n",
      "Epoch 31/54\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.4079 - accuracy: 0.6136\n",
      "Epoch 32/54\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 3.4117 - accuracy: 0.6364\n",
      "Epoch 33/54\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 3.3959 - accuracy: 0.6364\n",
      "Epoch 34/54\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 3.3777 - accuracy: 0.6364\n",
      "Epoch 35/54\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 3.4085 - accuracy: 0.6364\n",
      "Epoch 36/54\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 3.3845 - accuracy: 0.6364\n",
      "Epoch 37/54\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 3.3639 - accuracy: 0.6364\n",
      "Epoch 38/54\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.3697 - accuracy: 0.6591\n",
      "Epoch 39/54\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 3.3723 - accuracy: 0.6364\n",
      "Epoch 40/54\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 3.3415 - accuracy: 0.6136\n",
      "Epoch 41/54\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 3.3562 - accuracy: 0.6818\n",
      "Epoch 42/54\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 3.3450 - accuracy: 0.6364\n",
      "Epoch 43/54\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 3.3387 - accuracy: 0.6136\n",
      "Epoch 44/54\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.3174 - accuracy: 0.6364\n",
      "Epoch 45/54\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 3.3129 - accuracy: 0.6136\n",
      "Epoch 46/54\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 3.3017 - accuracy: 0.6136\n",
      "Epoch 47/54\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 3.2653 - accuracy: 0.6364\n",
      "Epoch 48/54\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 3.2816 - accuracy: 0.6364\n",
      "Epoch 49/54\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 3.2690 - accuracy: 0.6364\n",
      "Epoch 50/54\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 3.2652 - accuracy: 0.6136\n",
      "Epoch 51/54\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.2556 - accuracy: 0.6591\n",
      "Epoch 52/54\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.2563 - accuracy: 0.6591\n",
      "Epoch 53/54\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.3084 - accuracy: 0.6136\n",
      "Epoch 54/54\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.2415 - accuracy: 0.7045\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560b8bee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0848 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:33:55,609]\u001b[0m Trial 16 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 44, 'num_epochs': 54}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/36\n",
      "1/1 [==============================] - 9s 9s/step - loss: 5.2284 - accuracy: 0.2727\n",
      "Epoch 2/36\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 3.5557 - accuracy: 0.5455\n",
      "Epoch 3/36\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.3676 - accuracy: 0.4318\n",
      "Epoch 4/36\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 3.0699 - accuracy: 0.4318\n",
      "Epoch 5/36\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.9645 - accuracy: 0.4545\n",
      "Epoch 6/36\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 3.2147 - accuracy: 0.3864\n",
      "Epoch 7/36\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.8675 - accuracy: 0.4773\n",
      "Epoch 8/36\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.1973 - accuracy: 0.4545\n",
      "Epoch 9/36\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.8703 - accuracy: 0.4773\n",
      "Epoch 10/36\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.8305 - accuracy: 0.4318\n",
      "Epoch 11/36\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.7977 - accuracy: 0.5227\n",
      "Epoch 12/36\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.7948 - accuracy: 0.4318\n",
      "Epoch 13/36\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.7612 - accuracy: 0.6136\n",
      "Epoch 14/36\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.7933 - accuracy: 0.5227\n",
      "Epoch 15/36\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.7837 - accuracy: 0.5455\n",
      "Epoch 16/36\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.7388 - accuracy: 0.5909\n",
      "Epoch 17/36\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.7588 - accuracy: 0.4318\n",
      "Epoch 18/36\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.7148 - accuracy: 0.5227\n",
      "Epoch 19/36\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.9809 - accuracy: 0.5909\n",
      "Epoch 20/36\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.4085 - accuracy: 0.4545\n",
      "Epoch 21/36\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.6739 - accuracy: 0.4773\n",
      "Epoch 22/36\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.9893 - accuracy: 0.4545\n",
      "Epoch 23/36\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 2.0055 - accuracy: 0.4773\n",
      "Epoch 24/36\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.0492 - accuracy: 0.4545\n",
      "Epoch 25/36\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.0010 - accuracy: 0.4318\n",
      "Epoch 26/36\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.2548 - accuracy: 0.4318\n",
      "Epoch 27/36\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.9417 - accuracy: 0.5227\n",
      "Epoch 28/36\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 1.9238 - accuracy: 0.4318\n",
      "Epoch 29/36\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.9834 - accuracy: 0.4773\n",
      "Epoch 30/36\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.9332 - accuracy: 0.4773\n",
      "Epoch 31/36\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.9396 - accuracy: 0.4773\n",
      "Epoch 32/36\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.9479 - accuracy: 0.5227\n",
      "Epoch 33/36\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.8511 - accuracy: 0.5909\n",
      "Epoch 34/36\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.9000 - accuracy: 0.5000\n",
      "Epoch 35/36\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.8511 - accuracy: 0.5455\n",
      "Epoch 36/36\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.8571 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff56126f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.4139 - accuracy: 0.6364\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:34:10,730]\u001b[0m Trial 17 finished with value: 0.6363636255264282 and parameters: {'embedding_output_dim': 39, 'num_epochs': 36}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/106\n",
      "1/1 [==============================] - 9s 9s/step - loss: 11.8208 - accuracy: 0.0227\n",
      "Epoch 2/106\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 5.8133 - accuracy: 0.0227\n",
      "Epoch 3/106\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 4.0073 - accuracy: 0.1818\n",
      "Epoch 4/106\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 3.2065 - accuracy: 0.2727\n",
      "Epoch 5/106\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 3.3681 - accuracy: 0.4318\n",
      "Epoch 6/106\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.7825 - accuracy: 0.3864\n",
      "Epoch 7/106\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.6748 - accuracy: 0.4773\n",
      "Epoch 8/106\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.6380 - accuracy: 0.5000\n",
      "Epoch 9/106\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.5412 - accuracy: 0.5455\n",
      "Epoch 10/106\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.5108 - accuracy: 0.5682\n",
      "Epoch 11/106\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.4870 - accuracy: 0.6136\n",
      "Epoch 12/106\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.5026 - accuracy: 0.5909\n",
      "Epoch 13/106\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.4494 - accuracy: 0.6136\n",
      "Epoch 14/106\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.4263 - accuracy: 0.6136\n",
      "Epoch 15/106\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.3960 - accuracy: 0.6136\n",
      "Epoch 16/106\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.3716 - accuracy: 0.6136\n",
      "Epoch 17/106\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.3688 - accuracy: 0.6136\n",
      "Epoch 18/106\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.3140 - accuracy: 0.6136\n",
      "Epoch 19/106\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 2.3103 - accuracy: 0.6364\n",
      "Epoch 20/106\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.0181 - accuracy: 0.6136\n",
      "Epoch 21/106\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.2766 - accuracy: 0.6136\n",
      "Epoch 22/106\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.0333 - accuracy: 0.6136\n",
      "Epoch 23/106\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.9695 - accuracy: 0.6136\n",
      "Epoch 24/106\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.9532 - accuracy: 0.6364\n",
      "Epoch 25/106\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.9321 - accuracy: 0.6136\n",
      "Epoch 26/106\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.9344 - accuracy: 0.6136\n",
      "Epoch 27/106\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.9050 - accuracy: 0.6136\n",
      "Epoch 28/106\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.8861 - accuracy: 0.6136\n",
      "Epoch 29/106\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.8672 - accuracy: 0.6364\n",
      "Epoch 30/106\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.8894 - accuracy: 0.6136\n",
      "Epoch 31/106\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.8536 - accuracy: 0.6364\n",
      "Epoch 32/106\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8418 - accuracy: 0.6364\n",
      "Epoch 33/106\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.8440 - accuracy: 0.6364\n",
      "Epoch 34/106\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8205 - accuracy: 0.6136\n",
      "Epoch 35/106\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8633 - accuracy: 0.6591\n",
      "Epoch 36/106\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.7862 - accuracy: 0.6364\n",
      "Epoch 37/106\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.7966 - accuracy: 0.6136\n",
      "Epoch 38/106\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.7567 - accuracy: 0.6364\n",
      "Epoch 39/106\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.7472 - accuracy: 0.6136\n",
      "Epoch 40/106\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.7399 - accuracy: 0.6364\n",
      "Epoch 41/106\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.7242 - accuracy: 0.6136\n",
      "Epoch 42/106\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.7231 - accuracy: 0.6364\n",
      "Epoch 43/106\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.6991 - accuracy: 0.6364\n",
      "Epoch 44/106\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.6799 - accuracy: 0.6364\n",
      "Epoch 45/106\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.6727 - accuracy: 0.6136\n",
      "Epoch 46/106\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.6675 - accuracy: 0.6136\n",
      "Epoch 47/106\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.6672 - accuracy: 0.6364\n",
      "Epoch 48/106\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.6706 - accuracy: 0.6364\n",
      "Epoch 49/106\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 1.6551 - accuracy: 0.6591\n",
      "Epoch 50/106\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.6318 - accuracy: 0.6591\n",
      "Epoch 51/106\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.6089 - accuracy: 0.6591\n",
      "Epoch 52/106\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.6165 - accuracy: 0.6591\n",
      "Epoch 53/106\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.6121 - accuracy: 0.7045\n",
      "Epoch 54/106\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.6083 - accuracy: 0.6591\n",
      "Epoch 55/106\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.6022 - accuracy: 0.6818\n",
      "Epoch 56/106\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.5955 - accuracy: 0.6591\n",
      "Epoch 57/106\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.5856 - accuracy: 0.6591\n",
      "Epoch 58/106\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 1.5825 - accuracy: 0.6818\n",
      "Epoch 59/106\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.5564 - accuracy: 0.6818\n",
      "Epoch 60/106\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.5573 - accuracy: 0.6591\n",
      "Epoch 61/106\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.5520 - accuracy: 0.7273\n",
      "Epoch 62/106\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.5097 - accuracy: 0.7273\n",
      "Epoch 63/106\n",
      "1/1 [==============================] - 0s 139ms/step - loss: nan - accuracy: 0.6591\n",
      "Epoch 64/106\n",
      "1/1 [==============================] - 0s 178ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/106\n",
      "1/1 [==============================] - 0s 188ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/106\n",
      "1/1 [==============================] - 0s 173ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/106\n",
      "1/1 [==============================] - 0s 252ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/106\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/106\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/106\n",
      "1/1 [==============================] - 0s 180ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/106\n",
      "1/1 [==============================] - 0s 166ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/106\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/106\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/106\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/106\n",
      "1/1 [==============================] - 0s 161ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/106\n",
      "1/1 [==============================] - 0s 140ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/106\n",
      "1/1 [==============================] - 0s 224ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/106\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/106\n",
      "1/1 [==============================] - 0s 207ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/106\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/106\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/106\n",
      "1/1 [==============================] - 0s 179ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/106\n",
      "1/1 [==============================] - 0s 229ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/106\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/106\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/106\n",
      "1/1 [==============================] - 0s 177ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/106\n",
      "1/1 [==============================] - 0s 188ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/106\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/106\n",
      "1/1 [==============================] - 0s 198ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 90/106\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 91/106\n",
      "1/1 [==============================] - 0s 291ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 92/106\n",
      "1/1 [==============================] - 0s 138ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 93/106\n",
      "1/1 [==============================] - 0s 142ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 94/106\n",
      "1/1 [==============================] - 0s 120ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 95/106\n",
      "1/1 [==============================] - 0s 138ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 96/106\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 97/106\n",
      "1/1 [==============================] - 0s 177ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 98/106\n",
      "1/1 [==============================] - 0s 177ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 99/106\n",
      "1/1 [==============================] - 0s 161ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 100/106\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 101/106\n",
      "1/1 [==============================] - 0s 216ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 102/106\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 103/106\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 104/106\n",
      "1/1 [==============================] - 0s 119ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 105/106\n",
      "1/1 [==============================] - 0s 147ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 106/106\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560bff310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:34:39,091]\u001b[0m Trial 18 finished with value: 0.5 and parameters: {'embedding_output_dim': 110, 'num_epochs': 106}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.4672 - accuracy: 0.0455\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 5.4150 - accuracy: 0.4318\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.4206 - accuracy: 0.4318\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.0245 - accuracy: 0.4318\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.9928 - accuracy: 0.4318\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.9213 - accuracy: 0.4545\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 1.8933 - accuracy: 0.4545\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.8523 - accuracy: 0.4773\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.8003 - accuracy: 0.5455\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.8138 - accuracy: 0.4773\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.7687 - accuracy: 0.5000\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.7493 - accuracy: 0.5000\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.7230 - accuracy: 0.5227\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.6836 - accuracy: 0.5227\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.6562 - accuracy: 0.5455\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.6197 - accuracy: 0.5455\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.6131 - accuracy: 0.5682\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.6349 - accuracy: 0.5455\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.5505 - accuracy: 0.6364\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 1.5338 - accuracy: 0.5909\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.5434 - accuracy: 0.5909\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.4932 - accuracy: 0.5909\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.5024 - accuracy: 0.6364\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.4716 - accuracy: 0.6591\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.4319 - accuracy: 0.6591\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.4430 - accuracy: 0.6591\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.4157 - accuracy: 0.6818\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.4041 - accuracy: 0.6818\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.3841 - accuracy: 0.6364\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.3487 - accuracy: 0.7045\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.3387 - accuracy: 0.6818\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.3183 - accuracy: 0.7045\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.3117 - accuracy: 0.7273\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.2834 - accuracy: 0.6818\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.2546 - accuracy: 0.7045\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.2315 - accuracy: 0.7045\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.2393 - accuracy: 0.7045\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.2012 - accuracy: 0.7273\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.5346 - accuracy: 0.6818\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.2018 - accuracy: 0.7045\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.1813 - accuracy: 0.7273\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.1961 - accuracy: 0.6818\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.1839 - accuracy: 0.7727\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.5364 - accuracy: 0.6818\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.1556 - accuracy: 0.7727\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.8142 - accuracy: 0.7273\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 1.0957 - accuracy: 0.7045\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: nan - accuracy: 0.7727\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 233ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 231ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 227ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 276ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 256ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff56083a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:35:03,237]\u001b[0m Trial 19 finished with value: 0.5 and parameters: {'embedding_output_dim': 147, 'num_epochs': 64}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/6\n",
      "1/1 [==============================] - 9s 9s/step - loss: 12.8182 - accuracy: 0.0000e+00\n",
      "Epoch 2/6\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 6.3857 - accuracy: 0.3409\n",
      "Epoch 3/6\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 4.7180 - accuracy: 0.4318\n",
      "Epoch 4/6\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 3.7188 - accuracy: 0.4318\n",
      "Epoch 5/6\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 4.0184 - accuracy: 0.4091\n",
      "Epoch 6/6\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 3.9381 - accuracy: 0.4545\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560e7e040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5646 - accuracy: 0.3182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:35:14,847]\u001b[0m Trial 20 finished with value: 0.3181818127632141 and parameters: {'embedding_output_dim': 61, 'num_epochs': 6}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/96\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.2317 - accuracy: 0.0000e+00\n",
      "Epoch 2/96\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 4.5936 - accuracy: 0.4091\n",
      "Epoch 3/96\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 3.3762 - accuracy: 0.5000\n",
      "Epoch 4/96\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 3.3008 - accuracy: 0.5682\n",
      "Epoch 5/96\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 3.2662 - accuracy: 0.5909\n",
      "Epoch 6/96\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 3.2465 - accuracy: 0.5682\n",
      "Epoch 7/96\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 3.2081 - accuracy: 0.5682\n",
      "Epoch 8/96\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 3.1858 - accuracy: 0.5682\n",
      "Epoch 9/96\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 3.1414 - accuracy: 0.6364\n",
      "Epoch 10/96\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 3.0982 - accuracy: 0.6136\n",
      "Epoch 11/96\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 3.0817 - accuracy: 0.6136\n",
      "Epoch 12/96\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 3.0298 - accuracy: 0.6364\n",
      "Epoch 13/96\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 2.9989 - accuracy: 0.6364\n",
      "Epoch 14/96\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 3.0047 - accuracy: 0.6818\n",
      "Epoch 15/96\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 2.9793 - accuracy: 0.6591\n",
      "Epoch 16/96\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 2.9533 - accuracy: 0.6818\n",
      "Epoch 17/96\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.9417 - accuracy: 0.6818\n",
      "Epoch 18/96\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 2.8980 - accuracy: 0.7045\n",
      "Epoch 19/96\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 2.8798 - accuracy: 0.7045\n",
      "Epoch 20/96\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 2.8925 - accuracy: 0.6591\n",
      "Epoch 21/96\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 2.8808 - accuracy: 0.6364\n",
      "Epoch 22/96\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 2.8498 - accuracy: 0.7273\n",
      "Epoch 23/96\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 2.8285 - accuracy: 0.7500\n",
      "Epoch 24/96\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.8239 - accuracy: 0.7500\n",
      "Epoch 25/96\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 2.8919 - accuracy: 0.7045\n",
      "Epoch 26/96\n",
      "1/1 [==============================] - 0s 230ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 27/96\n",
      "1/1 [==============================] - 0s 256ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 28/96\n",
      "1/1 [==============================] - 0s 271ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 29/96\n",
      "1/1 [==============================] - 0s 283ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 30/96\n",
      "1/1 [==============================] - 0s 328ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 31/96\n",
      "1/1 [==============================] - 0s 294ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 32/96\n",
      "1/1 [==============================] - 0s 313ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 33/96\n",
      "1/1 [==============================] - 0s 366ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 34/96\n",
      "1/1 [==============================] - 0s 280ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 35/96\n",
      "1/1 [==============================] - 0s 364ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 36/96\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 37/96\n",
      "1/1 [==============================] - 0s 330ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 38/96\n",
      "1/1 [==============================] - 0s 279ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/96\n",
      "1/1 [==============================] - 0s 321ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/96\n",
      "1/1 [==============================] - 0s 279ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/96\n",
      "1/1 [==============================] - 0s 317ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/96\n",
      "1/1 [==============================] - 0s 342ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/96\n",
      "1/1 [==============================] - 0s 312ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/96\n",
      "1/1 [==============================] - 0s 256ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/96\n",
      "1/1 [==============================] - 0s 292ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/96\n",
      "1/1 [==============================] - 0s 266ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/96\n",
      "1/1 [==============================] - 0s 238ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/96\n",
      "1/1 [==============================] - 0s 313ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/96\n",
      "1/1 [==============================] - 0s 303ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/96\n",
      "1/1 [==============================] - 0s 280ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/96\n",
      "1/1 [==============================] - 0s 287ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/96\n",
      "1/1 [==============================] - 0s 289ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/96\n",
      "1/1 [==============================] - 0s 362ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/96\n",
      "1/1 [==============================] - 0s 300ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/96\n",
      "1/1 [==============================] - 0s 303ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/96\n",
      "1/1 [==============================] - 0s 284ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/96\n",
      "1/1 [==============================] - 0s 267ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/96\n",
      "1/1 [==============================] - 0s 401ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/96\n",
      "1/1 [==============================] - 0s 263ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/96\n",
      "1/1 [==============================] - 0s 291ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/96\n",
      "1/1 [==============================] - 0s 319ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/96\n",
      "1/1 [==============================] - 0s 331ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/96\n",
      "1/1 [==============================] - 0s 387ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/96\n",
      "1/1 [==============================] - 0s 322ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/96\n",
      "1/1 [==============================] - 0s 329ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/96\n",
      "1/1 [==============================] - 0s 379ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/96\n",
      "1/1 [==============================] - 0s 287ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/96\n",
      "1/1 [==============================] - 0s 351ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/96\n",
      "1/1 [==============================] - 0s 399ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/96\n",
      "1/1 [==============================] - 0s 340ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/96\n",
      "1/1 [==============================] - 0s 294ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/96\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/96\n",
      "1/1 [==============================] - 0s 295ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/96\n",
      "1/1 [==============================] - 0s 377ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/96\n",
      "1/1 [==============================] - 0s 362ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/96\n",
      "1/1 [==============================] - 0s 343ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/96\n",
      "1/1 [==============================] - 0s 469ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/96\n",
      "1/1 [==============================] - 0s 358ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/96\n",
      "1/1 [==============================] - 0s 404ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/96\n",
      "1/1 [==============================] - 0s 361ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/96\n",
      "1/1 [==============================] - 0s 337ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/96\n",
      "1/1 [==============================] - 0s 424ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/96\n",
      "1/1 [==============================] - 0s 364ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/96\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/96\n",
      "1/1 [==============================] - 0s 352ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/96\n",
      "1/1 [==============================] - 0s 282ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/96\n",
      "1/1 [==============================] - 0s 381ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/96\n",
      "1/1 [==============================] - 0s 322ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/96\n",
      "1/1 [==============================] - 0s 331ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 90/96\n",
      "1/1 [==============================] - 0s 318ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 91/96\n",
      "1/1 [==============================] - 0s 373ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 92/96\n",
      "1/1 [==============================] - 0s 387ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 93/96\n",
      "1/1 [==============================] - 0s 415ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 94/96\n",
      "1/1 [==============================] - 0s 441ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 95/96\n",
      "1/1 [==============================] - 0s 466ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 96/96\n",
      "1/1 [==============================] - 0s 361ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8b31a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:35:57,176]\u001b[0m Trial 21 finished with value: 0.5 and parameters: {'embedding_output_dim': 253, 'num_epochs': 96}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/63\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.5103 - accuracy: 0.0227\n",
      "Epoch 2/63\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 3.9131 - accuracy: 0.2273\n",
      "Epoch 3/63\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 3.5366 - accuracy: 0.2955\n",
      "Epoch 4/63\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 2.9008 - accuracy: 0.5455\n",
      "Epoch 5/63\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.7686 - accuracy: 0.4773\n",
      "Epoch 6/63\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 2.6836 - accuracy: 0.5909\n",
      "Epoch 7/63\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 2.6387 - accuracy: 0.6136\n",
      "Epoch 8/63\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.5873 - accuracy: 0.6591\n",
      "Epoch 9/63\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 2.5701 - accuracy: 0.6591\n",
      "Epoch 10/63\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 2.5191 - accuracy: 0.6591\n",
      "Epoch 11/63\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 2.4945 - accuracy: 0.6591\n",
      "Epoch 12/63\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.4644 - accuracy: 0.6364\n",
      "Epoch 13/63\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.4199 - accuracy: 0.6591\n",
      "Epoch 14/63\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.3784 - accuracy: 0.6364\n",
      "Epoch 15/63\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.3473 - accuracy: 0.6591\n",
      "Epoch 16/63\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 2.3365 - accuracy: 0.6364\n",
      "Epoch 17/63\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 2.2939 - accuracy: 0.6591\n",
      "Epoch 18/63\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 2.2904 - accuracy: 0.6364\n",
      "Epoch 19/63\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.2762 - accuracy: 0.6591\n",
      "Epoch 20/63\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.2424 - accuracy: 0.6818\n",
      "Epoch 21/63\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.2367 - accuracy: 0.6591\n",
      "Epoch 22/63\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 2.2308 - accuracy: 0.6818\n",
      "Epoch 23/63\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.2168 - accuracy: 0.6591\n",
      "Epoch 24/63\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.2161 - accuracy: 0.6818\n",
      "Epoch 25/63\n",
      "1/1 [==============================] - 0s 197ms/step - loss: nan - accuracy: 0.6591\n",
      "Epoch 26/63\n",
      "1/1 [==============================] - 0s 145ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 27/63\n",
      "1/1 [==============================] - 0s 250ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 28/63\n",
      "1/1 [==============================] - 0s 187ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 29/63\n",
      "1/1 [==============================] - 0s 211ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 30/63\n",
      "1/1 [==============================] - 0s 178ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 31/63\n",
      "1/1 [==============================] - 0s 213ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 32/63\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 33/63\n",
      "1/1 [==============================] - 0s 232ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 34/63\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 35/63\n",
      "1/1 [==============================] - 0s 203ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 36/63\n",
      "1/1 [==============================] - 0s 194ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 37/63\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 38/63\n",
      "1/1 [==============================] - 0s 193ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/63\n",
      "1/1 [==============================] - 0s 283ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/63\n",
      "1/1 [==============================] - 0s 151ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/63\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/63\n",
      "1/1 [==============================] - 0s 213ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/63\n",
      "1/1 [==============================] - 0s 159ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/63\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/63\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/63\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/63\n",
      "1/1 [==============================] - 0s 173ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/63\n",
      "1/1 [==============================] - 0s 188ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/63\n",
      "1/1 [==============================] - 0s 194ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/63\n",
      "1/1 [==============================] - 0s 198ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/63\n",
      "1/1 [==============================] - 0s 200ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/63\n",
      "1/1 [==============================] - 0s 258ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/63\n",
      "1/1 [==============================] - 0s 181ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/63\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/63\n",
      "1/1 [==============================] - 0s 288ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/63\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/63\n",
      "1/1 [==============================] - 0s 212ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/63\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/63\n",
      "1/1 [==============================] - 0s 211ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/63\n",
      "1/1 [==============================] - 0s 173ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/63\n",
      "1/1 [==============================] - 0s 224ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/63\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/63\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5607b8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:36:21,450]\u001b[0m Trial 22 finished with value: 0.5 and parameters: {'embedding_output_dim': 175, 'num_epochs': 63}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/77\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.4927 - accuracy: 0.0455\n",
      "Epoch 2/77\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 6.6200 - accuracy: 0.4545\n",
      "Epoch 3/77\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 6.4370 - accuracy: 0.4318\n",
      "Epoch 4/77\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 6.4518 - accuracy: 0.4318\n",
      "Epoch 5/77\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 6.1679 - accuracy: 0.4318\n",
      "Epoch 6/77\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 6.1180 - accuracy: 0.4318\n",
      "Epoch 7/77\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 5.6488 - accuracy: 0.4545\n",
      "Epoch 8/77\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 5.4956 - accuracy: 0.4545\n",
      "Epoch 9/77\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 5.5211 - accuracy: 0.4318\n",
      "Epoch 10/77\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 5.5419 - accuracy: 0.4318\n",
      "Epoch 11/77\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 5.5537 - accuracy: 0.4318\n",
      "Epoch 12/77\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 5.5771 - accuracy: 0.4318\n",
      "Epoch 13/77\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 5.5811 - accuracy: 0.4318\n",
      "Epoch 14/77\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 5.5724 - accuracy: 0.4318\n",
      "Epoch 15/77\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 5.5622 - accuracy: 0.4318\n",
      "Epoch 16/77\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 5.5655 - accuracy: 0.4091\n",
      "Epoch 17/77\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 5.5514 - accuracy: 0.4091\n",
      "Epoch 18/77\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 5.5358 - accuracy: 0.4318\n",
      "Epoch 19/77\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.5205 - accuracy: 0.4318\n",
      "Epoch 20/77\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 5.5185 - accuracy: 0.4318\n",
      "Epoch 21/77\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 5.4904 - accuracy: 0.4545\n",
      "Epoch 22/77\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.4888 - accuracy: 0.4545\n",
      "Epoch 23/77\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 5.4860 - accuracy: 0.4545\n",
      "Epoch 24/77\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 5.4717 - accuracy: 0.4318\n",
      "Epoch 25/77\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 5.1997 - accuracy: 0.4545\n",
      "Epoch 26/77\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 5.1231 - accuracy: 0.4318\n",
      "Epoch 27/77\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 5.1148 - accuracy: 0.4773\n",
      "Epoch 28/77\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 5.1097 - accuracy: 0.4773\n",
      "Epoch 29/77\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 5.0901 - accuracy: 0.4773\n",
      "Epoch 30/77\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 4.5599 - accuracy: 0.5000\n",
      "Epoch 31/77\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 3.9507 - accuracy: 0.5000\n",
      "Epoch 32/77\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 3.0071 - accuracy: 0.4545\n",
      "Epoch 33/77\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 2.0537 - accuracy: 0.4773\n",
      "Epoch 34/77\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 1.5683 - accuracy: 0.4091\n",
      "Epoch 35/77\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.5282 - accuracy: 0.3409\n",
      "Epoch 36/77\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.4982 - accuracy: 0.2955\n",
      "Epoch 37/77\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.4769 - accuracy: 0.2955\n",
      "Epoch 38/77\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.4839 - accuracy: 0.2727\n",
      "Epoch 39/77\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.4864 - accuracy: 0.3409\n",
      "Epoch 40/77\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 1.4437 - accuracy: 0.4318\n",
      "Epoch 41/77\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.4617 - accuracy: 0.4091\n",
      "Epoch 42/77\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.4431 - accuracy: 0.4318\n",
      "Epoch 43/77\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.4387 - accuracy: 0.5000\n",
      "Epoch 44/77\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.3925 - accuracy: 0.5455\n",
      "Epoch 45/77\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.3982 - accuracy: 0.5227\n",
      "Epoch 46/77\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.3964 - accuracy: 0.5227\n",
      "Epoch 47/77\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.3688 - accuracy: 0.5682\n",
      "Epoch 48/77\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 1.3423 - accuracy: 0.5682\n",
      "Epoch 49/77\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 1.3394 - accuracy: 0.5682\n",
      "Epoch 50/77\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1.3143 - accuracy: 0.6136\n",
      "Epoch 51/77\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 1.2917 - accuracy: 0.5909\n",
      "Epoch 52/77\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 1.2865 - accuracy: 0.6136\n",
      "Epoch 53/77\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.2552 - accuracy: 0.6136\n",
      "Epoch 54/77\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 1.2339 - accuracy: 0.6591\n",
      "Epoch 55/77\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 1.2127 - accuracy: 0.6591\n",
      "Epoch 56/77\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 1.1727 - accuracy: 0.6818\n",
      "Epoch 57/77\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 1.1691 - accuracy: 0.7045\n",
      "Epoch 58/77\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 1.1470 - accuracy: 0.7273\n",
      "Epoch 59/77\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 1.1124 - accuracy: 0.7045\n",
      "Epoch 60/77\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 1.0919 - accuracy: 0.7273\n",
      "Epoch 61/77\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.0829 - accuracy: 0.7273\n",
      "Epoch 62/77\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 1.0421 - accuracy: 0.7045\n",
      "Epoch 63/77\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 1.0262 - accuracy: 0.7045\n",
      "Epoch 64/77\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.0025 - accuracy: 0.6818\n",
      "Epoch 65/77\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.9686 - accuracy: 0.6818\n",
      "Epoch 66/77\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.9862 - accuracy: 0.7045\n",
      "Epoch 67/77\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.9484 - accuracy: 0.6818\n",
      "Epoch 68/77\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.9236 - accuracy: 0.7045\n",
      "Epoch 69/77\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.9123 - accuracy: 0.7045\n",
      "Epoch 70/77\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.8894 - accuracy: 0.7045\n",
      "Epoch 71/77\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.9186 - accuracy: 0.6591\n",
      "Epoch 72/77\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.2178 - accuracy: 0.7045\n",
      "Epoch 73/77\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 1.2073 - accuracy: 0.6818\n",
      "Epoch 74/77\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 1.2052 - accuracy: 0.6818\n",
      "Epoch 75/77\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.2004 - accuracy: 0.7273\n",
      "Epoch 76/77\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 1.1760 - accuracy: 0.6818\n",
      "Epoch 77/77\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 1.1724 - accuracy: 0.7500\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8b131f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4852 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:36:54,478]\u001b[0m Trial 23 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 212, 'num_epochs': 77}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n",
      "1/1 [==============================] - 9s 9s/step - loss: 11.5415 - accuracy: 0.0227\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 3.3610 - accuracy: 0.3182\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.7425 - accuracy: 0.3636\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.2978 - accuracy: 0.5227\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.9712 - accuracy: 0.5909\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.1678 - accuracy: 0.6136\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.8776 - accuracy: 0.6591\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.8594 - accuracy: 0.6364\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.8144 - accuracy: 0.6591\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.7355 - accuracy: 0.6591\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.7094 - accuracy: 0.6818\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.7300 - accuracy: 0.6136\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.6385 - accuracy: 0.6818\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.6344 - accuracy: 0.6591\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.5938 - accuracy: 0.6364\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.5801 - accuracy: 0.6591\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.5365 - accuracy: 0.6591\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.5135 - accuracy: 0.6591\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.4914 - accuracy: 0.6591\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.4717 - accuracy: 0.6591\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.4826 - accuracy: 0.6364\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.4460 - accuracy: 0.6136\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.4301 - accuracy: 0.6591\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.4239 - accuracy: 0.6591\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.3970 - accuracy: 0.6591\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1.3745 - accuracy: 0.6364\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1.3654 - accuracy: 0.6364\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.3352 - accuracy: 0.6136\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.3325 - accuracy: 0.6136\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.3487 - accuracy: 0.6364\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.3164 - accuracy: 0.6364\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.3235 - accuracy: 0.6364\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.2664 - accuracy: 0.6591\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.2697 - accuracy: 0.6364\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.2665 - accuracy: 0.7045\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.2625 - accuracy: 0.7045\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.2431 - accuracy: 0.6818\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 1.2257 - accuracy: 0.7045\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.2434 - accuracy: 0.6818\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.2300 - accuracy: 0.7273\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c610d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0143 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:37:13,261]\u001b[0m Trial 24 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 159, 'num_epochs': 40}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/24\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.4717 - accuracy: 0.2273\n",
      "Epoch 2/24\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 3.4717 - accuracy: 0.3864\n",
      "Epoch 3/24\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 3.1093 - accuracy: 0.5227\n",
      "Epoch 4/24\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 2.7742 - accuracy: 0.6591\n",
      "Epoch 5/24\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.7003 - accuracy: 0.6818\n",
      "Epoch 6/24\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.6245 - accuracy: 0.6364\n",
      "Epoch 7/24\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.6044 - accuracy: 0.6136\n",
      "Epoch 8/24\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.6140 - accuracy: 0.6136\n",
      "Epoch 9/24\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.5873 - accuracy: 0.5909\n",
      "Epoch 10/24\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.5954 - accuracy: 0.5682\n",
      "Epoch 11/24\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.5491 - accuracy: 0.5682\n",
      "Epoch 12/24\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 2.4856 - accuracy: 0.6136\n",
      "Epoch 13/24\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.4842 - accuracy: 0.5909\n",
      "Epoch 14/24\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.4670 - accuracy: 0.6136\n",
      "Epoch 15/24\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.4466 - accuracy: 0.5909\n",
      "Epoch 16/24\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.4522 - accuracy: 0.5909\n",
      "Epoch 17/24\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.4163 - accuracy: 0.6364\n",
      "Epoch 18/24\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.3878 - accuracy: 0.6364\n",
      "Epoch 19/24\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.3912 - accuracy: 0.6364\n",
      "Epoch 20/24\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.3579 - accuracy: 0.6364\n",
      "Epoch 21/24\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.3350 - accuracy: 0.6591\n",
      "Epoch 22/24\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2.3421 - accuracy: 0.6364\n",
      "Epoch 23/24\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 2.3129 - accuracy: 0.6364\n",
      "Epoch 24/24\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 2.2762 - accuracy: 0.6591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5613483a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.1057 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:37:29,609]\u001b[0m Trial 25 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 159, 'num_epochs': 24}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/59\n",
      "1/1 [==============================] - 9s 9s/step - loss: 6.0758 - accuracy: 0.0682\n",
      "Epoch 2/59\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 4.0215 - accuracy: 0.2500\n",
      "Epoch 3/59\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 4.1479 - accuracy: 0.2500\n",
      "Epoch 4/59\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 3.7729 - accuracy: 0.3182\n",
      "Epoch 5/59\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 3.7092 - accuracy: 0.2727\n",
      "Epoch 6/59\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 3.6751 - accuracy: 0.3636\n",
      "Epoch 7/59\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 3.6140 - accuracy: 0.4318\n",
      "Epoch 8/59\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 3.5961 - accuracy: 0.4545\n",
      "Epoch 9/59\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 3.5309 - accuracy: 0.5000\n",
      "Epoch 10/59\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 3.4691 - accuracy: 0.5227\n",
      "Epoch 11/59\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 3.4795 - accuracy: 0.4773\n",
      "Epoch 12/59\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 3.4134 - accuracy: 0.6591\n",
      "Epoch 13/59\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 3.4014 - accuracy: 0.6136\n",
      "Epoch 14/59\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 3.3647 - accuracy: 0.6136\n",
      "Epoch 15/59\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 3.3152 - accuracy: 0.6364\n",
      "Epoch 16/59\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 3.2863 - accuracy: 0.6591\n",
      "Epoch 17/59\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 3.2896 - accuracy: 0.6136\n",
      "Epoch 18/59\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 3.2467 - accuracy: 0.6364\n",
      "Epoch 19/59\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 3.2451 - accuracy: 0.6591\n",
      "Epoch 20/59\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 3.2315 - accuracy: 0.6364\n",
      "Epoch 21/59\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 3.2111 - accuracy: 0.6591\n",
      "Epoch 22/59\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 3.2164 - accuracy: 0.6364\n",
      "Epoch 23/59\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 3.1980 - accuracy: 0.6364\n",
      "Epoch 24/59\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 3.1948 - accuracy: 0.6364\n",
      "Epoch 25/59\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 3.1752 - accuracy: 0.6364\n",
      "Epoch 26/59\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 3.1929 - accuracy: 0.6136\n",
      "Epoch 27/59\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 3.1723 - accuracy: 0.6364\n",
      "Epoch 28/59\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 3.1415 - accuracy: 0.6591\n",
      "Epoch 29/59\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 3.1462 - accuracy: 0.6591\n",
      "Epoch 30/59\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 3.1532 - accuracy: 0.6364\n",
      "Epoch 31/59\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 3.1455 - accuracy: 0.6364\n",
      "Epoch 32/59\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 3.1239 - accuracy: 0.6136\n",
      "Epoch 33/59\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 3.1094 - accuracy: 0.6591\n",
      "Epoch 34/59\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 3.1120 - accuracy: 0.6364\n",
      "Epoch 35/59\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 3.1118 - accuracy: 0.6591\n",
      "Epoch 36/59\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 3.0824 - accuracy: 0.6591\n",
      "Epoch 37/59\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 3.0798 - accuracy: 0.6818\n",
      "Epoch 38/59\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 3.0625 - accuracy: 0.6591\n",
      "Epoch 39/59\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 3.0525 - accuracy: 0.6591\n",
      "Epoch 40/59\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 3.0533 - accuracy: 0.6591\n",
      "Epoch 41/59\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 3.0373 - accuracy: 0.6591\n",
      "Epoch 42/59\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 3.0600 - accuracy: 0.6591\n",
      "Epoch 43/59\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 3.0218 - accuracy: 0.6364\n",
      "Epoch 44/59\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 3.0236 - accuracy: 0.6591\n",
      "Epoch 45/59\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 2.8156 - accuracy: 0.6364\n",
      "Epoch 46/59\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 2.7086 - accuracy: 0.6591\n",
      "Epoch 47/59\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.1731 - accuracy: 0.6364\n",
      "Epoch 48/59\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1.8593 - accuracy: 0.5909\n",
      "Epoch 49/59\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 1.8642 - accuracy: 0.5682\n",
      "Epoch 50/59\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.8723 - accuracy: 0.5227\n",
      "Epoch 51/59\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.9338 - accuracy: 0.5455\n",
      "Epoch 52/59\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.9260 - accuracy: 0.5455\n",
      "Epoch 53/59\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.9770 - accuracy: 0.5455\n",
      "Epoch 54/59\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.9860 - accuracy: 0.4773\n",
      "Epoch 55/59\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.9610 - accuracy: 0.5000\n",
      "Epoch 56/59\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.9626 - accuracy: 0.4773\n",
      "Epoch 57/59\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 1.9898 - accuracy: 0.5455\n",
      "Epoch 58/59\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.9804 - accuracy: 0.5227\n",
      "Epoch 59/59\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.9533 - accuracy: 0.5682\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560cabd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2489 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:37:58,039]\u001b[0m Trial 26 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 200, 'num_epochs': 59}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/47\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.0140 - accuracy: 0.1364\n",
      "Epoch 2/47\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 3.3287 - accuracy: 0.0909\n",
      "Epoch 3/47\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 3.2080 - accuracy: 0.2045\n",
      "Epoch 4/47\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 2.8411 - accuracy: 0.2045\n",
      "Epoch 5/47\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 2.8118 - accuracy: 0.2045\n",
      "Epoch 6/47\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 2.7448 - accuracy: 0.2500\n",
      "Epoch 7/47\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.7057 - accuracy: 0.2955\n",
      "Epoch 8/47\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 2.6844 - accuracy: 0.3409\n",
      "Epoch 9/47\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 2.6665 - accuracy: 0.4773\n",
      "Epoch 10/47\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.6519 - accuracy: 0.3636\n",
      "Epoch 11/47\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.5979 - accuracy: 0.4545\n",
      "Epoch 12/47\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 2.5762 - accuracy: 0.4773\n",
      "Epoch 13/47\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 2.5531 - accuracy: 0.5227\n",
      "Epoch 14/47\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.4865 - accuracy: 0.5682\n",
      "Epoch 15/47\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 2.4605 - accuracy: 0.5227\n",
      "Epoch 16/47\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 2.4339 - accuracy: 0.5682\n",
      "Epoch 17/47\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 2.3954 - accuracy: 0.5682\n",
      "Epoch 18/47\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 2.3962 - accuracy: 0.6136\n",
      "Epoch 19/47\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 2.3338 - accuracy: 0.6136\n",
      "Epoch 20/47\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 2.3176 - accuracy: 0.6136\n",
      "Epoch 21/47\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 2.3043 - accuracy: 0.6136\n",
      "Epoch 22/47\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.2666 - accuracy: 0.6136\n",
      "Epoch 23/47\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 2.2674 - accuracy: 0.6136\n",
      "Epoch 24/47\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 2.2592 - accuracy: 0.6136\n",
      "Epoch 25/47\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 2.2422 - accuracy: 0.6136\n",
      "Epoch 26/47\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 2.2217 - accuracy: 0.6136\n",
      "Epoch 27/47\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 2.4865 - accuracy: 0.6364\n",
      "Epoch 28/47\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 2.2307 - accuracy: 0.6364\n",
      "Epoch 29/47\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 2.1652 - accuracy: 0.6364\n",
      "Epoch 30/47\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 2.1605 - accuracy: 0.6364\n",
      "Epoch 31/47\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 2.1172 - accuracy: 0.6364\n",
      "Epoch 32/47\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 2.1081 - accuracy: 0.6364\n",
      "Epoch 33/47\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 2.1009 - accuracy: 0.6364\n",
      "Epoch 34/47\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 2.0917 - accuracy: 0.6364\n",
      "Epoch 35/47\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 2.0508 - accuracy: 0.6364\n",
      "Epoch 36/47\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 2.0403 - accuracy: 0.6818\n",
      "Epoch 37/47\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 2.0220 - accuracy: 0.6591\n",
      "Epoch 38/47\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 1.9961 - accuracy: 0.6364\n",
      "Epoch 39/47\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 1.9746 - accuracy: 0.6591\n",
      "Epoch 40/47\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 1.9867 - accuracy: 0.6591\n",
      "Epoch 41/47\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.9807 - accuracy: 0.6364\n",
      "Epoch 42/47\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 1.9617 - accuracy: 0.6364\n",
      "Epoch 43/47\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.9319 - accuracy: 0.6818\n",
      "Epoch 44/47\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 1.9330 - accuracy: 0.6591\n",
      "Epoch 45/47\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.9185 - accuracy: 0.6591\n",
      "Epoch 46/47\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.8997 - accuracy: 0.6591\n",
      "Epoch 47/47\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 1.8967 - accuracy: 0.6818\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8bee940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3813 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:38:24,714]\u001b[0m Trial 27 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 255, 'num_epochs': 47}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/41\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.0703 - accuracy: 0.0909\n",
      "Epoch 2/41\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 4.9255 - accuracy: 0.2045\n",
      "Epoch 3/41\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.3021 - accuracy: 0.2273\n",
      "Epoch 4/41\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.8200 - accuracy: 0.3182\n",
      "Epoch 5/41\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.2787 - accuracy: 0.3636\n",
      "Epoch 6/41\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.9714 - accuracy: 0.3409\n",
      "Epoch 7/41\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.9679 - accuracy: 0.3864\n",
      "Epoch 8/41\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.7293 - accuracy: 0.4091\n",
      "Epoch 9/41\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 3.0067 - accuracy: 0.4318\n",
      "Epoch 10/41\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.7524 - accuracy: 0.4318\n",
      "Epoch 11/41\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.7119 - accuracy: 0.4318\n",
      "Epoch 12/41\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.6873 - accuracy: 0.4318\n",
      "Epoch 13/41\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 2.6836 - accuracy: 0.4318\n",
      "Epoch 14/41\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 2.6495 - accuracy: 0.4773\n",
      "Epoch 15/41\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.6839 - accuracy: 0.5000\n",
      "Epoch 16/41\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.6444 - accuracy: 0.5000\n",
      "Epoch 17/41\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.6444 - accuracy: 0.5227\n",
      "Epoch 18/41\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.6219 - accuracy: 0.5000\n",
      "Epoch 19/41\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.5997 - accuracy: 0.4773\n",
      "Epoch 20/41\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 2.6068 - accuracy: 0.4773\n",
      "Epoch 21/41\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.6231 - accuracy: 0.4545\n",
      "Epoch 22/41\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.5524 - accuracy: 0.4773\n",
      "Epoch 23/41\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.5644 - accuracy: 0.5000\n",
      "Epoch 24/41\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.5305 - accuracy: 0.5909\n",
      "Epoch 25/41\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.5039 - accuracy: 0.6136\n",
      "Epoch 26/41\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.5131 - accuracy: 0.5909\n",
      "Epoch 27/41\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.4808 - accuracy: 0.6364\n",
      "Epoch 28/41\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.4225 - accuracy: 0.6364\n",
      "Epoch 29/41\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.4423 - accuracy: 0.6364\n",
      "Epoch 30/41\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.4124 - accuracy: 0.6364\n",
      "Epoch 31/41\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.4032 - accuracy: 0.6364\n",
      "Epoch 32/41\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.3966 - accuracy: 0.6136\n",
      "Epoch 33/41\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.3644 - accuracy: 0.6591\n",
      "Epoch 34/41\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.3605 - accuracy: 0.6364\n",
      "Epoch 35/41\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.3172 - accuracy: 0.6591\n",
      "Epoch 36/41\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 2.3304 - accuracy: 0.6591\n",
      "Epoch 37/41\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.3260 - accuracy: 0.6591\n",
      "Epoch 38/41\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.2932 - accuracy: 0.6364\n",
      "Epoch 39/41\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.2862 - accuracy: 0.6591\n",
      "Epoch 40/41\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.2653 - accuracy: 0.6591\n",
      "Epoch 41/41\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.2928 - accuracy: 0.6136\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8d5c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.5695 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:38:41,798]\u001b[0m Trial 28 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 104, 'num_epochs': 41}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/19\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.1210 - accuracy: 0.0227\n",
      "Epoch 2/19\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 2.3804 - accuracy: 0.5227\n",
      "Epoch 3/19\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 1.6762 - accuracy: 0.5455\n",
      "Epoch 4/19\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.6111 - accuracy: 0.5227\n",
      "Epoch 5/19\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 1.5683 - accuracy: 0.5227\n",
      "Epoch 6/19\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 1.5846 - accuracy: 0.5455\n",
      "Epoch 7/19\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 1.5444 - accuracy: 0.5682\n",
      "Epoch 8/19\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 1.5214 - accuracy: 0.5682\n",
      "Epoch 9/19\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.5007 - accuracy: 0.5909\n",
      "Epoch 10/19\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.4878 - accuracy: 0.5909\n",
      "Epoch 11/19\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 1.4470 - accuracy: 0.5909\n",
      "Epoch 12/19\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.4208 - accuracy: 0.6136\n",
      "Epoch 13/19\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 1.3714 - accuracy: 0.6136\n",
      "Epoch 14/19\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.3506 - accuracy: 0.6136\n",
      "Epoch 15/19\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 1.3194 - accuracy: 0.6136\n",
      "Epoch 16/19\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 1.3080 - accuracy: 0.6136\n",
      "Epoch 17/19\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 1.2678 - accuracy: 0.6364\n",
      "Epoch 18/19\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.2349 - accuracy: 0.6136\n",
      "Epoch 19/19\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.2028 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5700f0670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1393 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:38:59,157]\u001b[0m Trial 29 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 256, 'num_epochs': 19}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/89\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.7244 - accuracy: 0.0227\n",
      "Epoch 2/89\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 3.1754 - accuracy: 0.4318\n",
      "Epoch 3/89\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.2265 - accuracy: 0.5227\n",
      "Epoch 4/89\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.8639 - accuracy: 0.6364\n",
      "Epoch 5/89\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.7520 - accuracy: 0.6136\n",
      "Epoch 6/89\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.2296 - accuracy: 0.6364\n",
      "Epoch 7/89\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.5502 - accuracy: 0.6364\n",
      "Epoch 8/89\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.7739 - accuracy: 0.5455\n",
      "Epoch 9/89\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.7889 - accuracy: 0.6136\n",
      "Epoch 10/89\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.8087 - accuracy: 0.5000\n",
      "Epoch 11/89\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.4722 - accuracy: 0.5227\n",
      "Epoch 12/89\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.4516 - accuracy: 0.5227\n",
      "Epoch 13/89\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.5211 - accuracy: 0.5227\n",
      "Epoch 14/89\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.4438 - accuracy: 0.5227\n",
      "Epoch 15/89\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.4596 - accuracy: 0.4773\n",
      "Epoch 16/89\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.4296 - accuracy: 0.5455\n",
      "Epoch 17/89\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.4140 - accuracy: 0.5455\n",
      "Epoch 18/89\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 1.3890 - accuracy: 0.5909\n",
      "Epoch 19/89\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.3586 - accuracy: 0.5682\n",
      "Epoch 20/89\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.2930 - accuracy: 0.6136\n",
      "Epoch 21/89\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.3252 - accuracy: 0.6364\n",
      "Epoch 22/89\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.2837 - accuracy: 0.6591\n",
      "Epoch 23/89\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.2883 - accuracy: 0.6364\n",
      "Epoch 24/89\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.2144 - accuracy: 0.6364\n",
      "Epoch 25/89\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.2104 - accuracy: 0.6591\n",
      "Epoch 26/89\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.1742 - accuracy: 0.6364\n",
      "Epoch 27/89\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.1757 - accuracy: 0.6136\n",
      "Epoch 28/89\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.1311 - accuracy: 0.6136\n",
      "Epoch 29/89\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.1200 - accuracy: 0.6591\n",
      "Epoch 30/89\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.1146 - accuracy: 0.6364\n",
      "Epoch 31/89\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.1129 - accuracy: 0.6364\n",
      "Epoch 32/89\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 1.0561 - accuracy: 0.6136\n",
      "Epoch 33/89\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.0317 - accuracy: 0.6591\n",
      "Epoch 34/89\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.0469 - accuracy: 0.6591\n",
      "Epoch 35/89\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.0275 - accuracy: 0.6591\n",
      "Epoch 36/89\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.0188 - accuracy: 0.6818\n",
      "Epoch 37/89\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9854 - accuracy: 0.6818\n",
      "Epoch 38/89\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9924 - accuracy: 0.6818\n",
      "Epoch 39/89\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.9750 - accuracy: 0.6364\n",
      "Epoch 40/89\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9646 - accuracy: 0.6364\n",
      "Epoch 41/89\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9559 - accuracy: 0.6364\n",
      "Epoch 42/89\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9537 - accuracy: 0.7045\n",
      "Epoch 43/89\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9457 - accuracy: 0.6591\n",
      "Epoch 44/89\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9468 - accuracy: 0.6818\n",
      "Epoch 45/89\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9078 - accuracy: 0.7045\n",
      "Epoch 46/89\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9099 - accuracy: 0.7045\n",
      "Epoch 47/89\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8622 - accuracy: 0.7045\n",
      "Epoch 48/89\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8799 - accuracy: 0.6818\n",
      "Epoch 49/89\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9054 - accuracy: 0.6591\n",
      "Epoch 50/89\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9021 - accuracy: 0.7273\n",
      "Epoch 51/89\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.8285 - accuracy: 0.7045\n",
      "Epoch 52/89\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.2384 - accuracy: 0.7045\n",
      "Epoch 53/89\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8970 - accuracy: 0.7273\n",
      "Epoch 54/89\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.2558 - accuracy: 0.6591\n",
      "Epoch 55/89\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9305 - accuracy: 0.7727\n",
      "Epoch 56/89\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9386 - accuracy: 0.7500\n",
      "Epoch 57/89\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.9216 - accuracy: 0.6818\n",
      "Epoch 58/89\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.9478 - accuracy: 0.6364\n",
      "Epoch 59/89\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.9274 - accuracy: 0.6364\n",
      "Epoch 60/89\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9041 - accuracy: 0.7273\n",
      "Epoch 61/89\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9079 - accuracy: 0.7045\n",
      "Epoch 62/89\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8662 - accuracy: 0.7273\n",
      "Epoch 63/89\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.8489 - accuracy: 0.7045\n",
      "Epoch 64/89\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.8481 - accuracy: 0.7273\n",
      "Epoch 65/89\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8054 - accuracy: 0.7500\n",
      "Epoch 66/89\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8140 - accuracy: 0.7955\n",
      "Epoch 67/89\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.4928 - accuracy: 0.6818\n",
      "Epoch 68/89\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7938 - accuracy: 0.7273\n",
      "Epoch 69/89\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.1586 - accuracy: 0.6818\n",
      "Epoch 70/89\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.4670 - accuracy: 0.7500\n",
      "Epoch 71/89\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.1418 - accuracy: 0.7955\n",
      "Epoch 72/89\n",
      "1/1 [==============================] - 0s 181ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 73/89\n",
      "1/1 [==============================] - 0s 149ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/89\n",
      "1/1 [==============================] - 0s 136ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/89\n",
      "1/1 [==============================] - 0s 136ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/89\n",
      "1/1 [==============================] - 0s 206ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/89\n",
      "1/1 [==============================] - 0s 94ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/89\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/89\n",
      "1/1 [==============================] - 0s 93ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/89\n",
      "1/1 [==============================] - 0s 173ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/89\n",
      "1/1 [==============================] - 0s 255ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/89\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/89\n",
      "1/1 [==============================] - 0s 126ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/89\n",
      "1/1 [==============================] - 0s 160ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/89\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/89\n",
      "1/1 [==============================] - 0s 154ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/89\n",
      "1/1 [==============================] - 0s 159ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/89\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/89\n",
      "1/1 [==============================] - 0s 145ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560e2fc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:39:24,043]\u001b[0m Trial 30 finished with value: 0.5 and parameters: {'embedding_output_dim': 86, 'num_epochs': 89}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/46\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.8072 - accuracy: 0.1364\n",
      "Epoch 2/46\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 5.0996 - accuracy: 0.4318\n",
      "Epoch 3/46\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 4.6359 - accuracy: 0.3182\n",
      "Epoch 4/46\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 4.3476 - accuracy: 0.3182\n",
      "Epoch 5/46\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.0430 - accuracy: 0.3182\n",
      "Epoch 6/46\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.7277 - accuracy: 0.3182\n",
      "Epoch 7/46\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 4.0442 - accuracy: 0.3182\n",
      "Epoch 8/46\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 3.9902 - accuracy: 0.3182\n",
      "Epoch 9/46\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.6767 - accuracy: 0.3182\n",
      "Epoch 10/46\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 3.7559 - accuracy: 0.3182\n",
      "Epoch 11/46\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.6457 - accuracy: 0.3182\n",
      "Epoch 12/46\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 3.6101 - accuracy: 0.3409\n",
      "Epoch 13/46\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 3.6206 - accuracy: 0.3182\n",
      "Epoch 14/46\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 3.5320 - accuracy: 0.3182\n",
      "Epoch 15/46\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 3.5641 - accuracy: 0.3409\n",
      "Epoch 16/46\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.5069 - accuracy: 0.3636\n",
      "Epoch 17/46\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 3.4877 - accuracy: 0.4318\n",
      "Epoch 18/46\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 3.4576 - accuracy: 0.4545\n",
      "Epoch 19/46\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 3.3205 - accuracy: 0.3864\n",
      "Epoch 20/46\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 3.4433 - accuracy: 0.4318\n",
      "Epoch 21/46\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 3.1290 - accuracy: 0.4545\n",
      "Epoch 22/46\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.3069 - accuracy: 0.4545\n",
      "Epoch 23/46\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.1793 - accuracy: 0.4545\n",
      "Epoch 24/46\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.1788 - accuracy: 0.4773\n",
      "Epoch 25/46\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.1633 - accuracy: 0.4773\n",
      "Epoch 26/46\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.1741 - accuracy: 0.5000\n",
      "Epoch 27/46\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.2038 - accuracy: 0.5682\n",
      "Epoch 28/46\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.1488 - accuracy: 0.5000\n",
      "Epoch 29/46\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.1490 - accuracy: 0.5000\n",
      "Epoch 30/46\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.1225 - accuracy: 0.5227\n",
      "Epoch 31/46\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.1286 - accuracy: 0.5227\n",
      "Epoch 32/46\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.1411 - accuracy: 0.4773\n",
      "Epoch 33/46\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.1173 - accuracy: 0.5455\n",
      "Epoch 34/46\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.1449 - accuracy: 0.5682\n",
      "Epoch 35/46\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.1297 - accuracy: 0.5455\n",
      "Epoch 36/46\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.1271 - accuracy: 0.5455\n",
      "Epoch 37/46\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.0863 - accuracy: 0.6136\n",
      "Epoch 38/46\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 2.1119 - accuracy: 0.5455\n",
      "Epoch 39/46\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.1053 - accuracy: 0.5227\n",
      "Epoch 40/46\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0774 - accuracy: 0.5909\n",
      "Epoch 41/46\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.0899 - accuracy: 0.5682\n",
      "Epoch 42/46\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0623 - accuracy: 0.5909\n",
      "Epoch 43/46\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.0661 - accuracy: 0.6136\n",
      "Epoch 44/46\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.0427 - accuracy: 0.5682\n",
      "Epoch 45/46\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.0460 - accuracy: 0.6136\n",
      "Epoch 46/46\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.0261 - accuracy: 0.5909\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff561370c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4433 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:39:42,471]\u001b[0m Trial 31 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 111, 'num_epochs': 46}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/34\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.4184 - accuracy: 0.0909\n",
      "Epoch 2/34\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 3.4332 - accuracy: 0.3864\n",
      "Epoch 3/34\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 3.8223 - accuracy: 0.5909\n",
      "Epoch 4/34\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 3.1354 - accuracy: 0.5909\n",
      "Epoch 5/34\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 3.1313 - accuracy: 0.5682\n",
      "Epoch 6/34\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 3.1339 - accuracy: 0.6136\n",
      "Epoch 7/34\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 3.1726 - accuracy: 0.5682\n",
      "Epoch 8/34\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.5439 - accuracy: 0.5682\n",
      "Epoch 9/34\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.5905 - accuracy: 0.6136\n",
      "Epoch 10/34\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.5753 - accuracy: 0.5000\n",
      "Epoch 11/34\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.5115 - accuracy: 0.5455\n",
      "Epoch 12/34\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.4858 - accuracy: 0.4773\n",
      "Epoch 13/34\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.4781 - accuracy: 0.5000\n",
      "Epoch 14/34\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.4474 - accuracy: 0.5682\n",
      "Epoch 15/34\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.4801 - accuracy: 0.5909\n",
      "Epoch 16/34\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.4173 - accuracy: 0.5682\n",
      "Epoch 17/34\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.3915 - accuracy: 0.5909\n",
      "Epoch 18/34\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.3528 - accuracy: 0.6364\n",
      "Epoch 19/34\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.3289 - accuracy: 0.6364\n",
      "Epoch 20/34\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.3183 - accuracy: 0.6591\n",
      "Epoch 21/34\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.2766 - accuracy: 0.6136\n",
      "Epoch 22/34\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.2535 - accuracy: 0.6364\n",
      "Epoch 23/34\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.2346 - accuracy: 0.6591\n",
      "Epoch 24/34\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.2135 - accuracy: 0.6364\n",
      "Epoch 25/34\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.2205 - accuracy: 0.6364\n",
      "Epoch 26/34\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.1950 - accuracy: 0.6591\n",
      "Epoch 27/34\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.1711 - accuracy: 0.6364\n",
      "Epoch 28/34\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.1780 - accuracy: 0.6591\n",
      "Epoch 29/34\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.1390 - accuracy: 0.6364\n",
      "Epoch 30/34\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.1633 - accuracy: 0.6591\n",
      "Epoch 31/34\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.1496 - accuracy: 0.6136\n",
      "Epoch 32/34\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.1302 - accuracy: 0.6364\n",
      "Epoch 33/34\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.1326 - accuracy: 0.6364\n",
      "Epoch 34/34\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.0825 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560a61820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.2922 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:39:58,480]\u001b[0m Trial 32 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 98, 'num_epochs': 34}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/44\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.7535 - accuracy: 0.0909\n",
      "Epoch 2/44\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 4.9623 - accuracy: 0.2045\n",
      "Epoch 3/44\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 3.0160 - accuracy: 0.0909\n",
      "Epoch 4/44\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.8356 - accuracy: 0.0909\n",
      "Epoch 5/44\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.7157 - accuracy: 0.0909\n",
      "Epoch 6/44\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.4174 - accuracy: 0.0909\n",
      "Epoch 7/44\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.4211 - accuracy: 0.0909\n",
      "Epoch 8/44\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.5927 - accuracy: 0.0909\n",
      "Epoch 9/44\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.3671 - accuracy: 0.0909\n",
      "Epoch 10/44\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.3209 - accuracy: 0.0909\n",
      "Epoch 11/44\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.2431 - accuracy: 0.1136\n",
      "Epoch 12/44\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.2481 - accuracy: 0.0909\n",
      "Epoch 13/44\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.2499 - accuracy: 0.1136\n",
      "Epoch 14/44\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 2.2313 - accuracy: 0.0909\n",
      "Epoch 15/44\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.2166 - accuracy: 0.0909\n",
      "Epoch 16/44\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 2.1759 - accuracy: 0.0909\n",
      "Epoch 17/44\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.2090 - accuracy: 0.1136\n",
      "Epoch 18/44\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.1381 - accuracy: 0.1364\n",
      "Epoch 19/44\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.1407 - accuracy: 0.2500\n",
      "Epoch 20/44\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.1329 - accuracy: 0.1591\n",
      "Epoch 21/44\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.1255 - accuracy: 0.2045\n",
      "Epoch 22/44\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.0930 - accuracy: 0.2273\n",
      "Epoch 23/44\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.1103 - accuracy: 0.2273\n",
      "Epoch 24/44\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.0803 - accuracy: 0.2500\n",
      "Epoch 25/44\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.0438 - accuracy: 0.2727\n",
      "Epoch 26/44\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0695 - accuracy: 0.2955\n",
      "Epoch 27/44\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.0588 - accuracy: 0.2500\n",
      "Epoch 28/44\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0315 - accuracy: 0.2955\n",
      "Epoch 29/44\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0052 - accuracy: 0.2727\n",
      "Epoch 30/44\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.9993 - accuracy: 0.2727\n",
      "Epoch 31/44\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.0180 - accuracy: 0.3864\n",
      "Epoch 32/44\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.9777 - accuracy: 0.3864\n",
      "Epoch 33/44\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.9623 - accuracy: 0.3409\n",
      "Epoch 34/44\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.9647 - accuracy: 0.3636\n",
      "Epoch 35/44\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.9565 - accuracy: 0.4091\n",
      "Epoch 36/44\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.9012 - accuracy: 0.4773\n",
      "Epoch 37/44\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.9378 - accuracy: 0.4318\n",
      "Epoch 38/44\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.9138 - accuracy: 0.4773\n",
      "Epoch 39/44\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.8886 - accuracy: 0.5000\n",
      "Epoch 40/44\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.8992 - accuracy: 0.4318\n",
      "Epoch 41/44\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.8951 - accuracy: 0.4545\n",
      "Epoch 42/44\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.8577 - accuracy: 0.4773\n",
      "Epoch 43/44\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.8678 - accuracy: 0.4318\n",
      "Epoch 44/44\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.8722 - accuracy: 0.4318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560d6dc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.6935 - accuracy: 0.6364\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:40:18,158]\u001b[0m Trial 33 finished with value: 0.6363636255264282 and parameters: {'embedding_output_dim': 139, 'num_epochs': 44}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/54\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.5147 - accuracy: 0.1818\n",
      "Epoch 2/54\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.9927 - accuracy: 0.5227\n",
      "Epoch 3/54\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 3.0686 - accuracy: 0.6364\n",
      "Epoch 4/54\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 3.6396 - accuracy: 0.6591\n",
      "Epoch 5/54\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 3.3911 - accuracy: 0.6591\n",
      "Epoch 6/54\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3.3607 - accuracy: 0.6818\n",
      "Epoch 7/54\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 3.0583 - accuracy: 0.6591\n",
      "Epoch 8/54\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 3.3079 - accuracy: 0.6364\n",
      "Epoch 9/54\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.3266 - accuracy: 0.6818\n",
      "Epoch 10/54\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.9882 - accuracy: 0.6591\n",
      "Epoch 11/54\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.7006 - accuracy: 0.6364\n",
      "Epoch 12/54\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.4266 - accuracy: 0.5909\n",
      "Epoch 13/54\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.3699 - accuracy: 0.6364\n",
      "Epoch 14/54\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.3743 - accuracy: 0.6591\n",
      "Epoch 15/54\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.2601 - accuracy: 0.6591\n",
      "Epoch 16/54\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.2553 - accuracy: 0.6364\n",
      "Epoch 17/54\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.2393 - accuracy: 0.6591\n",
      "Epoch 18/54\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.2528 - accuracy: 0.6591\n",
      "Epoch 19/54\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.2279 - accuracy: 0.6591\n",
      "Epoch 20/54\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.1989 - accuracy: 0.6591\n",
      "Epoch 21/54\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.1989 - accuracy: 0.6591\n",
      "Epoch 22/54\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.1905 - accuracy: 0.6591\n",
      "Epoch 23/54\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 2.1519 - accuracy: 0.6818\n",
      "Epoch 24/54\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.1244 - accuracy: 0.6591\n",
      "Epoch 25/54\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.1233 - accuracy: 0.6136\n",
      "Epoch 26/54\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0726 - accuracy: 0.6136\n",
      "Epoch 27/54\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.0776 - accuracy: 0.6818\n",
      "Epoch 28/54\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0557 - accuracy: 0.6364\n",
      "Epoch 29/54\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.0517 - accuracy: 0.6136\n",
      "Epoch 30/54\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.0024 - accuracy: 0.6364\n",
      "Epoch 31/54\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.9873 - accuracy: 0.6136\n",
      "Epoch 32/54\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.9830 - accuracy: 0.6364\n",
      "Epoch 33/54\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.9564 - accuracy: 0.6591\n",
      "Epoch 34/54\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.9547 - accuracy: 0.6136\n",
      "Epoch 35/54\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.9482 - accuracy: 0.6364\n",
      "Epoch 36/54\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.9441 - accuracy: 0.6591\n",
      "Epoch 37/54\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.9360 - accuracy: 0.6591\n",
      "Epoch 38/54\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.9217 - accuracy: 0.6364\n",
      "Epoch 39/54\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.9336 - accuracy: 0.6591\n",
      "Epoch 40/54\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.8990 - accuracy: 0.7273\n",
      "Epoch 41/54\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.8891 - accuracy: 0.7045\n",
      "Epoch 42/54\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 1.8961 - accuracy: 0.7045\n",
      "Epoch 43/54\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.8625 - accuracy: 0.7045\n",
      "Epoch 44/54\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.8653 - accuracy: 0.7273\n",
      "Epoch 45/54\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.8608 - accuracy: 0.7045\n",
      "Epoch 46/54\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.8362 - accuracy: 0.7273\n",
      "Epoch 47/54\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.8403 - accuracy: 0.7045\n",
      "Epoch 48/54\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.8316 - accuracy: 0.7045\n",
      "Epoch 49/54\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.8180 - accuracy: 0.7273\n",
      "Epoch 50/54\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.8161 - accuracy: 0.7500\n",
      "Epoch 51/54\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.8234 - accuracy: 0.6818\n",
      "Epoch 52/54\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.8046 - accuracy: 0.7500\n",
      "Epoch 53/54\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.1362 - accuracy: 0.7045\n",
      "Epoch 54/54\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 2.1731 - accuracy: 0.7045\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5428bab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5909\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:40:38,621]\u001b[0m Trial 34 finished with value: 0.5909090638160706 and parameters: {'embedding_output_dim': 122, 'num_epochs': 54}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/17\n",
      "1/1 [==============================] - 9s 9s/step - loss: 12.0992 - accuracy: 0.0227\n",
      "Epoch 2/17\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.1511 - accuracy: 0.1818\n",
      "Epoch 3/17\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.4610 - accuracy: 0.3182\n",
      "Epoch 4/17\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.4021 - accuracy: 0.1364\n",
      "Epoch 5/17\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.7745 - accuracy: 0.3182\n",
      "Epoch 6/17\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 3.6644 - accuracy: 0.4091\n",
      "Epoch 7/17\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 3.6818 - accuracy: 0.3182\n",
      "Epoch 8/17\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.6975 - accuracy: 0.3864\n",
      "Epoch 9/17\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 3.6075 - accuracy: 0.4773\n",
      "Epoch 10/17\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 3.3459 - accuracy: 0.4545\n",
      "Epoch 11/17\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 3.6387 - accuracy: 0.3864\n",
      "Epoch 12/17\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.2673 - accuracy: 0.5455\n",
      "Epoch 13/17\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.2856 - accuracy: 0.4318\n",
      "Epoch 14/17\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.6435 - accuracy: 0.4773\n",
      "Epoch 15/17\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 3.2606 - accuracy: 0.4545\n",
      "Epoch 16/17\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.2362 - accuracy: 0.5455\n",
      "Epoch 17/17\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 3.2509 - accuracy: 0.6136\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff510645940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7057 - accuracy: 0.6364\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:40:51,508]\u001b[0m Trial 35 finished with value: 0.6363636255264282 and parameters: {'embedding_output_dim': 36, 'num_epochs': 17}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/71\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.9072 - accuracy: 0.0227\n",
      "Epoch 2/71\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 4.7323 - accuracy: 0.3409\n",
      "Epoch 3/71\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 3.7369 - accuracy: 0.4318\n",
      "Epoch 4/71\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.3409 - accuracy: 0.4773\n",
      "Epoch 5/71\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.2177 - accuracy: 0.5682\n",
      "Epoch 6/71\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.1050 - accuracy: 0.6136\n",
      "Epoch 7/71\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.1104 - accuracy: 0.5909\n",
      "Epoch 8/71\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3.1049 - accuracy: 0.5455\n",
      "Epoch 9/71\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 3.0586 - accuracy: 0.6364\n",
      "Epoch 10/71\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 3.0463 - accuracy: 0.5909\n",
      "Epoch 11/71\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 3.0524 - accuracy: 0.5909\n",
      "Epoch 12/71\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.9976 - accuracy: 0.6136\n",
      "Epoch 13/71\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.9667 - accuracy: 0.6818\n",
      "Epoch 14/71\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.9855 - accuracy: 0.5455\n",
      "Epoch 15/71\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.9599 - accuracy: 0.6136\n",
      "Epoch 16/71\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.9286 - accuracy: 0.6364\n",
      "Epoch 17/71\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.9148 - accuracy: 0.6136\n",
      "Epoch 18/71\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.9353 - accuracy: 0.6136\n",
      "Epoch 19/71\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.8669 - accuracy: 0.6818\n",
      "Epoch 20/71\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.8781 - accuracy: 0.6364\n",
      "Epoch 21/71\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.8635 - accuracy: 0.6818\n",
      "Epoch 22/71\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.8414 - accuracy: 0.6818\n",
      "Epoch 23/71\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.8240 - accuracy: 0.6591\n",
      "Epoch 24/71\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.8284 - accuracy: 0.6364\n",
      "Epoch 25/71\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.8277 - accuracy: 0.6591\n",
      "Epoch 26/71\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.8337 - accuracy: 0.6591\n",
      "Epoch 27/71\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.8159 - accuracy: 0.6591\n",
      "Epoch 28/71\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.7707 - accuracy: 0.6818\n",
      "Epoch 29/71\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.7929 - accuracy: 0.6136\n",
      "Epoch 30/71\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.7738 - accuracy: 0.6591\n",
      "Epoch 31/71\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.7722 - accuracy: 0.6364\n",
      "Epoch 32/71\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.7747 - accuracy: 0.6818\n",
      "Epoch 33/71\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.4620 - accuracy: 0.6364\n",
      "Epoch 34/71\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.7364 - accuracy: 0.6364\n",
      "Epoch 35/71\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 2.4326 - accuracy: 0.6364\n",
      "Epoch 36/71\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.7207 - accuracy: 0.6818\n",
      "Epoch 37/71\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.7263 - accuracy: 0.6364\n",
      "Epoch 38/71\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.4592 - accuracy: 0.6364\n",
      "Epoch 39/71\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.1678 - accuracy: 0.6591\n",
      "Epoch 40/71\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.1147 - accuracy: 0.6591\n",
      "Epoch 41/71\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.0731 - accuracy: 0.6364\n",
      "Epoch 42/71\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.1205 - accuracy: 0.6136\n",
      "Epoch 43/71\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.8031 - accuracy: 0.6591\n",
      "Epoch 44/71\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.0994 - accuracy: 0.6136\n",
      "Epoch 45/71\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.0947 - accuracy: 0.6818\n",
      "Epoch 46/71\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.1380 - accuracy: 0.6818\n",
      "Epoch 47/71\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.0454 - accuracy: 0.6364\n",
      "Epoch 48/71\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.7270 - accuracy: 0.6591\n",
      "Epoch 49/71\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.6758 - accuracy: 0.6818\n",
      "Epoch 50/71\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.6928 - accuracy: 0.6818\n",
      "Epoch 51/71\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.6513 - accuracy: 0.6591\n",
      "Epoch 52/71\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.7015 - accuracy: 0.6818\n",
      "Epoch 53/71\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.6455 - accuracy: 0.6818\n",
      "Epoch 54/71\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.6456 - accuracy: 0.6818\n",
      "Epoch 55/71\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.6555 - accuracy: 0.6818\n",
      "Epoch 56/71\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.7126 - accuracy: 0.7273\n",
      "Epoch 57/71\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.6539 - accuracy: 0.7273\n",
      "Epoch 58/71\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.6227 - accuracy: 0.7045\n",
      "Epoch 59/71\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.6456 - accuracy: 0.6591\n",
      "Epoch 60/71\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.6836 - accuracy: 0.6818\n",
      "Epoch 61/71\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.6543 - accuracy: 0.7045\n",
      "Epoch 62/71\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.7066 - accuracy: 0.5909\n",
      "Epoch 63/71\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.6560 - accuracy: 0.6136\n",
      "Epoch 64/71\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.6419 - accuracy: 0.6136\n",
      "Epoch 65/71\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.6198 - accuracy: 0.7045\n",
      "Epoch 66/71\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.6415 - accuracy: 0.6591\n",
      "Epoch 67/71\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.7254 - accuracy: 0.6364\n",
      "Epoch 68/71\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.5978 - accuracy: 0.6591\n",
      "Epoch 69/71\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.6005 - accuracy: 0.7045\n",
      "Epoch 70/71\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.5706 - accuracy: 0.7273\n",
      "Epoch 71/71\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.5625 - accuracy: 0.7273\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5402f4d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.9987 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:41:13,349]\u001b[0m Trial 36 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 69, 'num_epochs': 71}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/69\n",
      "1/1 [==============================] - 9s 9s/step - loss: 5.9669 - accuracy: 0.0909\n",
      "Epoch 2/69\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 3.9947 - accuracy: 0.5000\n",
      "Epoch 3/69\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.4661 - accuracy: 0.6136\n",
      "Epoch 4/69\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.3261 - accuracy: 0.5455\n",
      "Epoch 5/69\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 3.3298 - accuracy: 0.6364\n",
      "Epoch 6/69\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 3.0626 - accuracy: 0.6591\n",
      "Epoch 7/69\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 3.0617 - accuracy: 0.6364\n",
      "Epoch 8/69\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 3.0685 - accuracy: 0.5909\n",
      "Epoch 9/69\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.0446 - accuracy: 0.6136\n",
      "Epoch 10/69\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.0276 - accuracy: 0.6136\n",
      "Epoch 11/69\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 3.0283 - accuracy: 0.6364\n",
      "Epoch 12/69\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.0150 - accuracy: 0.6136\n",
      "Epoch 13/69\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 2.9984 - accuracy: 0.6136\n",
      "Epoch 14/69\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 3.0048 - accuracy: 0.6136\n",
      "Epoch 15/69\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.7508 - accuracy: 0.6364\n",
      "Epoch 16/69\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 2.6956 - accuracy: 0.6136\n",
      "Epoch 17/69\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.6764 - accuracy: 0.5909\n",
      "Epoch 18/69\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.6691 - accuracy: 0.6364\n",
      "Epoch 19/69\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.6617 - accuracy: 0.5909\n",
      "Epoch 20/69\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 2.6714 - accuracy: 0.6364\n",
      "Epoch 21/69\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.6751 - accuracy: 0.5909\n",
      "Epoch 22/69\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 2.6617 - accuracy: 0.6136\n",
      "Epoch 23/69\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.6407 - accuracy: 0.6136\n",
      "Epoch 24/69\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 2.6032 - accuracy: 0.6136\n",
      "Epoch 25/69\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.5931 - accuracy: 0.6136\n",
      "Epoch 26/69\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.5829 - accuracy: 0.6591\n",
      "Epoch 27/69\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.5811 - accuracy: 0.6591\n",
      "Epoch 28/69\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.5429 - accuracy: 0.6364\n",
      "Epoch 29/69\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.5426 - accuracy: 0.6591\n",
      "Epoch 30/69\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.5086 - accuracy: 0.6591\n",
      "Epoch 31/69\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.5141 - accuracy: 0.6818\n",
      "Epoch 32/69\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.4637 - accuracy: 0.6818\n",
      "Epoch 33/69\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.4481 - accuracy: 0.6818\n",
      "Epoch 34/69\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.4103 - accuracy: 0.6591\n",
      "Epoch 35/69\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.4080 - accuracy: 0.6364\n",
      "Epoch 36/69\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.3875 - accuracy: 0.6591\n",
      "Epoch 37/69\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 2.3711 - accuracy: 0.6364\n",
      "Epoch 38/69\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.3441 - accuracy: 0.6364\n",
      "Epoch 39/69\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.3490 - accuracy: 0.6364\n",
      "Epoch 40/69\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.3464 - accuracy: 0.6364\n",
      "Epoch 41/69\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.3263 - accuracy: 0.6364\n",
      "Epoch 42/69\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.3263 - accuracy: 0.6136\n",
      "Epoch 43/69\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.3105 - accuracy: 0.6364\n",
      "Epoch 44/69\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.3051 - accuracy: 0.6364\n",
      "Epoch 45/69\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.3026 - accuracy: 0.6136\n",
      "Epoch 46/69\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.2863 - accuracy: 0.6136\n",
      "Epoch 47/69\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.2698 - accuracy: 0.6591\n",
      "Epoch 48/69\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 2.2637 - accuracy: 0.6591\n",
      "Epoch 49/69\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.2685 - accuracy: 0.6591\n",
      "Epoch 50/69\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.2424 - accuracy: 0.6364\n",
      "Epoch 51/69\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.2304 - accuracy: 0.6591\n",
      "Epoch 52/69\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 2.2260 - accuracy: 0.6818\n",
      "Epoch 53/69\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.2089 - accuracy: 0.6818\n",
      "Epoch 54/69\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.2263 - accuracy: 0.6818\n",
      "Epoch 55/69\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.2008 - accuracy: 0.7045\n",
      "Epoch 56/69\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 2.1935 - accuracy: 0.7045\n",
      "Epoch 57/69\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.1744 - accuracy: 0.7273\n",
      "Epoch 58/69\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 2.1828 - accuracy: 0.7045\n",
      "Epoch 59/69\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 2.1708 - accuracy: 0.6818\n",
      "Epoch 60/69\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.1569 - accuracy: 0.7045\n",
      "Epoch 61/69\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.1257 - accuracy: 0.7045\n",
      "Epoch 62/69\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - accuracy: 0.6591\n",
      "Epoch 63/69\n",
      "1/1 [==============================] - 0s 162ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/69\n",
      "1/1 [==============================] - 0s 272ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/69\n",
      "1/1 [==============================] - 0s 325ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/69\n",
      "1/1 [==============================] - 0s 344ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/69\n",
      "1/1 [==============================] - 0s 244ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/69\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/69\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff561299d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:41:39,205]\u001b[0m Trial 37 finished with value: 0.5 and parameters: {'embedding_output_dim': 176, 'num_epochs': 69}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/39\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.2321 - accuracy: 0.0227\n",
      "Epoch 2/39\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 3.4136 - accuracy: 0.5455\n",
      "Epoch 3/39\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 3.2983 - accuracy: 0.6818\n",
      "Epoch 4/39\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 3.2272 - accuracy: 0.5909\n",
      "Epoch 5/39\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 3.1801 - accuracy: 0.5909\n",
      "Epoch 6/39\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 3.1573 - accuracy: 0.5455\n",
      "Epoch 7/39\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 3.1389 - accuracy: 0.5227\n",
      "Epoch 8/39\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 3.1105 - accuracy: 0.5909\n",
      "Epoch 9/39\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 3.0939 - accuracy: 0.5909\n",
      "Epoch 10/39\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 3.0497 - accuracy: 0.6136\n",
      "Epoch 11/39\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 3.0251 - accuracy: 0.6591\n",
      "Epoch 12/39\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.9971 - accuracy: 0.6818\n",
      "Epoch 13/39\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.9691 - accuracy: 0.7045\n",
      "Epoch 14/39\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.9460 - accuracy: 0.7045\n",
      "Epoch 15/39\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 2.9266 - accuracy: 0.6136\n",
      "Epoch 16/39\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 2.8940 - accuracy: 0.7045\n",
      "Epoch 17/39\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 2.8898 - accuracy: 0.7045\n",
      "Epoch 18/39\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 2.8711 - accuracy: 0.7045\n",
      "Epoch 19/39\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 2.8449 - accuracy: 0.7045\n",
      "Epoch 20/39\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 2.8252 - accuracy: 0.6818\n",
      "Epoch 21/39\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 2.8115 - accuracy: 0.7045\n",
      "Epoch 22/39\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 2.7995 - accuracy: 0.6818\n",
      "Epoch 23/39\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.7964 - accuracy: 0.7273\n",
      "Epoch 24/39\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 2.7654 - accuracy: 0.7273\n",
      "Epoch 25/39\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 2.7816 - accuracy: 0.6818\n",
      "Epoch 26/39\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 2.7307 - accuracy: 0.7273\n",
      "Epoch 27/39\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 2.7363 - accuracy: 0.7273\n",
      "Epoch 28/39\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 2.7485 - accuracy: 0.7045\n",
      "Epoch 29/39\n",
      "1/1 [==============================] - 0s 370ms/step - loss: nan - accuracy: 0.7273\n",
      "Epoch 30/39\n",
      "1/1 [==============================] - 0s 376ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 31/39\n",
      "1/1 [==============================] - 0s 405ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 32/39\n",
      "1/1 [==============================] - 0s 453ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 33/39\n",
      "1/1 [==============================] - 0s 377ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 34/39\n",
      "1/1 [==============================] - 0s 376ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 35/39\n",
      "1/1 [==============================] - 0s 478ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 36/39\n",
      "1/1 [==============================] - 0s 312ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 37/39\n",
      "1/1 [==============================] - 0s 325ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 38/39\n",
      "1/1 [==============================] - 0s 297ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/39\n",
      "1/1 [==============================] - 0s 299ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e05031f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:42:03,182]\u001b[0m Trial 38 finished with value: 0.5 and parameters: {'embedding_output_dim': 236, 'num_epochs': 39}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/80\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.9453 - accuracy: 0.1136\n",
      "Epoch 2/80\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 4.2151 - accuracy: 0.2955\n",
      "Epoch 3/80\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 3.5652 - accuracy: 0.5000\n",
      "Epoch 4/80\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 3.1961 - accuracy: 0.5000\n",
      "Epoch 5/80\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 3.2178 - accuracy: 0.5000\n",
      "Epoch 6/80\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.9466 - accuracy: 0.5000\n",
      "Epoch 7/80\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 2.6461 - accuracy: 0.4773\n",
      "Epoch 8/80\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 2.7159 - accuracy: 0.5000\n",
      "Epoch 9/80\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.6468 - accuracy: 0.4545\n",
      "Epoch 10/80\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 2.6773 - accuracy: 0.5455\n",
      "Epoch 11/80\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 2.6693 - accuracy: 0.5682\n",
      "Epoch 12/80\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 2.6770 - accuracy: 0.5682\n",
      "Epoch 13/80\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.6260 - accuracy: 0.6136\n",
      "Epoch 14/80\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.6260 - accuracy: 0.5909\n",
      "Epoch 15/80\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 2.6173 - accuracy: 0.6364\n",
      "Epoch 16/80\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 2.5995 - accuracy: 0.6136\n",
      "Epoch 17/80\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 2.5563 - accuracy: 0.6136\n",
      "Epoch 18/80\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 2.5245 - accuracy: 0.6591\n",
      "Epoch 19/80\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.5002 - accuracy: 0.6591\n",
      "Epoch 20/80\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.4626 - accuracy: 0.6591\n",
      "Epoch 21/80\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.4466 - accuracy: 0.6364\n",
      "Epoch 22/80\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.4215 - accuracy: 0.6364\n",
      "Epoch 23/80\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 2.3952 - accuracy: 0.6364\n",
      "Epoch 24/80\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 2.3693 - accuracy: 0.6591\n",
      "Epoch 25/80\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 2.3470 - accuracy: 0.6364\n",
      "Epoch 26/80\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.3236 - accuracy: 0.6136\n",
      "Epoch 27/80\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 2.2833 - accuracy: 0.6364\n",
      "Epoch 28/80\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 2.2706 - accuracy: 0.6591\n",
      "Epoch 29/80\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 2.2294 - accuracy: 0.6364\n",
      "Epoch 30/80\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 2.2041 - accuracy: 0.6364\n",
      "Epoch 31/80\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 2.1773 - accuracy: 0.6364\n",
      "Epoch 32/80\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 2.1636 - accuracy: 0.6591\n",
      "Epoch 33/80\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.1177 - accuracy: 0.6591\n",
      "Epoch 34/80\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 2.1281 - accuracy: 0.6364\n",
      "Epoch 35/80\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.1164 - accuracy: 0.6364\n",
      "Epoch 36/80\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.1089 - accuracy: 0.6136\n",
      "Epoch 37/80\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0797 - accuracy: 0.6364\n",
      "Epoch 38/80\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 2.0630 - accuracy: 0.6591\n",
      "Epoch 39/80\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.0486 - accuracy: 0.6364\n",
      "Epoch 40/80\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 2.0208 - accuracy: 0.6591\n",
      "Epoch 41/80\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.0279 - accuracy: 0.6364\n",
      "Epoch 42/80\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 2.0105 - accuracy: 0.6364\n",
      "Epoch 43/80\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.0264 - accuracy: 0.6364\n",
      "Epoch 44/80\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.9920 - accuracy: 0.6364\n",
      "Epoch 45/80\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.0248 - accuracy: 0.6591\n",
      "Epoch 46/80\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 1.9928 - accuracy: 0.6364\n",
      "Epoch 47/80\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.9674 - accuracy: 0.6818\n",
      "Epoch 48/80\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.9453 - accuracy: 0.6818\n",
      "Epoch 49/80\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 1.9455 - accuracy: 0.6591\n",
      "Epoch 50/80\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 1.9446 - accuracy: 0.7045\n",
      "Epoch 51/80\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.9333 - accuracy: 0.7045\n",
      "Epoch 52/80\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.9123 - accuracy: 0.7273\n",
      "Epoch 53/80\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 1.9100 - accuracy: 0.7500\n",
      "Epoch 54/80\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.8846 - accuracy: 0.7273\n",
      "Epoch 55/80\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 1.8906 - accuracy: 0.7273\n",
      "Epoch 56/80\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.2347 - accuracy: 0.6818\n",
      "Epoch 57/80\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.8562 - accuracy: 0.7273\n",
      "Epoch 58/80\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.8560 - accuracy: 0.7045\n",
      "Epoch 59/80\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.8259 - accuracy: 0.7500\n",
      "Epoch 60/80\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 1.8481 - accuracy: 0.7045\n",
      "Epoch 61/80\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.7996 - accuracy: 0.7500\n",
      "Epoch 62/80\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 2.5025 - accuracy: 0.7045\n",
      "Epoch 63/80\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.8191 - accuracy: 0.7273\n",
      "Epoch 64/80\n",
      "1/1 [==============================] - 0s 255ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 65/80\n",
      "1/1 [==============================] - 0s 349ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/80\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/80\n",
      "1/1 [==============================] - 0s 236ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/80\n",
      "1/1 [==============================] - 0s 271ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/80\n",
      "1/1 [==============================] - 0s 209ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/80\n",
      "1/1 [==============================] - 0s 295ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/80\n",
      "1/1 [==============================] - 0s 268ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/80\n",
      "1/1 [==============================] - 0s 297ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/80\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/80\n",
      "1/1 [==============================] - 0s 339ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/80\n",
      "1/1 [==============================] - 0s 282ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/80\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/80\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/80\n",
      "1/1 [==============================] - 0s 308ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/80\n",
      "1/1 [==============================] - 0s 357ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/80\n",
      "1/1 [==============================] - 0s 273ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff578b82dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:42:36,105]\u001b[0m Trial 39 finished with value: 0.5 and parameters: {'embedding_output_dim': 197, 'num_epochs': 80}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/97\n",
      "1/1 [==============================] - 10s 10s/step - loss: 10.1772 - accuracy: 0.0682\n",
      "Epoch 2/97\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 6.3484 - accuracy: 0.2955\n",
      "Epoch 3/97\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 3.6079 - accuracy: 0.2727\n",
      "Epoch 4/97\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 3.0561 - accuracy: 0.2727\n",
      "Epoch 5/97\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 2.7546 - accuracy: 0.2955\n",
      "Epoch 6/97\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 2.6107 - accuracy: 0.3864\n",
      "Epoch 7/97\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 2.6133 - accuracy: 0.3636\n",
      "Epoch 8/97\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 2.5782 - accuracy: 0.4545\n",
      "Epoch 9/97\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 2.5726 - accuracy: 0.4545\n",
      "Epoch 10/97\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 2.5712 - accuracy: 0.4545\n",
      "Epoch 11/97\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.5368 - accuracy: 0.5000\n",
      "Epoch 12/97\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 2.5426 - accuracy: 0.4773\n",
      "Epoch 13/97\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 2.5283 - accuracy: 0.4773\n",
      "Epoch 14/97\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 2.5054 - accuracy: 0.5455\n",
      "Epoch 15/97\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 2.5001 - accuracy: 0.5455\n",
      "Epoch 16/97\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.2403 - accuracy: 0.5455\n",
      "Epoch 17/97\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 2.2343 - accuracy: 0.5682\n",
      "Epoch 18/97\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.1727 - accuracy: 0.5455\n",
      "Epoch 19/97\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.1585 - accuracy: 0.5682\n",
      "Epoch 20/97\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.1589 - accuracy: 0.5682\n",
      "Epoch 21/97\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.1514 - accuracy: 0.6136\n",
      "Epoch 22/97\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.1252 - accuracy: 0.5909\n",
      "Epoch 23/97\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 2.1279 - accuracy: 0.6364\n",
      "Epoch 24/97\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.1346 - accuracy: 0.6136\n",
      "Epoch 25/97\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 2.1296 - accuracy: 0.6136\n",
      "Epoch 26/97\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 2.1324 - accuracy: 0.6364\n",
      "Epoch 27/97\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 2.1066 - accuracy: 0.6591\n",
      "Epoch 28/97\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.0991 - accuracy: 0.6591\n",
      "Epoch 29/97\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.0765 - accuracy: 0.6136\n",
      "Epoch 30/97\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 2.0685 - accuracy: 0.6364\n",
      "Epoch 31/97\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 2.0285 - accuracy: 0.6591\n",
      "Epoch 32/97\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 2.0478 - accuracy: 0.6591\n",
      "Epoch 33/97\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 2.0187 - accuracy: 0.6591\n",
      "Epoch 34/97\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.0153 - accuracy: 0.6591\n",
      "Epoch 35/97\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 2.0122 - accuracy: 0.6591\n",
      "Epoch 36/97\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 2.0126 - accuracy: 0.6591\n",
      "Epoch 37/97\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.9889 - accuracy: 0.6591\n",
      "Epoch 38/97\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.9933 - accuracy: 0.6591\n",
      "Epoch 39/97\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.9622 - accuracy: 0.6818\n",
      "Epoch 40/97\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.9584 - accuracy: 0.6591\n",
      "Epoch 41/97\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 1.9440 - accuracy: 0.6591\n",
      "Epoch 42/97\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 1.9554 - accuracy: 0.6591\n",
      "Epoch 43/97\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.9206 - accuracy: 0.6591\n",
      "Epoch 44/97\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 1.9237 - accuracy: 0.6591\n",
      "Epoch 45/97\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1.9160 - accuracy: 0.6591\n",
      "Epoch 46/97\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.8985 - accuracy: 0.6591\n",
      "Epoch 47/97\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.8972 - accuracy: 0.6591\n",
      "Epoch 48/97\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 1.8923 - accuracy: 0.6591\n",
      "Epoch 49/97\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 1.8851 - accuracy: 0.6591\n",
      "Epoch 50/97\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 1.8695 - accuracy: 0.6591\n",
      "Epoch 51/97\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.8642 - accuracy: 0.6591\n",
      "Epoch 52/97\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.8538 - accuracy: 0.6591\n",
      "Epoch 53/97\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 1.8613 - accuracy: 0.6591\n",
      "Epoch 54/97\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.8335 - accuracy: 0.6591\n",
      "Epoch 55/97\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.8441 - accuracy: 0.6591\n",
      "Epoch 56/97\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.8376 - accuracy: 0.6591\n",
      "Epoch 57/97\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.8426 - accuracy: 0.6591\n",
      "Epoch 58/97\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1.8241 - accuracy: 0.6591\n",
      "Epoch 59/97\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 1.7933 - accuracy: 0.6591\n",
      "Epoch 60/97\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 1.8230 - accuracy: 0.6818\n",
      "Epoch 61/97\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.7765 - accuracy: 0.6591\n",
      "Epoch 62/97\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 1.7977 - accuracy: 0.6364\n",
      "Epoch 63/97\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 1.7758 - accuracy: 0.6591\n",
      "Epoch 64/97\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.7972 - accuracy: 0.6591\n",
      "Epoch 65/97\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.7526 - accuracy: 0.6818\n",
      "Epoch 66/97\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.7618 - accuracy: 0.6591\n",
      "Epoch 67/97\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.7436 - accuracy: 0.6591\n",
      "Epoch 68/97\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 1.7360 - accuracy: 0.6818\n",
      "Epoch 69/97\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 1.7307 - accuracy: 0.6591\n",
      "Epoch 70/97\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 1.7406 - accuracy: 0.6591\n",
      "Epoch 71/97\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.7322 - accuracy: 0.6591\n",
      "Epoch 72/97\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 1.7250 - accuracy: 0.6364\n",
      "Epoch 73/97\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 1.7237 - accuracy: 0.6364\n",
      "Epoch 74/97\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1.7098 - accuracy: 0.6591\n",
      "Epoch 75/97\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.6824 - accuracy: 0.6591\n",
      "Epoch 76/97\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 1.6732 - accuracy: 0.6591\n",
      "Epoch 77/97\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 1.6801 - accuracy: 0.7045\n",
      "Epoch 78/97\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.6733 - accuracy: 0.6591\n",
      "Epoch 79/97\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.6823 - accuracy: 0.7273\n",
      "Epoch 80/97\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 1.6633 - accuracy: 0.6591\n",
      "Epoch 81/97\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.6503 - accuracy: 0.6818\n",
      "Epoch 82/97\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.6391 - accuracy: 0.7273\n",
      "Epoch 83/97\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 1.6582 - accuracy: 0.6818\n",
      "Epoch 84/97\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 1.6360 - accuracy: 0.6818\n",
      "Epoch 85/97\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 1.6351 - accuracy: 0.6591\n",
      "Epoch 86/97\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.6293 - accuracy: 0.7045\n",
      "Epoch 87/97\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.6039 - accuracy: 0.7273\n",
      "Epoch 88/97\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 1.5992 - accuracy: 0.6818\n",
      "Epoch 89/97\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.5806 - accuracy: 0.7045\n",
      "Epoch 90/97\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 1.6055 - accuracy: 0.6818\n",
      "Epoch 91/97\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.5743 - accuracy: 0.7045\n",
      "Epoch 92/97\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.5726 - accuracy: 0.7045\n",
      "Epoch 93/97\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.5419 - accuracy: 0.7045\n",
      "Epoch 94/97\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 1.5539 - accuracy: 0.7045\n",
      "Epoch 95/97\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 1.5344 - accuracy: 0.7045\n",
      "Epoch 96/97\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 1.5068 - accuracy: 0.7045\n",
      "Epoch 97/97\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.5249 - accuracy: 0.7045\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5609ff4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0378 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:43:21,652]\u001b[0m Trial 40 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 232, 'num_epochs': 97}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/28\n",
      "1/1 [==============================] - 10s 10s/step - loss: 9.5886 - accuracy: 0.0455\n",
      "Epoch 2/28\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 2.7929 - accuracy: 0.1818\n",
      "Epoch 3/28\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 3.2251 - accuracy: 0.2500\n",
      "Epoch 4/28\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 2.1522 - accuracy: 0.2955\n",
      "Epoch 5/28\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 2.7209 - accuracy: 0.3182\n",
      "Epoch 6/28\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.3196 - accuracy: 0.3182\n",
      "Epoch 7/28\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 2.0321 - accuracy: 0.3182\n",
      "Epoch 8/28\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 2.0579 - accuracy: 0.3864\n",
      "Epoch 9/28\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.8868 - accuracy: 0.3864\n",
      "Epoch 10/28\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.8618 - accuracy: 0.4091\n",
      "Epoch 11/28\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.8762 - accuracy: 0.4545\n",
      "Epoch 12/28\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 1.8475 - accuracy: 0.4773\n",
      "Epoch 13/28\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.8752 - accuracy: 0.4773\n",
      "Epoch 14/28\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 1.8537 - accuracy: 0.4773\n",
      "Epoch 15/28\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 1.8167 - accuracy: 0.4545\n",
      "Epoch 16/28\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.8133 - accuracy: 0.4773\n",
      "Epoch 17/28\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.8014 - accuracy: 0.4773\n",
      "Epoch 18/28\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 1.7744 - accuracy: 0.4545\n",
      "Epoch 19/28\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.7591 - accuracy: 0.4773\n",
      "Epoch 20/28\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.7003 - accuracy: 0.5000\n",
      "Epoch 21/28\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.6746 - accuracy: 0.5000\n",
      "Epoch 22/28\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.6435 - accuracy: 0.5227\n",
      "Epoch 23/28\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 1.6150 - accuracy: 0.5455\n",
      "Epoch 24/28\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.5907 - accuracy: 0.5455\n",
      "Epoch 25/28\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 1.5847 - accuracy: 0.5682\n",
      "Epoch 26/28\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 1.5280 - accuracy: 0.5455\n",
      "Epoch 27/28\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 1.5156 - accuracy: 0.5455\n",
      "Epoch 28/28\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.5010 - accuracy: 0.5682\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c1484c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1919 - accuracy: 0.6818\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:43:41,854]\u001b[0m Trial 41 finished with value: 0.6818181872367859 and parameters: {'embedding_output_dim': 235, 'num_epochs': 28}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/96\n",
      "1/1 [==============================] - 10s 10s/step - loss: 10.4854 - accuracy: 0.0227\n",
      "Epoch 2/96\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 3.0540 - accuracy: 0.4318\n",
      "Epoch 3/96\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 2.7972 - accuracy: 0.4318\n",
      "Epoch 4/96\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.6733 - accuracy: 0.4773\n",
      "Epoch 5/96\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.5907 - accuracy: 0.5682\n",
      "Epoch 6/96\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 2.2868 - accuracy: 0.5909\n",
      "Epoch 7/96\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 2.2196 - accuracy: 0.6364\n",
      "Epoch 8/96\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.2238 - accuracy: 0.6364\n",
      "Epoch 9/96\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.2016 - accuracy: 0.6364\n",
      "Epoch 10/96\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.1424 - accuracy: 0.6591\n",
      "Epoch 11/96\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.1496 - accuracy: 0.6364\n",
      "Epoch 12/96\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 2.0811 - accuracy: 0.6591\n",
      "Epoch 13/96\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 2.0530 - accuracy: 0.6364\n",
      "Epoch 14/96\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 1.9978 - accuracy: 0.6591\n",
      "Epoch 15/96\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1.9837 - accuracy: 0.6591\n",
      "Epoch 16/96\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.9777 - accuracy: 0.6591\n",
      "Epoch 17/96\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 1.9121 - accuracy: 0.7045\n",
      "Epoch 18/96\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.9101 - accuracy: 0.6818\n",
      "Epoch 19/96\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 1.9210 - accuracy: 0.6591\n",
      "Epoch 20/96\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1.8965 - accuracy: 0.6818\n",
      "Epoch 21/96\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.9118 - accuracy: 0.7045\n",
      "Epoch 22/96\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 1.8929 - accuracy: 0.7045\n",
      "Epoch 23/96\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 1.9686 - accuracy: 0.6818\n",
      "Epoch 24/96\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 2.0603 - accuracy: 0.6364\n",
      "Epoch 25/96\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 2.0689 - accuracy: 0.5455\n",
      "Epoch 26/96\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.1220 - accuracy: 0.5682\n",
      "Epoch 27/96\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 2.4331 - accuracy: 0.5455\n",
      "Epoch 28/96\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 2.1318 - accuracy: 0.5909\n",
      "Epoch 29/96\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0796 - accuracy: 0.5455\n",
      "Epoch 30/96\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 2.0259 - accuracy: 0.5909\n",
      "Epoch 31/96\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.0359 - accuracy: 0.6364\n",
      "Epoch 32/96\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.9845 - accuracy: 0.6591\n",
      "Epoch 33/96\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.9828 - accuracy: 0.6591\n",
      "Epoch 34/96\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.9529 - accuracy: 0.7045\n",
      "Epoch 35/96\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.9307 - accuracy: 0.6818\n",
      "Epoch 36/96\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.9312 - accuracy: 0.7273\n",
      "Epoch 37/96\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.9136 - accuracy: 0.7045\n",
      "Epoch 38/96\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.9273 - accuracy: 0.6818\n",
      "Epoch 39/96\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.9147 - accuracy: 0.6818\n",
      "Epoch 40/96\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.9030 - accuracy: 0.7045\n",
      "Epoch 41/96\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.8969 - accuracy: 0.7045\n",
      "Epoch 42/96\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.8881 - accuracy: 0.7045\n",
      "Epoch 43/96\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.8733 - accuracy: 0.7273\n",
      "Epoch 44/96\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 1.8641 - accuracy: 0.6818\n",
      "Epoch 45/96\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.8456 - accuracy: 0.7273\n",
      "Epoch 46/96\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 1.8590 - accuracy: 0.7045\n",
      "Epoch 47/96\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 1.8485 - accuracy: 0.7045\n",
      "Epoch 48/96\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 1.8348 - accuracy: 0.7273\n",
      "Epoch 49/96\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.8225 - accuracy: 0.7045\n",
      "Epoch 50/96\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.8181 - accuracy: 0.7273\n",
      "Epoch 51/96\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.8021 - accuracy: 0.7273\n",
      "Epoch 52/96\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 1.8247 - accuracy: 0.7500\n",
      "Epoch 53/96\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.7800 - accuracy: 0.7727\n",
      "Epoch 54/96\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 2.1366 - accuracy: 0.7273\n",
      "Epoch 55/96\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.8167 - accuracy: 0.7045\n",
      "Epoch 56/96\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 1.7885 - accuracy: 0.7500\n",
      "Epoch 57/96\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 1.7881 - accuracy: 0.7500\n",
      "Epoch 58/96\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.7964 - accuracy: 0.6818\n",
      "Epoch 59/96\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 1.7914 - accuracy: 0.7045\n",
      "Epoch 60/96\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.7886 - accuracy: 0.7045\n",
      "Epoch 61/96\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 1.7760 - accuracy: 0.7500\n",
      "Epoch 62/96\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.7734 - accuracy: 0.7500\n",
      "Epoch 63/96\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 1.7677 - accuracy: 0.7273\n",
      "Epoch 64/96\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 1.7520 - accuracy: 0.7500\n",
      "Epoch 65/96\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.7551 - accuracy: 0.7500\n",
      "Epoch 66/96\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 1.7703 - accuracy: 0.7727\n",
      "Epoch 67/96\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 1.7640 - accuracy: 0.7273\n",
      "Epoch 68/96\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 1.7499 - accuracy: 0.7727\n",
      "Epoch 69/96\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.7656 - accuracy: 0.7500\n",
      "Epoch 70/96\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 1.7461 - accuracy: 0.7500\n",
      "Epoch 71/96\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.7403 - accuracy: 0.7500\n",
      "Epoch 72/96\n",
      "1/1 [==============================] - 0s 457ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 73/96\n",
      "1/1 [==============================] - 0s 411ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/96\n",
      "1/1 [==============================] - 0s 428ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/96\n",
      "1/1 [==============================] - 0s 347ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/96\n",
      "1/1 [==============================] - 0s 348ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/96\n",
      "1/1 [==============================] - 0s 396ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/96\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/96\n",
      "1/1 [==============================] - 0s 337ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/96\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/96\n",
      "1/1 [==============================] - 0s 335ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/96\n",
      "1/1 [==============================] - 0s 340ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/96\n",
      "1/1 [==============================] - 0s 481ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/96\n",
      "1/1 [==============================] - 0s 373ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/96\n",
      "1/1 [==============================] - 0s 290ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/96\n",
      "1/1 [==============================] - 0s 376ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/96\n",
      "1/1 [==============================] - 0s 374ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/96\n",
      "1/1 [==============================] - 0s 296ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/96\n",
      "1/1 [==============================] - 0s 313ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 90/96\n",
      "1/1 [==============================] - 0s 344ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 91/96\n",
      "1/1 [==============================] - 0s 413ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 92/96\n",
      "1/1 [==============================] - 0s 421ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 93/96\n",
      "1/1 [==============================] - 0s 381ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 94/96\n",
      "1/1 [==============================] - 0s 350ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 95/96\n",
      "1/1 [==============================] - 0s 382ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 96/96\n",
      "1/1 [==============================] - 0s 414ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff561296790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:44:23,246]\u001b[0m Trial 42 finished with value: 0.5 and parameters: {'embedding_output_dim': 216, 'num_epochs': 96}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/84\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.2980 - accuracy: 0.0455\n",
      "Epoch 2/84\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.5822 - accuracy: 0.3864\n",
      "Epoch 3/84\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 2.4535 - accuracy: 0.3409\n",
      "Epoch 4/84\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 2.3549 - accuracy: 0.4545\n",
      "Epoch 5/84\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 2.3236 - accuracy: 0.5000\n",
      "Epoch 6/84\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 2.2991 - accuracy: 0.5455\n",
      "Epoch 7/84\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 2.2294 - accuracy: 0.5455\n",
      "Epoch 8/84\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 2.1884 - accuracy: 0.5909\n",
      "Epoch 9/84\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 2.1470 - accuracy: 0.5682\n",
      "Epoch 10/84\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.1258 - accuracy: 0.5909\n",
      "Epoch 11/84\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 2.1058 - accuracy: 0.5909\n",
      "Epoch 12/84\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.0724 - accuracy: 0.6136\n",
      "Epoch 13/84\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 2.0506 - accuracy: 0.6591\n",
      "Epoch 14/84\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 2.0055 - accuracy: 0.6591\n",
      "Epoch 15/84\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.9838 - accuracy: 0.6364\n",
      "Epoch 16/84\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.9766 - accuracy: 0.6364\n",
      "Epoch 17/84\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.9534 - accuracy: 0.6364\n",
      "Epoch 18/84\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 1.9395 - accuracy: 0.6591\n",
      "Epoch 19/84\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 1.9348 - accuracy: 0.6364\n",
      "Epoch 20/84\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 1.9155 - accuracy: 0.6591\n",
      "Epoch 21/84\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.8903 - accuracy: 0.6591\n",
      "Epoch 22/84\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.8427 - accuracy: 0.6591\n",
      "Epoch 23/84\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.8581 - accuracy: 0.6591\n",
      "Epoch 24/84\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 1.8442 - accuracy: 0.6591\n",
      "Epoch 25/84\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.8072 - accuracy: 0.6591\n",
      "Epoch 26/84\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.8025 - accuracy: 0.6591\n",
      "Epoch 27/84\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 1.7701 - accuracy: 0.6591\n",
      "Epoch 28/84\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 1.7625 - accuracy: 0.6364\n",
      "Epoch 29/84\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.7482 - accuracy: 0.6364\n",
      "Epoch 30/84\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 1.7393 - accuracy: 0.6364\n",
      "Epoch 31/84\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 1.7149 - accuracy: 0.6364\n",
      "Epoch 32/84\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.7052 - accuracy: 0.6591\n",
      "Epoch 33/84\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.6849 - accuracy: 0.6136\n",
      "Epoch 34/84\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.6662 - accuracy: 0.6364\n",
      "Epoch 35/84\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 1.6590 - accuracy: 0.6364\n",
      "Epoch 36/84\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 1.6268 - accuracy: 0.6591\n",
      "Epoch 37/84\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.6112 - accuracy: 0.6591\n",
      "Epoch 38/84\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 1.6242 - accuracy: 0.6364\n",
      "Epoch 39/84\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 1.6088 - accuracy: 0.6591\n",
      "Epoch 40/84\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.5819 - accuracy: 0.6364\n",
      "Epoch 41/84\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 1.5883 - accuracy: 0.6818\n",
      "Epoch 42/84\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.5546 - accuracy: 0.6818\n",
      "Epoch 43/84\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.5122 - accuracy: 0.7500\n",
      "Epoch 44/84\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 1.5100 - accuracy: 0.7045\n",
      "Epoch 45/84\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 1.4999 - accuracy: 0.7273\n",
      "Epoch 46/84\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.4885 - accuracy: 0.7273\n",
      "Epoch 47/84\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.7880 - accuracy: 0.7045\n",
      "Epoch 48/84\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 1.7846 - accuracy: 0.7273\n",
      "Epoch 49/84\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 1.7439 - accuracy: 0.7045\n",
      "Epoch 50/84\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.7900 - accuracy: 0.7727\n",
      "Epoch 51/84\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.7686 - accuracy: 0.6818\n",
      "Epoch 52/84\n",
      "1/1 [==============================] - 0s 296ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 53/84\n",
      "1/1 [==============================] - 0s 291ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/84\n",
      "1/1 [==============================] - 0s 382ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/84\n",
      "1/1 [==============================] - 0s 341ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/84\n",
      "1/1 [==============================] - 0s 389ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/84\n",
      "1/1 [==============================] - 0s 391ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/84\n",
      "1/1 [==============================] - 0s 392ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/84\n",
      "1/1 [==============================] - 0s 363ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/84\n",
      "1/1 [==============================] - 0s 385ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/84\n",
      "1/1 [==============================] - 0s 349ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/84\n",
      "1/1 [==============================] - 0s 334ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/84\n",
      "1/1 [==============================] - 0s 393ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/84\n",
      "1/1 [==============================] - 0s 356ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/84\n",
      "1/1 [==============================] - 0s 307ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/84\n",
      "1/1 [==============================] - 0s 338ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/84\n",
      "1/1 [==============================] - 0s 426ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/84\n",
      "1/1 [==============================] - 0s 337ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/84\n",
      "1/1 [==============================] - 0s 381ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/84\n",
      "1/1 [==============================] - 0s 309ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/84\n",
      "1/1 [==============================] - 0s 330ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/84\n",
      "1/1 [==============================] - 0s 337ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/84\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/84\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/84\n",
      "1/1 [==============================] - 0s 335ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/84\n",
      "1/1 [==============================] - 0s 476ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/84\n",
      "1/1 [==============================] - 0s 427ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/84\n",
      "1/1 [==============================] - 1s 574ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/84\n",
      "1/1 [==============================] - 0s 412ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/84\n",
      "1/1 [==============================] - 0s 381ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/84\n",
      "1/1 [==============================] - 0s 460ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/84\n",
      "1/1 [==============================] - 0s 379ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/84\n",
      "1/1 [==============================] - 0s 370ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/84\n",
      "1/1 [==============================] - 0s 440ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8f031f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:45:03,360]\u001b[0m Trial 43 finished with value: 0.5 and parameters: {'embedding_output_dim': 245, 'num_epochs': 84}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/104\n",
      "1/1 [==============================] - 10s 10s/step - loss: 11.7906 - accuracy: 0.0227\n",
      "Epoch 2/104\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 4.1240 - accuracy: 0.4545\n",
      "Epoch 3/104\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 3.2771 - accuracy: 0.4318\n",
      "Epoch 4/104\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 2.8862 - accuracy: 0.4318\n",
      "Epoch 5/104\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 3.1052 - accuracy: 0.4318\n",
      "Epoch 6/104\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 3.0646 - accuracy: 0.4318\n",
      "Epoch 7/104\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 3.0598 - accuracy: 0.4318\n",
      "Epoch 8/104\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 3.0507 - accuracy: 0.4318\n",
      "Epoch 9/104\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 3.0296 - accuracy: 0.4545\n",
      "Epoch 10/104\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 3.0182 - accuracy: 0.4318\n",
      "Epoch 11/104\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 3.0098 - accuracy: 0.4318\n",
      "Epoch 12/104\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 2.9620 - accuracy: 0.4318\n",
      "Epoch 13/104\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 2.9689 - accuracy: 0.4545\n",
      "Epoch 14/104\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 2.9489 - accuracy: 0.4773\n",
      "Epoch 15/104\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 2.9385 - accuracy: 0.4545\n",
      "Epoch 16/104\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.9302 - accuracy: 0.4773\n",
      "Epoch 17/104\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.9032 - accuracy: 0.4773\n",
      "Epoch 18/104\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 2.8965 - accuracy: 0.5000\n",
      "Epoch 19/104\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 2.8826 - accuracy: 0.5000\n",
      "Epoch 20/104\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.8834 - accuracy: 0.4773\n",
      "Epoch 21/104\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.8502 - accuracy: 0.5000\n",
      "Epoch 22/104\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.8451 - accuracy: 0.4773\n",
      "Epoch 23/104\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 2.8261 - accuracy: 0.5227\n",
      "Epoch 24/104\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.7942 - accuracy: 0.5682\n",
      "Epoch 25/104\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 2.7900 - accuracy: 0.5682\n",
      "Epoch 26/104\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 2.7646 - accuracy: 0.5909\n",
      "Epoch 27/104\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 2.4872 - accuracy: 0.5909\n",
      "Epoch 28/104\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.4616 - accuracy: 0.6364\n",
      "Epoch 29/104\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 2.4334 - accuracy: 0.6364\n",
      "Epoch 30/104\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 2.4096 - accuracy: 0.6591\n",
      "Epoch 31/104\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 2.4216 - accuracy: 0.6364\n",
      "Epoch 32/104\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 2.4159 - accuracy: 0.6136\n",
      "Epoch 33/104\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 2.3921 - accuracy: 0.6364\n",
      "Epoch 34/104\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 2.3622 - accuracy: 0.7045\n",
      "Epoch 35/104\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 2.3738 - accuracy: 0.6591\n",
      "Epoch 36/104\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 2.3406 - accuracy: 0.6818\n",
      "Epoch 37/104\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.3324 - accuracy: 0.6818\n",
      "Epoch 38/104\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 2.2915 - accuracy: 0.6818\n",
      "Epoch 39/104\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 2.2958 - accuracy: 0.7045\n",
      "Epoch 40/104\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.2699 - accuracy: 0.7273\n",
      "Epoch 41/104\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 2.2443 - accuracy: 0.7273\n",
      "Epoch 42/104\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.2183 - accuracy: 0.6818\n",
      "Epoch 43/104\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 2.2049 - accuracy: 0.7045\n",
      "Epoch 44/104\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.2090 - accuracy: 0.7045\n",
      "Epoch 45/104\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 2.1657 - accuracy: 0.7045\n",
      "Epoch 46/104\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.1565 - accuracy: 0.7273\n",
      "Epoch 47/104\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.1393 - accuracy: 0.7500\n",
      "Epoch 48/104\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 2.2045 - accuracy: 0.6818\n",
      "Epoch 49/104\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.1215 - accuracy: 0.7273\n",
      "Epoch 50/104\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 2.4789 - accuracy: 0.7045\n",
      "Epoch 51/104\n",
      "1/1 [==============================] - 0s 360ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 52/104\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/104\n",
      "1/1 [==============================] - 0s 353ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/104\n",
      "1/1 [==============================] - 0s 388ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/104\n",
      "1/1 [==============================] - 0s 391ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/104\n",
      "1/1 [==============================] - 0s 367ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/104\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/104\n",
      "1/1 [==============================] - 0s 300ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/104\n",
      "1/1 [==============================] - 0s 307ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/104\n",
      "1/1 [==============================] - 0s 332ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/104\n",
      "1/1 [==============================] - 0s 329ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/104\n",
      "1/1 [==============================] - 0s 317ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/104\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/104\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/104\n",
      "1/1 [==============================] - 0s 322ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/104\n",
      "1/1 [==============================] - 0s 328ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/104\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/104\n",
      "1/1 [==============================] - 0s 299ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/104\n",
      "1/1 [==============================] - 0s 344ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/104\n",
      "1/1 [==============================] - 0s 323ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/104\n",
      "1/1 [==============================] - 0s 349ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/104\n",
      "1/1 [==============================] - 0s 359ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/104\n",
      "1/1 [==============================] - 0s 362ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/104\n",
      "1/1 [==============================] - 0s 330ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/104\n",
      "1/1 [==============================] - 0s 322ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/104\n",
      "1/1 [==============================] - 0s 350ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/104\n",
      "1/1 [==============================] - 0s 364ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/104\n",
      "1/1 [==============================] - 0s 444ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/104\n",
      "1/1 [==============================] - 0s 353ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/104\n",
      "1/1 [==============================] - 0s 272ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/104\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/104\n",
      "1/1 [==============================] - 0s 254ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/104\n",
      "1/1 [==============================] - 0s 239ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/104\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/104\n",
      "1/1 [==============================] - 0s 394ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/104\n",
      "1/1 [==============================] - 0s 395ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/104\n",
      "1/1 [==============================] - 0s 336ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/104\n",
      "1/1 [==============================] - 0s 338ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/104\n",
      "1/1 [==============================] - 0s 342ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 90/104\n",
      "1/1 [==============================] - 0s 409ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 91/104\n",
      "1/1 [==============================] - 0s 370ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 92/104\n",
      "1/1 [==============================] - 0s 369ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 93/104\n",
      "1/1 [==============================] - 0s 347ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 94/104\n",
      "1/1 [==============================] - 0s 372ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 95/104\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 96/104\n",
      "1/1 [==============================] - 0s 319ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 97/104\n",
      "1/1 [==============================] - 0s 408ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 98/104\n",
      "1/1 [==============================] - 0s 476ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 99/104\n",
      "1/1 [==============================] - 0s 409ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 100/104\n",
      "1/1 [==============================] - 0s 343ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 101/104\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 102/104\n",
      "1/1 [==============================] - 0s 362ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 103/104\n",
      "1/1 [==============================] - 0s 344ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 104/104\n",
      "1/1 [==============================] - 0s 398ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff57009d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:45:49,460]\u001b[0m Trial 44 finished with value: 0.5 and parameters: {'embedding_output_dim': 221, 'num_epochs': 104}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/73\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.3087 - accuracy: 0.0455\n",
      "Epoch 2/73\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 3.6487 - accuracy: 0.3864\n",
      "Epoch 3/73\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 3.4821 - accuracy: 0.4773\n",
      "Epoch 4/73\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 2.8633 - accuracy: 0.4545\n",
      "Epoch 5/73\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2.7964 - accuracy: 0.5000\n",
      "Epoch 6/73\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.7568 - accuracy: 0.5227\n",
      "Epoch 7/73\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 2.6992 - accuracy: 0.5455\n",
      "Epoch 8/73\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 2.6820 - accuracy: 0.5227\n",
      "Epoch 9/73\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 2.3992 - accuracy: 0.6136\n",
      "Epoch 10/73\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.3814 - accuracy: 0.6136\n",
      "Epoch 11/73\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.3605 - accuracy: 0.5909\n",
      "Epoch 12/73\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 2.3361 - accuracy: 0.5909\n",
      "Epoch 13/73\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 2.3212 - accuracy: 0.6364\n",
      "Epoch 14/73\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 2.3112 - accuracy: 0.6591\n",
      "Epoch 15/73\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 2.2622 - accuracy: 0.6364\n",
      "Epoch 16/73\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 2.2670 - accuracy: 0.6591\n",
      "Epoch 17/73\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.2551 - accuracy: 0.6818\n",
      "Epoch 18/73\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 2.2680 - accuracy: 0.6818\n",
      "Epoch 19/73\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 2.2006 - accuracy: 0.6818\n",
      "Epoch 20/73\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 2.1949 - accuracy: 0.7045\n",
      "Epoch 21/73\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 2.1906 - accuracy: 0.6818\n",
      "Epoch 22/73\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.1634 - accuracy: 0.6818\n",
      "Epoch 23/73\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.1217 - accuracy: 0.6818\n",
      "Epoch 24/73\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.1205 - accuracy: 0.6818\n",
      "Epoch 25/73\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.0737 - accuracy: 0.6818\n",
      "Epoch 26/73\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 2.0776 - accuracy: 0.6818\n",
      "Epoch 27/73\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 2.0770 - accuracy: 0.6818\n",
      "Epoch 28/73\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 2.0650 - accuracy: 0.6591\n",
      "Epoch 29/73\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 2.0123 - accuracy: 0.7273\n",
      "Epoch 30/73\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 2.0112 - accuracy: 0.6818\n",
      "Epoch 31/73\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.9972 - accuracy: 0.7045\n",
      "Epoch 32/73\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 1.9666 - accuracy: 0.7273\n",
      "Epoch 33/73\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.9544 - accuracy: 0.6591\n",
      "Epoch 34/73\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 1.9379 - accuracy: 0.7045\n",
      "Epoch 35/73\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.9240 - accuracy: 0.6591\n",
      "Epoch 36/73\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 1.9338 - accuracy: 0.6818\n",
      "Epoch 37/73\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 1.9240 - accuracy: 0.6591\n",
      "Epoch 38/73\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.9003 - accuracy: 0.6818\n",
      "Epoch 39/73\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 1.8785 - accuracy: 0.7045\n",
      "Epoch 40/73\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 1.8676 - accuracy: 0.7045\n",
      "Epoch 41/73\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.8692 - accuracy: 0.7045\n",
      "Epoch 42/73\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.8475 - accuracy: 0.7273\n",
      "Epoch 43/73\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.8863 - accuracy: 0.7273\n",
      "Epoch 44/73\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 1.8435 - accuracy: 0.7273\n",
      "Epoch 45/73\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 1.9069 - accuracy: 0.6364\n",
      "Epoch 46/73\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 1.8539 - accuracy: 0.7045\n",
      "Epoch 47/73\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.8232 - accuracy: 0.7045\n",
      "Epoch 48/73\n",
      "1/1 [==============================] - 0s 317ms/step - loss: nan - accuracy: 0.6818\n",
      "Epoch 49/73\n",
      "1/1 [==============================] - 0s 262ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/73\n",
      "1/1 [==============================] - 0s 283ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/73\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/73\n",
      "1/1 [==============================] - 0s 360ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/73\n",
      "1/1 [==============================] - 0s 292ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/73\n",
      "1/1 [==============================] - 0s 279ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/73\n",
      "1/1 [==============================] - 0s 296ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/73\n",
      "1/1 [==============================] - 0s 296ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/73\n",
      "1/1 [==============================] - 0s 331ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/73\n",
      "1/1 [==============================] - 0s 228ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/73\n",
      "1/1 [==============================] - 0s 330ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/73\n",
      "1/1 [==============================] - 0s 230ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/73\n",
      "1/1 [==============================] - 0s 307ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/73\n",
      "1/1 [==============================] - 0s 269ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/73\n",
      "1/1 [==============================] - 0s 276ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/73\n",
      "1/1 [==============================] - 0s 288ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/73\n",
      "1/1 [==============================] - 0s 260ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/73\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/73\n",
      "1/1 [==============================] - 0s 337ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/73\n",
      "1/1 [==============================] - 0s 256ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/73\n",
      "1/1 [==============================] - 0s 262ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/73\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/73\n",
      "1/1 [==============================] - 0s 268ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/73\n",
      "1/1 [==============================] - 0s 340ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/73\n",
      "1/1 [==============================] - 0s 452ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff540283e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:46:21,919]\u001b[0m Trial 45 finished with value: 0.5 and parameters: {'embedding_output_dim': 210, 'num_epochs': 73}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.7218 - accuracy: 0.0455\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.8695 - accuracy: 0.3409\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 3.2116 - accuracy: 0.4318\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 3.3455 - accuracy: 0.4318\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.6706 - accuracy: 0.4318\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.6086 - accuracy: 0.4545\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.2636 - accuracy: 0.4545\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.5616 - accuracy: 0.4318\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.5416 - accuracy: 0.4318\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.4859 - accuracy: 0.4773\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.4870 - accuracy: 0.5227\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.1273 - accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.1550 - accuracy: 0.5909\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0890 - accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.1039 - accuracy: 0.5455\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.0694 - accuracy: 0.5455\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 2.0597 - accuracy: 0.5227\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.0621 - accuracy: 0.5455\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.0592 - accuracy: 0.5227\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.0508 - accuracy: 0.5227\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.0117 - accuracy: 0.6136\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.0191 - accuracy: 0.6136\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.9927 - accuracy: 0.6364\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.9999 - accuracy: 0.6364\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.9552 - accuracy: 0.6136\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.9656 - accuracy: 0.6364\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.9604 - accuracy: 0.6136\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.9336 - accuracy: 0.6364\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.9513 - accuracy: 0.6364\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9199 - accuracy: 0.6591\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.8998 - accuracy: 0.6364\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8754 - accuracy: 0.6136\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.8960 - accuracy: 0.6591\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8898 - accuracy: 0.6364\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8511 - accuracy: 0.6364\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.8294 - accuracy: 0.6364\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 1.8258 - accuracy: 0.6364\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.8162 - accuracy: 0.6364\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.8368 - accuracy: 0.6136\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.8106 - accuracy: 0.6591\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 1.7900 - accuracy: 0.6364\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.7765 - accuracy: 0.6364\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.7706 - accuracy: 0.6591\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.7668 - accuracy: 0.6364\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.7439 - accuracy: 0.6364\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.7256 - accuracy: 0.6591\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.7129 - accuracy: 0.6591\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.7020 - accuracy: 0.6364\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.6716 - accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.7052 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560fd2e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5144 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:46:40,324]\u001b[0m Trial 46 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 75, 'num_epochs': 50}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/115\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.0385 - accuracy: 0.0909\n",
      "Epoch 2/115\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 3.3290 - accuracy: 0.4545\n",
      "Epoch 3/115\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 3.0604 - accuracy: 0.4545\n",
      "Epoch 4/115\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.6214 - accuracy: 0.4773\n",
      "Epoch 5/115\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.6860 - accuracy: 0.3864\n",
      "Epoch 6/115\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.5947 - accuracy: 0.4773\n",
      "Epoch 7/115\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.6253 - accuracy: 0.3409\n",
      "Epoch 8/115\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.3426 - accuracy: 0.4091\n",
      "Epoch 9/115\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.3625 - accuracy: 0.4545\n",
      "Epoch 10/115\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.3571 - accuracy: 0.4318\n",
      "Epoch 11/115\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2.2998 - accuracy: 0.4091\n",
      "Epoch 12/115\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.2805 - accuracy: 0.5227\n",
      "Epoch 13/115\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.2837 - accuracy: 0.5227\n",
      "Epoch 14/115\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.2719 - accuracy: 0.4318\n",
      "Epoch 15/115\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.2094 - accuracy: 0.5455\n",
      "Epoch 16/115\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.2174 - accuracy: 0.5227\n",
      "Epoch 17/115\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.1734 - accuracy: 0.5909\n",
      "Epoch 18/115\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.1726 - accuracy: 0.5682\n",
      "Epoch 19/115\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.1175 - accuracy: 0.5909\n",
      "Epoch 20/115\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 2.1304 - accuracy: 0.5682\n",
      "Epoch 21/115\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 2.1015 - accuracy: 0.5682\n",
      "Epoch 22/115\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.0832 - accuracy: 0.5682\n",
      "Epoch 23/115\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.0679 - accuracy: 0.6136\n",
      "Epoch 24/115\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 2.0404 - accuracy: 0.5909\n",
      "Epoch 25/115\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.9964 - accuracy: 0.6136\n",
      "Epoch 26/115\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.9952 - accuracy: 0.6364\n",
      "Epoch 27/115\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.9980 - accuracy: 0.6364\n",
      "Epoch 28/115\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.2452 - accuracy: 0.5909\n",
      "Epoch 29/115\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 1.9543 - accuracy: 0.6591\n",
      "Epoch 30/115\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.9588 - accuracy: 0.6364\n",
      "Epoch 31/115\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.9111 - accuracy: 0.6364\n",
      "Epoch 32/115\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.8849 - accuracy: 0.6591\n",
      "Epoch 33/115\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.8846 - accuracy: 0.6136\n",
      "Epoch 34/115\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.8641 - accuracy: 0.6136\n",
      "Epoch 35/115\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.8899 - accuracy: 0.6364\n",
      "Epoch 36/115\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.8548 - accuracy: 0.6591\n",
      "Epoch 37/115\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.8401 - accuracy: 0.6364\n",
      "Epoch 38/115\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.8176 - accuracy: 0.6136\n",
      "Epoch 39/115\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.8603 - accuracy: 0.6591\n",
      "Epoch 40/115\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.7708 - accuracy: 0.6818\n",
      "Epoch 41/115\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.7862 - accuracy: 0.6591\n",
      "Epoch 42/115\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.7783 - accuracy: 0.6364\n",
      "Epoch 43/115\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.7540 - accuracy: 0.6364\n",
      "Epoch 44/115\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.7459 - accuracy: 0.6364\n",
      "Epoch 45/115\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.7511 - accuracy: 0.6364\n",
      "Epoch 46/115\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.6904 - accuracy: 0.6591\n",
      "Epoch 47/115\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.7160 - accuracy: 0.6591\n",
      "Epoch 48/115\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.7045 - accuracy: 0.6818\n",
      "Epoch 49/115\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.6807 - accuracy: 0.6591\n",
      "Epoch 50/115\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.6760 - accuracy: 0.6364\n",
      "Epoch 51/115\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.6949 - accuracy: 0.6591\n",
      "Epoch 52/115\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.6653 - accuracy: 0.6364\n",
      "Epoch 53/115\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.6212 - accuracy: 0.6591\n",
      "Epoch 54/115\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.6280 - accuracy: 0.6364\n",
      "Epoch 55/115\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.6596 - accuracy: 0.6591\n",
      "Epoch 56/115\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.6547 - accuracy: 0.6818\n",
      "Epoch 57/115\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.5945 - accuracy: 0.7045\n",
      "Epoch 58/115\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.6314 - accuracy: 0.6591\n",
      "Epoch 59/115\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.6165 - accuracy: 0.6591\n",
      "Epoch 60/115\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.5916 - accuracy: 0.6818\n",
      "Epoch 61/115\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.5891 - accuracy: 0.6818\n",
      "Epoch 62/115\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.5902 - accuracy: 0.6818\n",
      "Epoch 63/115\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.5798 - accuracy: 0.7045\n",
      "Epoch 64/115\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.5475 - accuracy: 0.7273\n",
      "Epoch 65/115\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.5631 - accuracy: 0.7273\n",
      "Epoch 66/115\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.5490 - accuracy: 0.6591\n",
      "Epoch 67/115\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.5369 - accuracy: 0.6591\n",
      "Epoch 68/115\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.5123 - accuracy: 0.6591\n",
      "Epoch 69/115\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.5246 - accuracy: 0.7045\n",
      "Epoch 70/115\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.5179 - accuracy: 0.6818\n",
      "Epoch 71/115\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.5271 - accuracy: 0.7045\n",
      "Epoch 72/115\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1.5029 - accuracy: 0.7045\n",
      "Epoch 73/115\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.4989 - accuracy: 0.7045\n",
      "Epoch 74/115\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.5351 - accuracy: 0.7045\n",
      "Epoch 75/115\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.5781 - accuracy: 0.7273\n",
      "Epoch 76/115\n",
      "1/1 [==============================] - 0s 166ms/step - loss: nan - accuracy: 0.6591\n",
      "Epoch 77/115\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/115\n",
      "1/1 [==============================] - 0s 133ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/115\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/115\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/115\n",
      "1/1 [==============================] - 0s 131ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/115\n",
      "1/1 [==============================] - 0s 158ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/115\n",
      "1/1 [==============================] - 0s 174ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/115\n",
      "1/1 [==============================] - 0s 163ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/115\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/115\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/115\n",
      "1/1 [==============================] - 0s 140ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/115\n",
      "1/1 [==============================] - 0s 79ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/115\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 90/115\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 91/115\n",
      "1/1 [==============================] - 0s 151ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 92/115\n",
      "1/1 [==============================] - 0s 127ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 93/115\n",
      "1/1 [==============================] - 0s 165ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 94/115\n",
      "1/1 [==============================] - 0s 136ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 95/115\n",
      "1/1 [==============================] - 0s 225ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 96/115\n",
      "1/1 [==============================] - 0s 196ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 97/115\n",
      "1/1 [==============================] - 0s 165ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 98/115\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 99/115\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 100/115\n",
      "1/1 [==============================] - 0s 131ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 101/115\n",
      "1/1 [==============================] - 0s 147ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 102/115\n",
      "1/1 [==============================] - 0s 164ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 103/115\n",
      "1/1 [==============================] - 0s 165ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 104/115\n",
      "1/1 [==============================] - 0s 141ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 105/115\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 106/115\n",
      "1/1 [==============================] - 0s 144ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 107/115\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 108/115\n",
      "1/1 [==============================] - 0s 153ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 109/115\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 110/115\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 111/115\n",
      "1/1 [==============================] - 0s 235ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 112/115\n",
      "1/1 [==============================] - 0s 164ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 113/115\n",
      "1/1 [==============================] - 0s 139ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 114/115\n",
      "1/1 [==============================] - 0s 148ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 115/115\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff542a24430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:47:10,143]\u001b[0m Trial 47 finished with value: 0.5 and parameters: {'embedding_output_dim': 98, 'num_epochs': 115}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/60\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.2370 - accuracy: 0.0455\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 3.1823 - accuracy: 0.5455\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.4560 - accuracy: 0.5455\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.1533 - accuracy: 0.5455\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 2.1158 - accuracy: 0.5455\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.8093 - accuracy: 0.5682\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.5165 - accuracy: 0.5455\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.4130 - accuracy: 0.5682\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.3505 - accuracy: 0.5455\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.3091 - accuracy: 0.6136\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.3362 - accuracy: 0.6364\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.3423 - accuracy: 0.5909\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 1.3281 - accuracy: 0.6364\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 1.3150 - accuracy: 0.6136\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.2825 - accuracy: 0.6136\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.2713 - accuracy: 0.6364\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.2518 - accuracy: 0.6364\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.2350 - accuracy: 0.6364\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.2191 - accuracy: 0.6364\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.2070 - accuracy: 0.6591\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.1898 - accuracy: 0.6364\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.1853 - accuracy: 0.6364\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.1225 - accuracy: 0.6364\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.1151 - accuracy: 0.6364\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.1235 - accuracy: 0.6136\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.0826 - accuracy: 0.6364\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.0682 - accuracy: 0.6591\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.0497 - accuracy: 0.6591\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.0250 - accuracy: 0.6364\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.0008 - accuracy: 0.6364\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9680 - accuracy: 0.6818\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9588 - accuracy: 0.6136\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.9652 - accuracy: 0.6364\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.9623 - accuracy: 0.6364\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9490 - accuracy: 0.6364\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.9293 - accuracy: 0.6591\n",
      "Epoch 37/60\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8917 - accuracy: 0.6364\n",
      "Epoch 38/60\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.9063 - accuracy: 0.6364\n",
      "Epoch 39/60\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8799 - accuracy: 0.6364\n",
      "Epoch 40/60\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.8755 - accuracy: 0.6591\n",
      "Epoch 41/60\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8557 - accuracy: 0.6591\n",
      "Epoch 42/60\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8620 - accuracy: 0.6818\n",
      "Epoch 43/60\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8393 - accuracy: 0.6364\n",
      "Epoch 44/60\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.8221 - accuracy: 0.6591\n",
      "Epoch 45/60\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.8084 - accuracy: 0.6591\n",
      "Epoch 46/60\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7817 - accuracy: 0.6818\n",
      "Epoch 47/60\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7744 - accuracy: 0.6591\n",
      "Epoch 48/60\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7497 - accuracy: 0.6364\n",
      "Epoch 49/60\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7366 - accuracy: 0.6818\n",
      "Epoch 50/60\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.7254 - accuracy: 0.6818\n",
      "Epoch 51/60\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.7362 - accuracy: 0.6591\n",
      "Epoch 52/60\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.6943 - accuracy: 0.6591\n",
      "Epoch 53/60\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6920 - accuracy: 0.6818\n",
      "Epoch 54/60\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.6942 - accuracy: 0.7273\n",
      "Epoch 55/60\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.6762 - accuracy: 0.7273\n",
      "Epoch 56/60\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6571 - accuracy: 0.6818\n",
      "Epoch 57/60\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.6529 - accuracy: 0.6818\n",
      "Epoch 58/60\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6340 - accuracy: 0.6364\n",
      "Epoch 59/60\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.6137 - accuracy: 0.7045\n",
      "Epoch 60/60\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.6087 - accuracy: 0.6591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560b8b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4800 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:47:35,208]\u001b[0m Trial 48 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 184, 'num_epochs': 60}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/139\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.8128 - accuracy: 0.1364\n",
      "Epoch 2/139\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.0871 - accuracy: 0.3864\n",
      "Epoch 3/139\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 4.1531 - accuracy: 0.4773\n",
      "Epoch 4/139\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.0565 - accuracy: 0.5455\n",
      "Epoch 5/139\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.7427 - accuracy: 0.6364\n",
      "Epoch 6/139\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 3.6949 - accuracy: 0.6364\n",
      "Epoch 7/139\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 3.6525 - accuracy: 0.6591\n",
      "Epoch 8/139\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 3.4186 - accuracy: 0.4545\n",
      "Epoch 9/139\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 3.3165 - accuracy: 0.5455\n",
      "Epoch 10/139\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 3.0301 - accuracy: 0.5455\n",
      "Epoch 11/139\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.9919 - accuracy: 0.5682\n",
      "Epoch 12/139\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.9888 - accuracy: 0.5909\n",
      "Epoch 13/139\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.9803 - accuracy: 0.5455\n",
      "Epoch 14/139\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.9703 - accuracy: 0.6364\n",
      "Epoch 15/139\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.8981 - accuracy: 0.6364\n",
      "Epoch 16/139\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9255 - accuracy: 0.5909\n",
      "Epoch 17/139\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.8939 - accuracy: 0.5909\n",
      "Epoch 18/139\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.8786 - accuracy: 0.6364\n",
      "Epoch 19/139\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.8607 - accuracy: 0.5455\n",
      "Epoch 20/139\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.8405 - accuracy: 0.6364\n",
      "Epoch 21/139\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.8038 - accuracy: 0.6364\n",
      "Epoch 22/139\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.8091 - accuracy: 0.5909\n",
      "Epoch 23/139\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.7898 - accuracy: 0.6364\n",
      "Epoch 24/139\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.7926 - accuracy: 0.6364\n",
      "Epoch 25/139\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.7631 - accuracy: 0.6364\n",
      "Epoch 26/139\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.7281 - accuracy: 0.6364\n",
      "Epoch 27/139\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.7510 - accuracy: 0.6364\n",
      "Epoch 28/139\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.7372 - accuracy: 0.6591\n",
      "Epoch 29/139\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.7326 - accuracy: 0.6364\n",
      "Epoch 30/139\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.6937 - accuracy: 0.6364\n",
      "Epoch 31/139\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.6687 - accuracy: 0.6136\n",
      "Epoch 32/139\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.6717 - accuracy: 0.6364\n",
      "Epoch 33/139\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.6488 - accuracy: 0.6818\n",
      "Epoch 34/139\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.6620 - accuracy: 0.6364\n",
      "Epoch 35/139\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.6820 - accuracy: 0.6364\n",
      "Epoch 36/139\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.6184 - accuracy: 0.6591\n",
      "Epoch 37/139\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 2.6030 - accuracy: 0.6818\n",
      "Epoch 38/139\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.6155 - accuracy: 0.6591\n",
      "Epoch 39/139\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.5778 - accuracy: 0.6818\n",
      "Epoch 40/139\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.5918 - accuracy: 0.6364\n",
      "Epoch 41/139\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.5732 - accuracy: 0.6591\n",
      "Epoch 42/139\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.5845 - accuracy: 0.6818\n",
      "Epoch 43/139\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.5514 - accuracy: 0.6591\n",
      "Epoch 44/139\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.5485 - accuracy: 0.6818\n",
      "Epoch 45/139\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.5221 - accuracy: 0.7045\n",
      "Epoch 46/139\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.8896 - accuracy: 0.6591\n",
      "Epoch 47/139\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.5726 - accuracy: 0.6818\n",
      "Epoch 48/139\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.6490 - accuracy: 0.6818\n",
      "Epoch 49/139\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.5404 - accuracy: 0.6818\n",
      "Epoch 50/139\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.5370 - accuracy: 0.7045\n",
      "Epoch 51/139\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.5652 - accuracy: 0.6818\n",
      "Epoch 52/139\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.5556 - accuracy: 0.6364\n",
      "Epoch 53/139\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.6197 - accuracy: 0.6364\n",
      "Epoch 54/139\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.9283 - accuracy: 0.5909\n",
      "Epoch 55/139\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 3.0110 - accuracy: 0.5682\n",
      "Epoch 56/139\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 3.0238 - accuracy: 0.5909\n",
      "Epoch 57/139\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.7102 - accuracy: 0.5682\n",
      "Epoch 58/139\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.9484 - accuracy: 0.6364\n",
      "Epoch 59/139\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.9731 - accuracy: 0.6364\n",
      "Epoch 60/139\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.6077 - accuracy: 0.6364\n",
      "Epoch 61/139\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.9688 - accuracy: 0.6136\n",
      "Epoch 62/139\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.6043 - accuracy: 0.7045\n",
      "Epoch 63/139\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.3135 - accuracy: 0.6818\n",
      "Epoch 64/139\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.5983 - accuracy: 0.6591\n",
      "Epoch 65/139\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.6416 - accuracy: 0.6818\n",
      "Epoch 66/139\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.3153 - accuracy: 0.6591\n",
      "Epoch 67/139\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.3255 - accuracy: 0.6591\n",
      "Epoch 68/139\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.3279 - accuracy: 0.6591\n",
      "Epoch 69/139\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.3150 - accuracy: 0.6364\n",
      "Epoch 70/139\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.2716 - accuracy: 0.6364\n",
      "Epoch 71/139\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.2709 - accuracy: 0.6818\n",
      "Epoch 72/139\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.6073 - accuracy: 0.6364\n",
      "Epoch 73/139\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.2834 - accuracy: 0.6818\n",
      "Epoch 74/139\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.2638 - accuracy: 0.6818\n",
      "Epoch 75/139\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.2568 - accuracy: 0.7273\n",
      "Epoch 76/139\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.2793 - accuracy: 0.6818\n",
      "Epoch 77/139\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 2.2829 - accuracy: 0.6818\n",
      "Epoch 78/139\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.2103 - accuracy: 0.7045\n",
      "Epoch 79/139\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.2189 - accuracy: 0.6818\n",
      "Epoch 80/139\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.2103 - accuracy: 0.7045\n",
      "Epoch 81/139\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.2661 - accuracy: 0.6818\n",
      "Epoch 82/139\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.1739 - accuracy: 0.7273\n",
      "Epoch 83/139\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2480 - accuracy: 0.7273\n",
      "Epoch 84/139\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.2425 - accuracy: 0.7045\n",
      "Epoch 85/139\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2382 - accuracy: 0.6818\n",
      "Epoch 86/139\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2352 - accuracy: 0.6364\n",
      "Epoch 87/139\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.1986 - accuracy: 0.6818\n",
      "Epoch 88/139\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.8960 - accuracy: 0.6818\n",
      "Epoch 89/139\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.1955 - accuracy: 0.6591\n",
      "Epoch 90/139\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.2107 - accuracy: 0.7500\n",
      "Epoch 91/139\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.9793 - accuracy: 0.6136\n",
      "Epoch 92/139\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.2489 - accuracy: 0.7045\n",
      "Epoch 93/139\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8997 - accuracy: 0.6818\n",
      "Epoch 94/139\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.8553 - accuracy: 0.7273\n",
      "Epoch 95/139\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.8698 - accuracy: 0.7500\n",
      "Epoch 96/139\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.8793 - accuracy: 0.6364\n",
      "Epoch 97/139\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8803 - accuracy: 0.7045\n",
      "Epoch 98/139\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2202 - accuracy: 0.6818\n",
      "Epoch 99/139\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.8614 - accuracy: 0.7273\n",
      "Epoch 100/139\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8842 - accuracy: 0.6818\n",
      "Epoch 101/139\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.8662 - accuracy: 0.7273\n",
      "Epoch 102/139\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.8824 - accuracy: 0.6818\n",
      "Epoch 103/139\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.7913 - accuracy: 0.7273\n",
      "Epoch 104/139\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8800 - accuracy: 0.7500\n",
      "Epoch 105/139\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.8222 - accuracy: 0.7045\n",
      "Epoch 106/139\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.8255 - accuracy: 0.7500\n",
      "Epoch 107/139\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.8390 - accuracy: 0.7500\n",
      "Epoch 108/139\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.8216 - accuracy: 0.6818\n",
      "Epoch 109/139\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.8104 - accuracy: 0.6818\n",
      "Epoch 110/139\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.8238 - accuracy: 0.7273\n",
      "Epoch 111/139\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.7928 - accuracy: 0.7273\n",
      "Epoch 112/139\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7972 - accuracy: 0.7045\n",
      "Epoch 113/139\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.8068 - accuracy: 0.6818\n",
      "Epoch 114/139\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8222 - accuracy: 0.6818\n",
      "Epoch 115/139\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.8352 - accuracy: 0.7045\n",
      "Epoch 116/139\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.8482 - accuracy: 0.6818\n",
      "Epoch 117/139\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.7824 - accuracy: 0.7273\n",
      "Epoch 118/139\n",
      "1/1 [==============================] - 0s 168ms/step - loss: nan - accuracy: 0.7273\n",
      "Epoch 119/139\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 120/139\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 121/139\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 122/139\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 123/139\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 124/139\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 125/139\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 126/139\n",
      "1/1 [==============================] - 0s 153ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 127/139\n",
      "1/1 [==============================] - 0s 100ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 128/139\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 129/139\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 130/139\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 131/139\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 132/139\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 133/139\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 134/139\n",
      "1/1 [==============================] - 0s 91ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 135/139\n",
      "1/1 [==============================] - 0s 137ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 136/139\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 137/139\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 138/139\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 139/139\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5107a99d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:48:05,090]\u001b[0m Trial 49 finished with value: 0.5 and parameters: {'embedding_output_dim': 53, 'num_epochs': 139}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/41\n",
      "1/1 [==============================] - 10s 10s/step - loss: 6.4434 - accuracy: 0.0455\n",
      "Epoch 2/41\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.9061 - accuracy: 0.2727\n",
      "Epoch 3/41\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.6137 - accuracy: 0.4545\n",
      "Epoch 4/41\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.8168 - accuracy: 0.4545\n",
      "Epoch 5/41\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.6565 - accuracy: 0.6364\n",
      "Epoch 6/41\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.5630 - accuracy: 0.6364\n",
      "Epoch 7/41\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.2664 - accuracy: 0.6364\n",
      "Epoch 8/41\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.1845 - accuracy: 0.6364\n",
      "Epoch 9/41\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.1145 - accuracy: 0.6364\n",
      "Epoch 10/41\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.0942 - accuracy: 0.6136\n",
      "Epoch 11/41\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.1098 - accuracy: 0.6364\n",
      "Epoch 12/41\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 1.0980 - accuracy: 0.6591\n",
      "Epoch 13/41\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.0429 - accuracy: 0.6591\n",
      "Epoch 14/41\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1.0245 - accuracy: 0.6364\n",
      "Epoch 15/41\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.0189 - accuracy: 0.6591\n",
      "Epoch 16/41\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.9886 - accuracy: 0.6364\n",
      "Epoch 17/41\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.9200 - accuracy: 0.6591\n",
      "Epoch 18/41\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.8979 - accuracy: 0.6818\n",
      "Epoch 19/41\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.8913 - accuracy: 0.6591\n",
      "Epoch 20/41\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8561 - accuracy: 0.6818\n",
      "Epoch 21/41\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8222 - accuracy: 0.6364\n",
      "Epoch 22/41\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8062 - accuracy: 0.6364\n",
      "Epoch 23/41\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.7833 - accuracy: 0.6818\n",
      "Epoch 24/41\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7284 - accuracy: 0.6136\n",
      "Epoch 25/41\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7321 - accuracy: 0.7045\n",
      "Epoch 26/41\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7146 - accuracy: 0.6591\n",
      "Epoch 27/41\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.6874 - accuracy: 0.6591\n",
      "Epoch 28/41\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.6787 - accuracy: 0.6591\n",
      "Epoch 29/41\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6640 - accuracy: 0.6591\n",
      "Epoch 30/41\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.6296 - accuracy: 0.6818\n",
      "Epoch 31/41\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.6191 - accuracy: 0.6591\n",
      "Epoch 32/41\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.5745 - accuracy: 0.7273\n",
      "Epoch 33/41\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5755 - accuracy: 0.7500\n",
      "Epoch 34/41\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5884 - accuracy: 0.7045\n",
      "Epoch 35/41\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5792 - accuracy: 0.7045\n",
      "Epoch 36/41\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6175 - accuracy: 0.7045\n",
      "Epoch 37/41\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9704 - accuracy: 0.7045\n",
      "Epoch 38/41\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7661 - accuracy: 0.5909\n",
      "Epoch 39/41\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.0780 - accuracy: 0.6364\n",
      "Epoch 40/41\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7223 - accuracy: 0.6364\n",
      "Epoch 41/41\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7196 - accuracy: 0.6136\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5701efd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4777 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:48:25,514]\u001b[0m Trial 50 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 163, 'num_epochs': 41}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/70\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.4203 - accuracy: 0.0227\n",
      "Epoch 2/70\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 4.9715 - accuracy: 0.3864\n",
      "Epoch 3/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 3.2434 - accuracy: 0.4318\n",
      "Epoch 4/70\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.6781 - accuracy: 0.4545\n",
      "Epoch 5/70\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.6426 - accuracy: 0.4773\n",
      "Epoch 6/70\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.5666 - accuracy: 0.4773\n",
      "Epoch 7/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.8875 - accuracy: 0.5455\n",
      "Epoch 8/70\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.5400 - accuracy: 0.4545\n",
      "Epoch 9/70\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.7943 - accuracy: 0.4545\n",
      "Epoch 10/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.4879 - accuracy: 0.5909\n",
      "Epoch 11/70\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 2.4662 - accuracy: 0.5682\n",
      "Epoch 12/70\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.4583 - accuracy: 0.5909\n",
      "Epoch 13/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.4458 - accuracy: 0.5909\n",
      "Epoch 14/70\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.4345 - accuracy: 0.6136\n",
      "Epoch 15/70\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.3971 - accuracy: 0.6364\n",
      "Epoch 16/70\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.3735 - accuracy: 0.6364\n",
      "Epoch 17/70\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.3720 - accuracy: 0.6136\n",
      "Epoch 18/70\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.3726 - accuracy: 0.6818\n",
      "Epoch 19/70\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.3605 - accuracy: 0.5909\n",
      "Epoch 20/70\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 2.3485 - accuracy: 0.6591\n",
      "Epoch 21/70\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.3174 - accuracy: 0.6364\n",
      "Epoch 22/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.2967 - accuracy: 0.5682\n",
      "Epoch 23/70\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.3235 - accuracy: 0.5909\n",
      "Epoch 24/70\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.2906 - accuracy: 0.6136\n",
      "Epoch 25/70\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.2889 - accuracy: 0.6136\n",
      "Epoch 26/70\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.2651 - accuracy: 0.5909\n",
      "Epoch 27/70\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.2443 - accuracy: 0.5455\n",
      "Epoch 28/70\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.2356 - accuracy: 0.5909\n",
      "Epoch 29/70\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.2048 - accuracy: 0.6136\n",
      "Epoch 30/70\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.1956 - accuracy: 0.6364\n",
      "Epoch 31/70\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.1875 - accuracy: 0.5909\n",
      "Epoch 32/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.2126 - accuracy: 0.5909\n",
      "Epoch 33/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.1885 - accuracy: 0.5909\n",
      "Epoch 34/70\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.1691 - accuracy: 0.6136\n",
      "Epoch 35/70\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.1665 - accuracy: 0.6364\n",
      "Epoch 36/70\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.1604 - accuracy: 0.6364\n",
      "Epoch 37/70\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 2.1612 - accuracy: 0.6364\n",
      "Epoch 38/70\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.1226 - accuracy: 0.6364\n",
      "Epoch 39/70\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.1190 - accuracy: 0.6364\n",
      "Epoch 40/70\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.1065 - accuracy: 0.6364\n",
      "Epoch 41/70\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 2.1151 - accuracy: 0.6136\n",
      "Epoch 42/70\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.0843 - accuracy: 0.6591\n",
      "Epoch 43/70\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0738 - accuracy: 0.6818\n",
      "Epoch 44/70\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0590 - accuracy: 0.7045\n",
      "Epoch 45/70\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.0578 - accuracy: 0.6591\n",
      "Epoch 46/70\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.0744 - accuracy: 0.6818\n",
      "Epoch 47/70\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0345 - accuracy: 0.6818\n",
      "Epoch 48/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.0247 - accuracy: 0.6364\n",
      "Epoch 49/70\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.0402 - accuracy: 0.6591\n",
      "Epoch 50/70\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.0248 - accuracy: 0.7273\n",
      "Epoch 51/70\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.9962 - accuracy: 0.6818\n",
      "Epoch 52/70\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.9973 - accuracy: 0.7045\n",
      "Epoch 53/70\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.9877 - accuracy: 0.6591\n",
      "Epoch 54/70\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.9788 - accuracy: 0.6591\n",
      "Epoch 55/70\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.9806 - accuracy: 0.6818\n",
      "Epoch 56/70\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.9651 - accuracy: 0.7273\n",
      "Epoch 57/70\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.9396 - accuracy: 0.7273\n",
      "Epoch 58/70\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.9246 - accuracy: 0.6818\n",
      "Epoch 59/70\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.9440 - accuracy: 0.7273\n",
      "Epoch 60/70\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.9405 - accuracy: 0.6818\n",
      "Epoch 61/70\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.8950 - accuracy: 0.7045\n",
      "Epoch 62/70\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.9407 - accuracy: 0.6818\n",
      "Epoch 63/70\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.8882 - accuracy: 0.7273\n",
      "Epoch 64/70\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.9151 - accuracy: 0.6818\n",
      "Epoch 65/70\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.8460 - accuracy: 0.7045\n",
      "Epoch 66/70\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.8555 - accuracy: 0.7045\n",
      "Epoch 67/70\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.8945 - accuracy: 0.7273\n",
      "Epoch 68/70\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.8501 - accuracy: 0.7045\n",
      "Epoch 69/70\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.8681 - accuracy: 0.7045\n",
      "Epoch 70/70\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.8522 - accuracy: 0.7045\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e04df1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0394 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:48:47,105]\u001b[0m Trial 51 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 78, 'num_epochs': 70}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.2295 - accuracy: 0.1364\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 4.0124 - accuracy: 0.3864\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 4.0661 - accuracy: 0.2727\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.4787 - accuracy: 0.4091\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 3.4796 - accuracy: 0.3409\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 3.1458 - accuracy: 0.3636\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.8838 - accuracy: 0.4091\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 3.0551 - accuracy: 0.3636\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 2.9438 - accuracy: 0.1818\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 2.7606 - accuracy: 0.3182\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.7440 - accuracy: 0.4773\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.6841 - accuracy: 0.5227\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.7161 - accuracy: 0.5227\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 3.0261 - accuracy: 0.3864\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.8495 - accuracy: 0.3636\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.8277 - accuracy: 0.4318\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.7845 - accuracy: 0.4318\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.7492 - accuracy: 0.3636\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.7326 - accuracy: 0.5909\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 2.7419 - accuracy: 0.4773\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.7237 - accuracy: 0.4545\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.6925 - accuracy: 0.5455\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.6940 - accuracy: 0.5455\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.7060 - accuracy: 0.5227\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2.6576 - accuracy: 0.5000\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.4091 - accuracy: 0.4545\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.6258 - accuracy: 0.4545\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.6487 - accuracy: 0.4773\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.6111 - accuracy: 0.4773\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.6381 - accuracy: 0.4318\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.6430 - accuracy: 0.4773\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.5585 - accuracy: 0.4773\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.5411 - accuracy: 0.4773\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.4851 - accuracy: 0.4545\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.4989 - accuracy: 0.4318\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.5015 - accuracy: 0.4318\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.4613 - accuracy: 0.4318\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.4492 - accuracy: 0.4773\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.4280 - accuracy: 0.4318\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.3939 - accuracy: 0.4318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c6b38b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5215 - accuracy: 0.3182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:49:03,647]\u001b[0m Trial 52 finished with value: 0.3181818127632141 and parameters: {'embedding_output_dim': 26, 'num_epochs': 40}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/34\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.0773 - accuracy: 0.0909\n",
      "Epoch 2/34\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 4.5148 - accuracy: 0.5227\n",
      "Epoch 3/34\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 3.0475 - accuracy: 0.5909\n",
      "Epoch 4/34\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 3.0554 - accuracy: 0.6364\n",
      "Epoch 5/34\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.9861 - accuracy: 0.6818\n",
      "Epoch 6/34\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.9668 - accuracy: 0.6364\n",
      "Epoch 7/34\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.9184 - accuracy: 0.7045\n",
      "Epoch 8/34\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 2.8863 - accuracy: 0.7045\n",
      "Epoch 9/34\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.8540 - accuracy: 0.6818\n",
      "Epoch 10/34\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.8110 - accuracy: 0.6818\n",
      "Epoch 11/34\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.7739 - accuracy: 0.6136\n",
      "Epoch 12/34\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.7567 - accuracy: 0.6591\n",
      "Epoch 13/34\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.7087 - accuracy: 0.6591\n",
      "Epoch 14/34\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.6731 - accuracy: 0.6591\n",
      "Epoch 15/34\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 2.6935 - accuracy: 0.6591\n",
      "Epoch 16/34\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.6574 - accuracy: 0.6591\n",
      "Epoch 17/34\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.6149 - accuracy: 0.6818\n",
      "Epoch 18/34\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 2.5979 - accuracy: 0.6364\n",
      "Epoch 19/34\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.5917 - accuracy: 0.6364\n",
      "Epoch 20/34\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2.5658 - accuracy: 0.6136\n",
      "Epoch 21/34\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.5389 - accuracy: 0.6818\n",
      "Epoch 22/34\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 2.5450 - accuracy: 0.7045\n",
      "Epoch 23/34\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.5562 - accuracy: 0.7045\n",
      "Epoch 24/34\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 2.5127 - accuracy: 0.7045\n",
      "Epoch 25/34\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.5266 - accuracy: 0.6591\n",
      "Epoch 26/34\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 2.5208 - accuracy: 0.6591\n",
      "Epoch 27/34\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 2.5013 - accuracy: 0.6818\n",
      "Epoch 28/34\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.4705 - accuracy: 0.7045\n",
      "Epoch 29/34\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.4762 - accuracy: 0.6818\n",
      "Epoch 30/34\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 31/34\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 32/34\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 33/34\n",
      "1/1 [==============================] - 0s 254ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 34/34\n",
      "1/1 [==============================] - 0s 275ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4db223c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:49:21,895]\u001b[0m Trial 53 finished with value: 0.5 and parameters: {'embedding_output_dim': 162, 'num_epochs': 34}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/77\n",
      "1/1 [==============================] - 10s 10s/step - loss: 11.1913 - accuracy: 0.0682\n",
      "Epoch 2/77\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 7.9555 - accuracy: 0.0227\n",
      "Epoch 3/77\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 3.3099 - accuracy: 0.0227\n",
      "Epoch 4/77\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 2.7799 - accuracy: 0.0682\n",
      "Epoch 5/77\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 2.6786 - accuracy: 0.1136\n",
      "Epoch 6/77\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 2.6549 - accuracy: 0.1136\n",
      "Epoch 7/77\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.5572 - accuracy: 0.2045\n",
      "Epoch 8/77\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.6051 - accuracy: 0.3864\n",
      "Epoch 9/77\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 2.4866 - accuracy: 0.4545\n",
      "Epoch 10/77\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 2.5096 - accuracy: 0.4545\n",
      "Epoch 11/77\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 2.4817 - accuracy: 0.5000\n",
      "Epoch 12/77\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 2.4983 - accuracy: 0.4773\n",
      "Epoch 13/77\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 2.4510 - accuracy: 0.5455\n",
      "Epoch 14/77\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 2.4460 - accuracy: 0.5227\n",
      "Epoch 15/77\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 2.4122 - accuracy: 0.5682\n",
      "Epoch 16/77\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 2.4193 - accuracy: 0.5227\n",
      "Epoch 17/77\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 2.3910 - accuracy: 0.5682\n",
      "Epoch 18/77\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.3365 - accuracy: 0.5455\n",
      "Epoch 19/77\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.3213 - accuracy: 0.5227\n",
      "Epoch 20/77\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.2960 - accuracy: 0.5682\n",
      "Epoch 21/77\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 2.2472 - accuracy: 0.6136\n",
      "Epoch 22/77\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 2.2237 - accuracy: 0.5909\n",
      "Epoch 23/77\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 2.1624 - accuracy: 0.5455\n",
      "Epoch 24/77\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 2.1542 - accuracy: 0.6136\n",
      "Epoch 25/77\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 2.1135 - accuracy: 0.5909\n",
      "Epoch 26/77\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 2.0853 - accuracy: 0.6136\n",
      "Epoch 27/77\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 2.0516 - accuracy: 0.6364\n",
      "Epoch 28/77\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 2.0061 - accuracy: 0.6364\n",
      "Epoch 29/77\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 2.0145 - accuracy: 0.6364\n",
      "Epoch 30/77\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 1.9876 - accuracy: 0.6364\n",
      "Epoch 31/77\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.9577 - accuracy: 0.6364\n",
      "Epoch 32/77\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.9413 - accuracy: 0.6364\n",
      "Epoch 33/77\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 1.9154 - accuracy: 0.6591\n",
      "Epoch 34/77\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.8891 - accuracy: 0.6591\n",
      "Epoch 35/77\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.8817 - accuracy: 0.6591\n",
      "Epoch 36/77\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 1.8708 - accuracy: 0.6364\n",
      "Epoch 37/77\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.8459 - accuracy: 0.6818\n",
      "Epoch 38/77\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.8189 - accuracy: 0.6818\n",
      "Epoch 39/77\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.8526 - accuracy: 0.6818\n",
      "Epoch 40/77\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 1.8147 - accuracy: 0.6818\n",
      "Epoch 41/77\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 1.7978 - accuracy: 0.6591\n",
      "Epoch 42/77\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.8180 - accuracy: 0.6591\n",
      "Epoch 43/77\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.7744 - accuracy: 0.6591\n",
      "Epoch 44/77\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 1.7599 - accuracy: 0.6591\n",
      "Epoch 45/77\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1.7434 - accuracy: 0.6591\n",
      "Epoch 46/77\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.7280 - accuracy: 0.6818\n",
      "Epoch 47/77\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.7031 - accuracy: 0.6364\n",
      "Epoch 48/77\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.7118 - accuracy: 0.6591\n",
      "Epoch 49/77\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.7246 - accuracy: 0.6136\n",
      "Epoch 50/77\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.6891 - accuracy: 0.6818\n",
      "Epoch 51/77\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 1.6607 - accuracy: 0.6136\n",
      "Epoch 52/77\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.6758 - accuracy: 0.6136\n",
      "Epoch 53/77\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.6491 - accuracy: 0.7273\n",
      "Epoch 54/77\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 1.6229 - accuracy: 0.6818\n",
      "Epoch 55/77\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1.6640 - accuracy: 0.6818\n",
      "Epoch 56/77\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 1.6040 - accuracy: 0.7045\n",
      "Epoch 57/77\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 1.6017 - accuracy: 0.7273\n",
      "Epoch 58/77\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.5944 - accuracy: 0.7273\n",
      "Epoch 59/77\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 1.5679 - accuracy: 0.6818\n",
      "Epoch 60/77\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 1.6084 - accuracy: 0.7045\n",
      "Epoch 61/77\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.5938 - accuracy: 0.6818\n",
      "Epoch 62/77\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 1.6215 - accuracy: 0.6364\n",
      "Epoch 63/77\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 1.6156 - accuracy: 0.6818\n",
      "Epoch 64/77\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 1.6087 - accuracy: 0.6591\n",
      "Epoch 65/77\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 1.6060 - accuracy: 0.6591\n",
      "Epoch 66/77\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 1.5850 - accuracy: 0.7045\n",
      "Epoch 67/77\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.5980 - accuracy: 0.6818\n",
      "Epoch 68/77\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 1.5844 - accuracy: 0.6591\n",
      "Epoch 69/77\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 1.5794 - accuracy: 0.6591\n",
      "Epoch 70/77\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 1.5638 - accuracy: 0.6818\n",
      "Epoch 71/77\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.5680 - accuracy: 0.7045\n",
      "Epoch 72/77\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1.5292 - accuracy: 0.7045\n",
      "Epoch 73/77\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 1.5354 - accuracy: 0.7045\n",
      "Epoch 74/77\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 1.5252 - accuracy: 0.7045\n",
      "Epoch 75/77\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 1.5337 - accuracy: 0.7045\n",
      "Epoch 76/77\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 1.5750 - accuracy: 0.6818\n",
      "Epoch 77/77\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.5099 - accuracy: 0.7273\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8e27700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7735 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:50:01,066]\u001b[0m Trial 54 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 232, 'num_epochs': 77}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/95\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.3803 - accuracy: 0.1818\n",
      "Epoch 2/95\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 5.8759 - accuracy: 0.2500\n",
      "Epoch 3/95\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4.5115 - accuracy: 0.2727\n",
      "Epoch 4/95\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.9772 - accuracy: 0.2727\n",
      "Epoch 5/95\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 4.5386 - accuracy: 0.2955\n",
      "Epoch 6/95\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 4.1661 - accuracy: 0.2727\n",
      "Epoch 7/95\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 4.0134 - accuracy: 0.2727\n",
      "Epoch 8/95\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 3.8462 - accuracy: 0.2727\n",
      "Epoch 9/95\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 3.8529 - accuracy: 0.2727\n",
      "Epoch 10/95\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 3.5173 - accuracy: 0.2727\n",
      "Epoch 11/95\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.7761 - accuracy: 0.2727\n",
      "Epoch 12/95\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 3.8499 - accuracy: 0.2727\n",
      "Epoch 13/95\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 3.8340 - accuracy: 0.2727\n",
      "Epoch 14/95\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 3.7385 - accuracy: 0.2955\n",
      "Epoch 15/95\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.8087 - accuracy: 0.2500\n",
      "Epoch 16/95\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 3.8286 - accuracy: 0.2727\n",
      "Epoch 17/95\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 3.7844 - accuracy: 0.3864\n",
      "Epoch 18/95\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 3.7536 - accuracy: 0.3636\n",
      "Epoch 19/95\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 3.8303 - accuracy: 0.3864\n",
      "Epoch 20/95\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 3.7981 - accuracy: 0.2955\n",
      "Epoch 21/95\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 3.7765 - accuracy: 0.2727\n",
      "Epoch 22/95\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 3.7633 - accuracy: 0.4545\n",
      "Epoch 23/95\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 3.7716 - accuracy: 0.3864\n",
      "Epoch 24/95\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 3.7817 - accuracy: 0.4091\n",
      "Epoch 25/95\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 3.8049 - accuracy: 0.3864\n",
      "Epoch 26/95\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 3.5720 - accuracy: 0.3409\n",
      "Epoch 27/95\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 3.7290 - accuracy: 0.4545\n",
      "Epoch 28/95\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.7436 - accuracy: 0.4773\n",
      "Epoch 29/95\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 3.7579 - accuracy: 0.3864\n",
      "Epoch 30/95\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 3.7392 - accuracy: 0.5000\n",
      "Epoch 31/95\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.7323 - accuracy: 0.5455\n",
      "Epoch 32/95\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.7670 - accuracy: 0.4318\n",
      "Epoch 33/95\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.7189 - accuracy: 0.5227\n",
      "Epoch 34/95\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 3.4207 - accuracy: 0.5455\n",
      "Epoch 35/95\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 3.7411 - accuracy: 0.5455\n",
      "Epoch 36/95\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.4588 - accuracy: 0.5455\n",
      "Epoch 37/95\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 3.4507 - accuracy: 0.5455\n",
      "Epoch 38/95\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.6998 - accuracy: 0.5227\n",
      "Epoch 39/95\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 3.4128 - accuracy: 0.5227\n",
      "Epoch 40/95\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 3.7180 - accuracy: 0.5000\n",
      "Epoch 41/95\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.4037 - accuracy: 0.5682\n",
      "Epoch 42/95\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 3.4435 - accuracy: 0.5682\n",
      "Epoch 43/95\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 3.3833 - accuracy: 0.5455\n",
      "Epoch 44/95\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 3.4076 - accuracy: 0.5682\n",
      "Epoch 45/95\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 3.3595 - accuracy: 0.5682\n",
      "Epoch 46/95\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 3.3608 - accuracy: 0.5909\n",
      "Epoch 47/95\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.3755 - accuracy: 0.5000\n",
      "Epoch 48/95\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 3.3679 - accuracy: 0.6364\n",
      "Epoch 49/95\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 3.3427 - accuracy: 0.5455\n",
      "Epoch 50/95\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 3.3431 - accuracy: 0.6591\n",
      "Epoch 51/95\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 3.3304 - accuracy: 0.5682\n",
      "Epoch 52/95\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 3.3320 - accuracy: 0.5455\n",
      "Epoch 53/95\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 3.2731 - accuracy: 0.5909\n",
      "Epoch 54/95\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.2855 - accuracy: 0.6364\n",
      "Epoch 55/95\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 3.3021 - accuracy: 0.6364\n",
      "Epoch 56/95\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 3.2882 - accuracy: 0.6136\n",
      "Epoch 57/95\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.2931 - accuracy: 0.5909\n",
      "Epoch 58/95\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.2851 - accuracy: 0.6364\n",
      "Epoch 59/95\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 3.3073 - accuracy: 0.6136\n",
      "Epoch 60/95\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.2532 - accuracy: 0.6136\n",
      "Epoch 61/95\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.2725 - accuracy: 0.5909\n",
      "Epoch 62/95\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.2866 - accuracy: 0.6364\n",
      "Epoch 63/95\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 3.2401 - accuracy: 0.6364\n",
      "Epoch 64/95\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 3.2685 - accuracy: 0.5909\n",
      "Epoch 65/95\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.2451 - accuracy: 0.6364\n",
      "Epoch 66/95\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 3.2603 - accuracy: 0.6136\n",
      "Epoch 67/95\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.2606 - accuracy: 0.6136\n",
      "Epoch 68/95\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.2292 - accuracy: 0.6136\n",
      "Epoch 69/95\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.2378 - accuracy: 0.6591\n",
      "Epoch 70/95\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.2061 - accuracy: 0.6364\n",
      "Epoch 71/95\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 3.2717 - accuracy: 0.5909\n",
      "Epoch 72/95\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 3.1885 - accuracy: 0.5909\n",
      "Epoch 73/95\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 3.2131 - accuracy: 0.6364\n",
      "Epoch 74/95\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 3.2346 - accuracy: 0.5682\n",
      "Epoch 75/95\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 3.1755 - accuracy: 0.6364\n",
      "Epoch 76/95\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 3.1725 - accuracy: 0.6136\n",
      "Epoch 77/95\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.1774 - accuracy: 0.6364\n",
      "Epoch 78/95\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.2014 - accuracy: 0.6364\n",
      "Epoch 79/95\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 3.1948 - accuracy: 0.5909\n",
      "Epoch 80/95\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.1520 - accuracy: 0.6364\n",
      "Epoch 81/95\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 3.1584 - accuracy: 0.6591\n",
      "Epoch 82/95\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.2021 - accuracy: 0.6591\n",
      "Epoch 83/95\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 3.1690 - accuracy: 0.5909\n",
      "Epoch 84/95\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.1363 - accuracy: 0.5909\n",
      "Epoch 85/95\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.1659 - accuracy: 0.6364\n",
      "Epoch 86/95\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1383 - accuracy: 0.6136\n",
      "Epoch 87/95\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.1869 - accuracy: 0.6364\n",
      "Epoch 88/95\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.1422 - accuracy: 0.6364\n",
      "Epoch 89/95\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 3.1184 - accuracy: 0.6364\n",
      "Epoch 90/95\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.8309 - accuracy: 0.6364\n",
      "Epoch 91/95\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1298 - accuracy: 0.6364\n",
      "Epoch 92/95\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.1087 - accuracy: 0.5909\n",
      "Epoch 93/95\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.1045 - accuracy: 0.6591\n",
      "Epoch 94/95\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.1116 - accuracy: 0.6136\n",
      "Epoch 95/95\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.0962 - accuracy: 0.6136\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c61670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1282 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:50:24,845]\u001b[0m Trial 55 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 61, 'num_epochs': 95}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.1838 - accuracy: 0.0909\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 4.7511 - accuracy: 0.1136\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 3.8609 - accuracy: 0.0909\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 3.0427 - accuracy: 0.0682\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.9093 - accuracy: 0.1136\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.6957 - accuracy: 0.0909\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.7766 - accuracy: 0.0909\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.7170 - accuracy: 0.1364\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.6922 - accuracy: 0.2500\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.6757 - accuracy: 0.0455\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.5871 - accuracy: 0.2727\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.6219 - accuracy: 0.2273\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.6309 - accuracy: 0.1818\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.6031 - accuracy: 0.2500\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.6011 - accuracy: 0.2955\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.5572 - accuracy: 0.3864\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.5318 - accuracy: 0.3636\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.5628 - accuracy: 0.2955\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.4893 - accuracy: 0.3182\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.4507 - accuracy: 0.3182\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.4861 - accuracy: 0.3409\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.4530 - accuracy: 0.4091\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 2.4012 - accuracy: 0.3864\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.4397 - accuracy: 0.3636\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.3866 - accuracy: 0.3409\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.3605 - accuracy: 0.4545\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.3736 - accuracy: 0.3864\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.3427 - accuracy: 0.4773\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.3623 - accuracy: 0.4318\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2.3251 - accuracy: 0.5455\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.3332 - accuracy: 0.4318\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.3092 - accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.3015 - accuracy: 0.4318\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.3001 - accuracy: 0.4545\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.2641 - accuracy: 0.4545\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.2707 - accuracy: 0.4318\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.2575 - accuracy: 0.4545\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.2292 - accuracy: 0.4773\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.2402 - accuracy: 0.4318\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.2309 - accuracy: 0.4773\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 2.2191 - accuracy: 0.4318\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.2145 - accuracy: 0.4318\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.1825 - accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.1848 - accuracy: 0.5227\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.1432 - accuracy: 0.6136\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.1652 - accuracy: 0.5455\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.1562 - accuracy: 0.4773\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.1726 - accuracy: 0.5909\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.1509 - accuracy: 0.4773\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.1337 - accuracy: 0.5000\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8aafb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4137 - accuracy: 0.5455\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:50:42,807]\u001b[0m Trial 56 finished with value: 0.5454545617103577 and parameters: {'embedding_output_dim': 85, 'num_epochs': 50}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/42\n",
      "1/1 [==============================] - 9s 9s/step - loss: 13.3365 - accuracy: 0.0455\n",
      "Epoch 2/42\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 3.2067 - accuracy: 0.4318\n",
      "Epoch 3/42\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.5794 - accuracy: 0.5000\n",
      "Epoch 4/42\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.3423 - accuracy: 0.6364\n",
      "Epoch 5/42\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.1982 - accuracy: 0.6818\n",
      "Epoch 6/42\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.2185 - accuracy: 0.6591\n",
      "Epoch 7/42\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.1749 - accuracy: 0.6364\n",
      "Epoch 8/42\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.1364 - accuracy: 0.7045\n",
      "Epoch 9/42\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.1173 - accuracy: 0.6364\n",
      "Epoch 10/42\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0843 - accuracy: 0.6591\n",
      "Epoch 11/42\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.0741 - accuracy: 0.6818\n",
      "Epoch 12/42\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.0136 - accuracy: 0.6136\n",
      "Epoch 13/42\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.9437 - accuracy: 0.6364\n",
      "Epoch 14/42\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.9118 - accuracy: 0.6136\n",
      "Epoch 15/42\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.8891 - accuracy: 0.6136\n",
      "Epoch 16/42\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.8393 - accuracy: 0.6364\n",
      "Epoch 17/42\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.8416 - accuracy: 0.6591\n",
      "Epoch 18/42\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 1.8009 - accuracy: 0.6364\n",
      "Epoch 19/42\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.7585 - accuracy: 0.6591\n",
      "Epoch 20/42\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.7343 - accuracy: 0.6818\n",
      "Epoch 21/42\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.7142 - accuracy: 0.6818\n",
      "Epoch 22/42\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.7317 - accuracy: 0.7045\n",
      "Epoch 23/42\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.6911 - accuracy: 0.6818\n",
      "Epoch 24/42\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.6531 - accuracy: 0.7045\n",
      "Epoch 25/42\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.6257 - accuracy: 0.6591\n",
      "Epoch 26/42\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.6206 - accuracy: 0.6591\n",
      "Epoch 27/42\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.6240 - accuracy: 0.6591\n",
      "Epoch 28/42\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.5971 - accuracy: 0.6818\n",
      "Epoch 29/42\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 1.5657 - accuracy: 0.7273\n",
      "Epoch 30/42\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.5648 - accuracy: 0.7045\n",
      "Epoch 31/42\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.5715 - accuracy: 0.6591\n",
      "Epoch 32/42\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.5432 - accuracy: 0.6591\n",
      "Epoch 33/42\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.5483 - accuracy: 0.7045\n",
      "Epoch 34/42\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.4985 - accuracy: 0.7273\n",
      "Epoch 35/42\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.4736 - accuracy: 0.6818\n",
      "Epoch 36/42\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.4746 - accuracy: 0.6818\n",
      "Epoch 37/42\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.4854 - accuracy: 0.6818\n",
      "Epoch 38/42\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.4590 - accuracy: 0.7045\n",
      "Epoch 39/42\n",
      "1/1 [==============================] - 0s 193ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 40/42\n",
      "1/1 [==============================] - 0s 247ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/42\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/42\n",
      "1/1 [==============================] - 0s 154ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff57805f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:51:00,770]\u001b[0m Trial 57 finished with value: 0.5 and parameters: {'embedding_output_dim': 139, 'num_epochs': 42}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.9853 - accuracy: 0.1136\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 7.4648 - accuracy: 0.1818\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 7.3079 - accuracy: 0.2045\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 6.6340 - accuracy: 0.3182\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 6.5769 - accuracy: 0.3409\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 6.2312 - accuracy: 0.4318\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 6.1477 - accuracy: 0.4318\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 6.1473 - accuracy: 0.4318\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 6.1112 - accuracy: 0.4318\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.1061 - accuracy: 0.4318\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 6.0748 - accuracy: 0.4318\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 6.0462 - accuracy: 0.4318\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 6.0581 - accuracy: 0.4318\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 6.0305 - accuracy: 0.4318\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 6.0260 - accuracy: 0.4318\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 6.0214 - accuracy: 0.4318\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 6.0130 - accuracy: 0.4318\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 6.0230 - accuracy: 0.4318\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 5.9998 - accuracy: 0.4318\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.9820 - accuracy: 0.4318\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 5.9862 - accuracy: 0.4318\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 5.9930 - accuracy: 0.4318\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 5.9781 - accuracy: 0.4318\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 5.9599 - accuracy: 0.4318\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 5.9736 - accuracy: 0.4318\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 5.9635 - accuracy: 0.4318\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 5.9451 - accuracy: 0.4318\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 5.9389 - accuracy: 0.4318\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 5.9292 - accuracy: 0.4318\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 5.9260 - accuracy: 0.4318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff570181f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.0630 - accuracy: 0.3182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:51:17,090]\u001b[0m Trial 58 finished with value: 0.3181818127632141 and parameters: {'embedding_output_dim': 149, 'num_epochs': 30}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/84\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.7608 - accuracy: 0.0000e+00\n",
      "Epoch 2/84\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 5.5689 - accuracy: 0.1818\n",
      "Epoch 3/84\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 2.9956 - accuracy: 0.2273\n",
      "Epoch 4/84\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 2.6242 - accuracy: 0.2273\n",
      "Epoch 5/84\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.2411 - accuracy: 0.3182\n",
      "Epoch 6/84\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.4410 - accuracy: 0.4091\n",
      "Epoch 7/84\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.0764 - accuracy: 0.5000\n",
      "Epoch 8/84\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 2.0433 - accuracy: 0.5682\n",
      "Epoch 9/84\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.9788 - accuracy: 0.5909\n",
      "Epoch 10/84\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 1.9200 - accuracy: 0.6364\n",
      "Epoch 11/84\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.8590 - accuracy: 0.5909\n",
      "Epoch 12/84\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.8684 - accuracy: 0.5682\n",
      "Epoch 13/84\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.7993 - accuracy: 0.6364\n",
      "Epoch 14/84\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.7817 - accuracy: 0.6136\n",
      "Epoch 15/84\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 1.7595 - accuracy: 0.6364\n",
      "Epoch 16/84\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.7497 - accuracy: 0.6136\n",
      "Epoch 17/84\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.7172 - accuracy: 0.6364\n",
      "Epoch 18/84\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.6813 - accuracy: 0.6136\n",
      "Epoch 19/84\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.6593 - accuracy: 0.6591\n",
      "Epoch 20/84\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.6498 - accuracy: 0.6364\n",
      "Epoch 21/84\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.5951 - accuracy: 0.6591\n",
      "Epoch 22/84\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 1.5836 - accuracy: 0.6591\n",
      "Epoch 23/84\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.5666 - accuracy: 0.6591\n",
      "Epoch 24/84\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.5546 - accuracy: 0.6591\n",
      "Epoch 25/84\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.5431 - accuracy: 0.6364\n",
      "Epoch 26/84\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.5195 - accuracy: 0.6364\n",
      "Epoch 27/84\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.5747 - accuracy: 0.6136\n",
      "Epoch 28/84\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.5016 - accuracy: 0.6364\n",
      "Epoch 29/84\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.4664 - accuracy: 0.6591\n",
      "Epoch 30/84\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.4498 - accuracy: 0.6364\n",
      "Epoch 31/84\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.4232 - accuracy: 0.6364\n",
      "Epoch 32/84\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.4222 - accuracy: 0.6591\n",
      "Epoch 33/84\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.4071 - accuracy: 0.6364\n",
      "Epoch 34/84\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.3958 - accuracy: 0.6364\n",
      "Epoch 35/84\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.3674 - accuracy: 0.6136\n",
      "Epoch 36/84\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.3805 - accuracy: 0.6136\n",
      "Epoch 37/84\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.3468 - accuracy: 0.6591\n",
      "Epoch 38/84\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.3436 - accuracy: 0.6818\n",
      "Epoch 39/84\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.3406 - accuracy: 0.6591\n",
      "Epoch 40/84\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 1.3266 - accuracy: 0.6818\n",
      "Epoch 41/84\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.3259 - accuracy: 0.6818\n",
      "Epoch 42/84\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.3042 - accuracy: 0.6591\n",
      "Epoch 43/84\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.2743 - accuracy: 0.6818\n",
      "Epoch 44/84\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.2722 - accuracy: 0.6364\n",
      "Epoch 45/84\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.2623 - accuracy: 0.6818\n",
      "Epoch 46/84\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.2458 - accuracy: 0.7500\n",
      "Epoch 47/84\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.2300 - accuracy: 0.6818\n",
      "Epoch 48/84\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.2223 - accuracy: 0.6591\n",
      "Epoch 49/84\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.2373 - accuracy: 0.6818\n",
      "Epoch 50/84\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.2053 - accuracy: 0.7045\n",
      "Epoch 51/84\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.2240 - accuracy: 0.6818\n",
      "Epoch 52/84\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.2033 - accuracy: 0.7045\n",
      "Epoch 53/84\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.1492 - accuracy: 0.7273\n",
      "Epoch 54/84\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.1492 - accuracy: 0.6818\n",
      "Epoch 55/84\n",
      "1/1 [==============================] - 0s 225ms/step - loss: nan - accuracy: 0.6591\n",
      "Epoch 56/84\n",
      "1/1 [==============================] - 0s 241ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/84\n",
      "1/1 [==============================] - 0s 274ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/84\n",
      "1/1 [==============================] - 0s 239ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/84\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/84\n",
      "1/1 [==============================] - 0s 228ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/84\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/84\n",
      "1/1 [==============================] - 0s 258ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/84\n",
      "1/1 [==============================] - 0s 187ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/84\n",
      "1/1 [==============================] - 0s 232ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/84\n",
      "1/1 [==============================] - 0s 263ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/84\n",
      "1/1 [==============================] - 0s 270ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/84\n",
      "1/1 [==============================] - 0s 275ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/84\n",
      "1/1 [==============================] - 0s 193ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/84\n",
      "1/1 [==============================] - 0s 318ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/84\n",
      "1/1 [==============================] - 0s 286ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/84\n",
      "1/1 [==============================] - 0s 264ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/84\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/84\n",
      "1/1 [==============================] - 0s 236ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/84\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/84\n",
      "1/1 [==============================] - 0s 276ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/84\n",
      "1/1 [==============================] - 0s 298ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/84\n",
      "1/1 [==============================] - 0s 304ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/84\n",
      "1/1 [==============================] - 0s 218ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/84\n",
      "1/1 [==============================] - 0s 292ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/84\n",
      "1/1 [==============================] - 0s 166ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/84\n",
      "1/1 [==============================] - 0s 206ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/84\n",
      "1/1 [==============================] - 0s 180ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/84\n",
      "1/1 [==============================] - 0s 335ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/84\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c1b99d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:51:47,219]\u001b[0m Trial 59 finished with value: 0.5 and parameters: {'embedding_output_dim': 164, 'num_epochs': 84}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/21\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.9062 - accuracy: 0.1364\n",
      "Epoch 2/21\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 3.7249 - accuracy: 0.4318\n",
      "Epoch 3/21\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 2.9206 - accuracy: 0.5682\n",
      "Epoch 4/21\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.5295 - accuracy: 0.5455\n",
      "Epoch 5/21\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 2.4547 - accuracy: 0.5909\n",
      "Epoch 6/21\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.3946 - accuracy: 0.6591\n",
      "Epoch 7/21\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 2.3685 - accuracy: 0.6591\n",
      "Epoch 8/21\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.3515 - accuracy: 0.6364\n",
      "Epoch 9/21\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 2.3075 - accuracy: 0.6818\n",
      "Epoch 10/21\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 2.2939 - accuracy: 0.6591\n",
      "Epoch 11/21\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.2637 - accuracy: 0.6818\n",
      "Epoch 12/21\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 2.1976 - accuracy: 0.6364\n",
      "Epoch 13/21\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.1731 - accuracy: 0.6591\n",
      "Epoch 14/21\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.1817 - accuracy: 0.6364\n",
      "Epoch 15/21\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.1192 - accuracy: 0.6591\n",
      "Epoch 16/21\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 2.0882 - accuracy: 0.6591\n",
      "Epoch 17/21\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0893 - accuracy: 0.6364\n",
      "Epoch 18/21\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 2.0651 - accuracy: 0.6364\n",
      "Epoch 19/21\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 2.0168 - accuracy: 0.6364\n",
      "Epoch 20/21\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 2.0222 - accuracy: 0.6818\n",
      "Epoch 21/21\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.9809 - accuracy: 0.6591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5608213a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4963 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:52:02,755]\u001b[0m Trial 60 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 186, 'num_epochs': 21}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/53\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.9735 - accuracy: 0.0455\n",
      "Epoch 2/53\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.8830 - accuracy: 0.1136\n",
      "Epoch 3/53\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 3.8987 - accuracy: 0.0455\n",
      "Epoch 4/53\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 3.5827 - accuracy: 0.1364\n",
      "Epoch 5/53\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 3.2697 - accuracy: 0.1136\n",
      "Epoch 6/53\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.9854 - accuracy: 0.1364\n",
      "Epoch 7/53\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.9256 - accuracy: 0.1364\n",
      "Epoch 8/53\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.8798 - accuracy: 0.1136\n",
      "Epoch 9/53\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.7896 - accuracy: 0.1136\n",
      "Epoch 10/53\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.7790 - accuracy: 0.1818\n",
      "Epoch 11/53\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.7932 - accuracy: 0.1591\n",
      "Epoch 12/53\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.7028 - accuracy: 0.1364\n",
      "Epoch 13/53\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.6628 - accuracy: 0.1818\n",
      "Epoch 14/53\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.6758 - accuracy: 0.1591\n",
      "Epoch 15/53\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.6513 - accuracy: 0.1818\n",
      "Epoch 16/53\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.6492 - accuracy: 0.1818\n",
      "Epoch 17/53\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.6142 - accuracy: 0.1364\n",
      "Epoch 18/53\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 2.5267 - accuracy: 0.3409\n",
      "Epoch 19/53\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 2.5415 - accuracy: 0.2045\n",
      "Epoch 20/53\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 2.5563 - accuracy: 0.3182\n",
      "Epoch 21/53\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.5225 - accuracy: 0.2955\n",
      "Epoch 22/53\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.4738 - accuracy: 0.2955\n",
      "Epoch 23/53\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.4612 - accuracy: 0.3636\n",
      "Epoch 24/53\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.4545 - accuracy: 0.3636\n",
      "Epoch 25/53\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.5018 - accuracy: 0.3864\n",
      "Epoch 26/53\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.3955 - accuracy: 0.5455\n",
      "Epoch 27/53\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.3820 - accuracy: 0.5000\n",
      "Epoch 28/53\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.3865 - accuracy: 0.5000\n",
      "Epoch 29/53\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.3837 - accuracy: 0.5227\n",
      "Epoch 30/53\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.3264 - accuracy: 0.5227\n",
      "Epoch 31/53\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.2944 - accuracy: 0.5909\n",
      "Epoch 32/53\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.2911 - accuracy: 0.5455\n",
      "Epoch 33/53\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.2802 - accuracy: 0.5455\n",
      "Epoch 34/53\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.2780 - accuracy: 0.5682\n",
      "Epoch 35/53\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.2292 - accuracy: 0.5682\n",
      "Epoch 36/53\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.2465 - accuracy: 0.5455\n",
      "Epoch 37/53\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.2218 - accuracy: 0.5682\n",
      "Epoch 38/53\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.2166 - accuracy: 0.5682\n",
      "Epoch 39/53\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.1886 - accuracy: 0.5909\n",
      "Epoch 40/53\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.1577 - accuracy: 0.5909\n",
      "Epoch 41/53\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.1488 - accuracy: 0.5909\n",
      "Epoch 42/53\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.1431 - accuracy: 0.5682\n",
      "Epoch 43/53\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.0873 - accuracy: 0.5909\n",
      "Epoch 44/53\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.1033 - accuracy: 0.5455\n",
      "Epoch 45/53\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.0888 - accuracy: 0.5909\n",
      "Epoch 46/53\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.0930 - accuracy: 0.5682\n",
      "Epoch 47/53\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.0650 - accuracy: 0.5682\n",
      "Epoch 48/53\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.0372 - accuracy: 0.5909\n",
      "Epoch 49/53\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.0177 - accuracy: 0.5909\n",
      "Epoch 50/53\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.0188 - accuracy: 0.5909\n",
      "Epoch 51/53\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.9829 - accuracy: 0.6136\n",
      "Epoch 52/53\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.9727 - accuracy: 0.6136\n",
      "Epoch 53/53\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.9570 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c6c03a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2353 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:52:22,500]\u001b[0m Trial 61 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 119, 'num_epochs': 53}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/54\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.4326 - accuracy: 0.0909\n",
      "Epoch 2/54\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 4.4657 - accuracy: 0.5227\n",
      "Epoch 3/54\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 4.2736 - accuracy: 0.6136\n",
      "Epoch 4/54\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3.6650 - accuracy: 0.5682\n",
      "Epoch 5/54\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 3.9236 - accuracy: 0.6364\n",
      "Epoch 6/54\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.6074 - accuracy: 0.6364\n",
      "Epoch 7/54\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.5318 - accuracy: 0.6364\n",
      "Epoch 8/54\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 3.5037 - accuracy: 0.6136\n",
      "Epoch 9/54\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.4985 - accuracy: 0.6364\n",
      "Epoch 10/54\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 3.4811 - accuracy: 0.5909\n",
      "Epoch 11/54\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 3.4728 - accuracy: 0.6364\n",
      "Epoch 12/54\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.4504 - accuracy: 0.6136\n",
      "Epoch 13/54\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.4035 - accuracy: 0.6364\n",
      "Epoch 14/54\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 3.3912 - accuracy: 0.6136\n",
      "Epoch 15/54\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 3.3997 - accuracy: 0.6364\n",
      "Epoch 16/54\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.3942 - accuracy: 0.6136\n",
      "Epoch 17/54\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 3.3437 - accuracy: 0.6591\n",
      "Epoch 18/54\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 3.3406 - accuracy: 0.6591\n",
      "Epoch 19/54\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.3150 - accuracy: 0.6364\n",
      "Epoch 20/54\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 3.2948 - accuracy: 0.6591\n",
      "Epoch 21/54\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 3.2854 - accuracy: 0.6364\n",
      "Epoch 22/54\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 3.2580 - accuracy: 0.6591\n",
      "Epoch 23/54\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3.2519 - accuracy: 0.6591\n",
      "Epoch 24/54\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 3.2390 - accuracy: 0.6591\n",
      "Epoch 25/54\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3.2241 - accuracy: 0.6818\n",
      "Epoch 26/54\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 3.2226 - accuracy: 0.6818\n",
      "Epoch 27/54\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.2080 - accuracy: 0.6591\n",
      "Epoch 28/54\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.1849 - accuracy: 0.6818\n",
      "Epoch 29/54\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 3.1714 - accuracy: 0.6818\n",
      "Epoch 30/54\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.1522 - accuracy: 0.7045\n",
      "Epoch 31/54\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 3.1469 - accuracy: 0.7045\n",
      "Epoch 32/54\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.1348 - accuracy: 0.7045\n",
      "Epoch 33/54\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 3.1416 - accuracy: 0.7045\n",
      "Epoch 34/54\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 3.1299 - accuracy: 0.7273\n",
      "Epoch 35/54\n",
      "1/1 [==============================] - 0s 270ms/step - loss: nan - accuracy: 0.7273\n",
      "Epoch 36/54\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 37/54\n",
      "1/1 [==============================] - 0s 231ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 38/54\n",
      "1/1 [==============================] - 0s 288ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/54\n",
      "1/1 [==============================] - 0s 177ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/54\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/54\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/54\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/54\n",
      "1/1 [==============================] - 0s 217ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/54\n",
      "1/1 [==============================] - 0s 149ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/54\n",
      "1/1 [==============================] - 0s 166ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/54\n",
      "1/1 [==============================] - 0s 125ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/54\n",
      "1/1 [==============================] - 0s 195ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/54\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/54\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/54\n",
      "1/1 [==============================] - 0s 174ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/54\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/54\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/54\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/54\n",
      "1/1 [==============================] - 0s 190ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c63eee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:52:43,646]\u001b[0m Trial 62 finished with value: 0.5 and parameters: {'embedding_output_dim': 115, 'num_epochs': 54}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/66\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.4328 - accuracy: 0.0227\n",
      "Epoch 2/66\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 6.6012 - accuracy: 0.2727\n",
      "Epoch 3/66\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.5946 - accuracy: 0.4318\n",
      "Epoch 4/66\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.9750 - accuracy: 0.5909\n",
      "Epoch 5/66\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.7683 - accuracy: 0.5000\n",
      "Epoch 6/66\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.0403 - accuracy: 0.4545\n",
      "Epoch 7/66\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.4847 - accuracy: 0.4318\n",
      "Epoch 8/66\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.7366 - accuracy: 0.4318\n",
      "Epoch 9/66\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.4325 - accuracy: 0.4545\n",
      "Epoch 10/66\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 1.4441 - accuracy: 0.4318\n",
      "Epoch 11/66\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.3207 - accuracy: 0.4318\n",
      "Epoch 12/66\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.3145 - accuracy: 0.4318\n",
      "Epoch 13/66\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.3387 - accuracy: 0.4318\n",
      "Epoch 14/66\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.3019 - accuracy: 0.4318\n",
      "Epoch 15/66\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.2399 - accuracy: 0.4318\n",
      "Epoch 16/66\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.2380 - accuracy: 0.4318\n",
      "Epoch 17/66\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.1992 - accuracy: 0.4318\n",
      "Epoch 18/66\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.1865 - accuracy: 0.4545\n",
      "Epoch 19/66\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.1440 - accuracy: 0.4318\n",
      "Epoch 20/66\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.1523 - accuracy: 0.4545\n",
      "Epoch 21/66\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.1272 - accuracy: 0.4318\n",
      "Epoch 22/66\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.1500 - accuracy: 0.4318\n",
      "Epoch 23/66\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.1126 - accuracy: 0.4545\n",
      "Epoch 24/66\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.0984 - accuracy: 0.4318\n",
      "Epoch 25/66\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.1132 - accuracy: 0.4318\n",
      "Epoch 26/66\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.0681 - accuracy: 0.4773\n",
      "Epoch 27/66\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.0452 - accuracy: 0.5000\n",
      "Epoch 28/66\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.0424 - accuracy: 0.4545\n",
      "Epoch 29/66\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.0136 - accuracy: 0.5000\n",
      "Epoch 30/66\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9884 - accuracy: 0.5000\n",
      "Epoch 31/66\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9867 - accuracy: 0.4545\n",
      "Epoch 32/66\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9922 - accuracy: 0.4545\n",
      "Epoch 33/66\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9560 - accuracy: 0.5227\n",
      "Epoch 34/66\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9754 - accuracy: 0.5000\n",
      "Epoch 35/66\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9434 - accuracy: 0.5227\n",
      "Epoch 36/66\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9406 - accuracy: 0.5455\n",
      "Epoch 37/66\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9106 - accuracy: 0.5000\n",
      "Epoch 38/66\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9182 - accuracy: 0.5227\n",
      "Epoch 39/66\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8922 - accuracy: 0.5682\n",
      "Epoch 40/66\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8869 - accuracy: 0.5682\n",
      "Epoch 41/66\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8830 - accuracy: 0.5909\n",
      "Epoch 42/66\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8573 - accuracy: 0.5682\n",
      "Epoch 43/66\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8343 - accuracy: 0.6136\n",
      "Epoch 44/66\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8464 - accuracy: 0.6136\n",
      "Epoch 45/66\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8285 - accuracy: 0.6136\n",
      "Epoch 46/66\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8106 - accuracy: 0.5909\n",
      "Epoch 47/66\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8031 - accuracy: 0.6136\n",
      "Epoch 48/66\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8208 - accuracy: 0.6136\n",
      "Epoch 49/66\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7721 - accuracy: 0.6136\n",
      "Epoch 50/66\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7673 - accuracy: 0.6364\n",
      "Epoch 51/66\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7193 - accuracy: 0.7045\n",
      "Epoch 52/66\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7446 - accuracy: 0.6591\n",
      "Epoch 53/66\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7110 - accuracy: 0.6364\n",
      "Epoch 54/66\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6993 - accuracy: 0.7045\n",
      "Epoch 55/66\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6700 - accuracy: 0.7045\n",
      "Epoch 56/66\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9731 - accuracy: 0.6591\n",
      "Epoch 57/66\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9542 - accuracy: 0.6818\n",
      "Epoch 58/66\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9840 - accuracy: 0.6818\n",
      "Epoch 59/66\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6032 - accuracy: 0.7273\n",
      "Epoch 60/66\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.2782 - accuracy: 0.6591\n",
      "Epoch 61/66\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.2611 - accuracy: 0.6591\n",
      "Epoch 62/66\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6031 - accuracy: 0.6818\n",
      "Epoch 63/66\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8869 - accuracy: 0.7273\n",
      "Epoch 64/66\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - accuracy: 0.7273\n",
      "Epoch 65/66\n",
      "1/1 [==============================] - 0s 180ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/66\n",
      "1/1 [==============================] - 0s 149ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff56100d280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:53:05,356]\u001b[0m Trial 63 finished with value: 0.5 and parameters: {'embedding_output_dim': 128, 'num_epochs': 66}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/61\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.3009 - accuracy: 0.0455\n",
      "Epoch 2/61\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 4.5708 - accuracy: 0.0227\n",
      "Epoch 3/61\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 3.4260 - accuracy: 0.0227\n",
      "Epoch 4/61\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.6956 - accuracy: 0.0455\n",
      "Epoch 5/61\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.5188 - accuracy: 0.0455\n",
      "Epoch 6/61\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 3.7382 - accuracy: 0.0455\n",
      "Epoch 7/61\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.4696 - accuracy: 0.0455\n",
      "Epoch 8/61\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.7575 - accuracy: 0.0455\n",
      "Epoch 9/61\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 3.7443 - accuracy: 0.0682\n",
      "Epoch 10/61\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.5295 - accuracy: 0.1136\n",
      "Epoch 11/61\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.5249 - accuracy: 0.0455\n",
      "Epoch 12/61\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.7822 - accuracy: 0.0455\n",
      "Epoch 13/61\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.7086 - accuracy: 0.0682\n",
      "Epoch 14/61\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 3.5316 - accuracy: 0.0682\n",
      "Epoch 15/61\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3.5055 - accuracy: 0.0682\n",
      "Epoch 16/61\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 3.7322 - accuracy: 0.0455\n",
      "Epoch 17/61\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.3975 - accuracy: 0.0682\n",
      "Epoch 18/61\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 3.3906 - accuracy: 0.0909\n",
      "Epoch 19/61\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 3.4142 - accuracy: 0.0682\n",
      "Epoch 20/61\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 3.3758 - accuracy: 0.0909\n",
      "Epoch 21/61\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.3757 - accuracy: 0.0682\n",
      "Epoch 22/61\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 3.3259 - accuracy: 0.1364\n",
      "Epoch 23/61\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 3.3428 - accuracy: 0.1364\n",
      "Epoch 24/61\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 3.3190 - accuracy: 0.1364\n",
      "Epoch 25/61\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 3.3197 - accuracy: 0.0909\n",
      "Epoch 26/61\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 3.3480 - accuracy: 0.0909\n",
      "Epoch 27/61\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.3112 - accuracy: 0.0909\n",
      "Epoch 28/61\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.2942 - accuracy: 0.0909\n",
      "Epoch 29/61\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.2978 - accuracy: 0.1818\n",
      "Epoch 30/61\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.2538 - accuracy: 0.1818\n",
      "Epoch 31/61\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 3.2932 - accuracy: 0.2045\n",
      "Epoch 32/61\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.2675 - accuracy: 0.1136\n",
      "Epoch 33/61\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.2495 - accuracy: 0.1364\n",
      "Epoch 34/61\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.2494 - accuracy: 0.1591\n",
      "Epoch 35/61\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 3.2357 - accuracy: 0.2500\n",
      "Epoch 36/61\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.2242 - accuracy: 0.1818\n",
      "Epoch 37/61\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 3.2176 - accuracy: 0.2045\n",
      "Epoch 38/61\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 3.2177 - accuracy: 0.1364\n",
      "Epoch 39/61\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 3.1848 - accuracy: 0.2955\n",
      "Epoch 40/61\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.2139 - accuracy: 0.2727\n",
      "Epoch 41/61\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3.2054 - accuracy: 0.2727\n",
      "Epoch 42/61\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 3.1828 - accuracy: 0.3636\n",
      "Epoch 43/61\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.1459 - accuracy: 0.2955\n",
      "Epoch 44/61\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.1754 - accuracy: 0.3182\n",
      "Epoch 45/61\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 3.1774 - accuracy: 0.2955\n",
      "Epoch 46/61\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.1533 - accuracy: 0.2500\n",
      "Epoch 47/61\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 3.1451 - accuracy: 0.2727\n",
      "Epoch 48/61\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.1517 - accuracy: 0.4091\n",
      "Epoch 49/61\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 3.1200 - accuracy: 0.4545\n",
      "Epoch 50/61\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.1056 - accuracy: 0.4318\n",
      "Epoch 51/61\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.1059 - accuracy: 0.4318\n",
      "Epoch 52/61\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 3.1219 - accuracy: 0.3409\n",
      "Epoch 53/61\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.0942 - accuracy: 0.3409\n",
      "Epoch 54/61\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.1346 - accuracy: 0.3864\n",
      "Epoch 55/61\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 3.0942 - accuracy: 0.4318\n",
      "Epoch 56/61\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.1243 - accuracy: 0.4091\n",
      "Epoch 57/61\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 3.1033 - accuracy: 0.4091\n",
      "Epoch 58/61\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.1021 - accuracy: 0.4773\n",
      "Epoch 59/61\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 3.0711 - accuracy: 0.4773\n",
      "Epoch 60/61\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 3.0877 - accuracy: 0.4773\n",
      "Epoch 61/61\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 3.0643 - accuracy: 0.5000\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e83aae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.9606 - accuracy: 0.5909\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:53:27,897]\u001b[0m Trial 64 finished with value: 0.5909090638160706 and parameters: {'embedding_output_dim': 119, 'num_epochs': 61}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/75\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.2073 - accuracy: 0.0909\n",
      "Epoch 2/75\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 3.1290 - accuracy: 0.4773\n",
      "Epoch 3/75\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 3.0122 - accuracy: 0.4318\n",
      "Epoch 4/75\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 3.0501 - accuracy: 0.4773\n",
      "Epoch 5/75\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 3.0086 - accuracy: 0.5000\n",
      "Epoch 6/75\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 2.7563 - accuracy: 0.4545\n",
      "Epoch 7/75\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 2.3549 - accuracy: 0.5455\n",
      "Epoch 8/75\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 2.4016 - accuracy: 0.5000\n",
      "Epoch 9/75\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 2.4143 - accuracy: 0.5909\n",
      "Epoch 10/75\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 2.4228 - accuracy: 0.6364\n",
      "Epoch 11/75\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 2.4450 - accuracy: 0.6364\n",
      "Epoch 12/75\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 2.4283 - accuracy: 0.6136\n",
      "Epoch 13/75\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 2.4138 - accuracy: 0.5682\n",
      "Epoch 14/75\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 2.3800 - accuracy: 0.6364\n",
      "Epoch 15/75\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 2.3711 - accuracy: 0.5682\n",
      "Epoch 16/75\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 2.3488 - accuracy: 0.5909\n",
      "Epoch 17/75\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 2.3318 - accuracy: 0.5909\n",
      "Epoch 18/75\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 2.2865 - accuracy: 0.5682\n",
      "Epoch 19/75\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.2704 - accuracy: 0.5455\n",
      "Epoch 20/75\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 2.2269 - accuracy: 0.6136\n",
      "Epoch 21/75\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 2.1822 - accuracy: 0.5909\n",
      "Epoch 22/75\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 2.1622 - accuracy: 0.6136\n",
      "Epoch 23/75\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.1208 - accuracy: 0.6591\n",
      "Epoch 24/75\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 2.1045 - accuracy: 0.6136\n",
      "Epoch 25/75\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.1001 - accuracy: 0.6364\n",
      "Epoch 26/75\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.7847 - accuracy: 0.6591\n",
      "Epoch 27/75\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 1.7630 - accuracy: 0.6591\n",
      "Epoch 28/75\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.7718 - accuracy: 0.6591\n",
      "Epoch 29/75\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 1.7948 - accuracy: 0.6364\n",
      "Epoch 30/75\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 1.8069 - accuracy: 0.6591\n",
      "Epoch 31/75\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.8148 - accuracy: 0.6591\n",
      "Epoch 32/75\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 1.7941 - accuracy: 0.6364\n",
      "Epoch 33/75\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.7926 - accuracy: 0.6818\n",
      "Epoch 34/75\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.7968 - accuracy: 0.6364\n",
      "Epoch 35/75\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.7646 - accuracy: 0.6818\n",
      "Epoch 36/75\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 1.7541 - accuracy: 0.7045\n",
      "Epoch 37/75\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 1.7321 - accuracy: 0.6591\n",
      "Epoch 38/75\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.6877 - accuracy: 0.6818\n",
      "Epoch 39/75\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 1.6855 - accuracy: 0.6818\n",
      "Epoch 40/75\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.6614 - accuracy: 0.7045\n",
      "Epoch 41/75\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 1.6447 - accuracy: 0.7045\n",
      "Epoch 42/75\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.6391 - accuracy: 0.7045\n",
      "Epoch 43/75\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.6068 - accuracy: 0.7273\n",
      "Epoch 44/75\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 1.5914 - accuracy: 0.7273\n",
      "Epoch 45/75\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 1.5956 - accuracy: 0.7045\n",
      "Epoch 46/75\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1.5808 - accuracy: 0.7045\n",
      "Epoch 47/75\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 1.5702 - accuracy: 0.7045\n",
      "Epoch 48/75\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.5688 - accuracy: 0.6818\n",
      "Epoch 49/75\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.5629 - accuracy: 0.7500\n",
      "Epoch 50/75\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 1.5455 - accuracy: 0.7045\n",
      "Epoch 51/75\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 1.5536 - accuracy: 0.7273\n",
      "Epoch 52/75\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 1.5249 - accuracy: 0.7273\n",
      "Epoch 53/75\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.5180 - accuracy: 0.7045\n",
      "Epoch 54/75\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 1.5198 - accuracy: 0.7273\n",
      "Epoch 55/75\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 1.5026 - accuracy: 0.7727\n",
      "Epoch 56/75\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1.4975 - accuracy: 0.7273\n",
      "Epoch 57/75\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 1.4698 - accuracy: 0.7500\n",
      "Epoch 58/75\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 1.4891 - accuracy: 0.7273\n",
      "Epoch 59/75\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 1.4830 - accuracy: 0.7045\n",
      "Epoch 60/75\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.4721 - accuracy: 0.7500\n",
      "Epoch 61/75\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.4761 - accuracy: 0.7727\n",
      "Epoch 62/75\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.4910 - accuracy: 0.7273\n",
      "Epoch 63/75\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.4284 - accuracy: 0.7727\n",
      "Epoch 64/75\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 1.4456 - accuracy: 0.7045\n",
      "Epoch 65/75\n",
      "1/1 [==============================] - 0s 327ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 66/75\n",
      "1/1 [==============================] - 0s 402ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/75\n",
      "1/1 [==============================] - 0s 372ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/75\n",
      "1/1 [==============================] - 0s 345ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/75\n",
      "1/1 [==============================] - 0s 318ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/75\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/75\n",
      "1/1 [==============================] - 0s 370ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/75\n",
      "1/1 [==============================] - 0s 442ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/75\n",
      "1/1 [==============================] - 0s 441ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/75\n",
      "1/1 [==============================] - 0s 348ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/75\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8a88ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:54:06,859]\u001b[0m Trial 65 finished with value: 0.5 and parameters: {'embedding_output_dim': 249, 'num_epochs': 75}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/36\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.9805 - accuracy: 0.1136\n",
      "Epoch 2/36\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 2.4124 - accuracy: 0.5000\n",
      "Epoch 3/36\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 2.2537 - accuracy: 0.6136\n",
      "Epoch 4/36\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 2.1724 - accuracy: 0.6364\n",
      "Epoch 5/36\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.8648 - accuracy: 0.6364\n",
      "Epoch 6/36\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.7882 - accuracy: 0.6136\n",
      "Epoch 7/36\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 1.7489 - accuracy: 0.5909\n",
      "Epoch 8/36\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.7202 - accuracy: 0.6364\n",
      "Epoch 9/36\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 1.6426 - accuracy: 0.6364\n",
      "Epoch 10/36\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 1.6215 - accuracy: 0.5909\n",
      "Epoch 11/36\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.5748 - accuracy: 0.6364\n",
      "Epoch 12/36\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 1.5500 - accuracy: 0.6591\n",
      "Epoch 13/36\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 1.5190 - accuracy: 0.6136\n",
      "Epoch 14/36\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.4769 - accuracy: 0.6136\n",
      "Epoch 15/36\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.4456 - accuracy: 0.6136\n",
      "Epoch 16/36\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.4157 - accuracy: 0.6591\n",
      "Epoch 17/36\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.3716 - accuracy: 0.6364\n",
      "Epoch 18/36\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.3710 - accuracy: 0.6591\n",
      "Epoch 19/36\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.3409 - accuracy: 0.6591\n",
      "Epoch 20/36\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1.3213 - accuracy: 0.6591\n",
      "Epoch 21/36\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.3281 - accuracy: 0.6818\n",
      "Epoch 22/36\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.2955 - accuracy: 0.6818\n",
      "Epoch 23/36\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.2808 - accuracy: 0.6591\n",
      "Epoch 24/36\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 1.2656 - accuracy: 0.7045\n",
      "Epoch 25/36\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.2107 - accuracy: 0.7045\n",
      "Epoch 26/36\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.2146 - accuracy: 0.6818\n",
      "Epoch 27/36\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.1834 - accuracy: 0.7500\n",
      "Epoch 28/36\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 1.1916 - accuracy: 0.7500\n",
      "Epoch 29/36\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.2014 - accuracy: 0.7045\n",
      "Epoch 30/36\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 31/36\n",
      "1/1 [==============================] - 0s 332ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 32/36\n",
      "1/1 [==============================] - 0s 350ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 33/36\n",
      "1/1 [==============================] - 0s 376ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 34/36\n",
      "1/1 [==============================] - 0s 291ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 35/36\n",
      "1/1 [==============================] - 0s 318ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 36/36\n",
      "1/1 [==============================] - 0s 298ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5607c33a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 973ms/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:54:28,801]\u001b[0m Trial 66 finished with value: 0.5 and parameters: {'embedding_output_dim': 226, 'num_epochs': 36}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/48\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.8784 - accuracy: 0.0682\n",
      "Epoch 2/48\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.9128 - accuracy: 0.4318\n",
      "Epoch 3/48\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.7956 - accuracy: 0.4091\n",
      "Epoch 4/48\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.6909 - accuracy: 0.4318\n",
      "Epoch 5/48\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 2.1561 - accuracy: 0.4318\n",
      "Epoch 6/48\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.1770 - accuracy: 0.2273\n",
      "Epoch 7/48\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.1902 - accuracy: 0.2500\n",
      "Epoch 8/48\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2.2087 - accuracy: 0.1591\n",
      "Epoch 9/48\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.1619 - accuracy: 0.2045\n",
      "Epoch 10/48\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 2.2068 - accuracy: 0.0909\n",
      "Epoch 11/48\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.2213 - accuracy: 0.0455\n",
      "Epoch 12/48\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.1866 - accuracy: 0.0682\n",
      "Epoch 13/48\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.1786 - accuracy: 0.0682\n",
      "Epoch 14/48\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.1696 - accuracy: 0.1364\n",
      "Epoch 15/48\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.1812 - accuracy: 0.0455\n",
      "Epoch 16/48\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.1711 - accuracy: 0.0455\n",
      "Epoch 17/48\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.1350 - accuracy: 0.0909\n",
      "Epoch 18/48\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.1685 - accuracy: 0.1136\n",
      "Epoch 19/48\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.1466 - accuracy: 0.0682\n",
      "Epoch 20/48\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 2.1221 - accuracy: 0.1136\n",
      "Epoch 21/48\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.1249 - accuracy: 0.1364\n",
      "Epoch 22/48\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.0954 - accuracy: 0.1818\n",
      "Epoch 23/48\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 2.0677 - accuracy: 0.1818\n",
      "Epoch 24/48\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 2.0430 - accuracy: 0.2500\n",
      "Epoch 25/48\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 2.0332 - accuracy: 0.2500\n",
      "Epoch 26/48\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 2.0101 - accuracy: 0.3636\n",
      "Epoch 27/48\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 2.0168 - accuracy: 0.2955\n",
      "Epoch 28/48\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.9627 - accuracy: 0.4545\n",
      "Epoch 29/48\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.9715 - accuracy: 0.4318\n",
      "Epoch 30/48\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.9462 - accuracy: 0.5000\n",
      "Epoch 31/48\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.9211 - accuracy: 0.5227\n",
      "Epoch 32/48\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.9012 - accuracy: 0.5227\n",
      "Epoch 33/48\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.8724 - accuracy: 0.5682\n",
      "Epoch 34/48\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 1.9044 - accuracy: 0.5227\n",
      "Epoch 35/48\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.8499 - accuracy: 0.5455\n",
      "Epoch 36/48\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.8331 - accuracy: 0.5682\n",
      "Epoch 37/48\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 1.8044 - accuracy: 0.5909\n",
      "Epoch 38/48\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.7793 - accuracy: 0.5682\n",
      "Epoch 39/48\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.7670 - accuracy: 0.5682\n",
      "Epoch 40/48\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.7521 - accuracy: 0.5455\n",
      "Epoch 41/48\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.7517 - accuracy: 0.5000\n",
      "Epoch 42/48\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.7067 - accuracy: 0.5682\n",
      "Epoch 43/48\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.6741 - accuracy: 0.5909\n",
      "Epoch 44/48\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.6848 - accuracy: 0.4545\n",
      "Epoch 45/48\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.6652 - accuracy: 0.5682\n",
      "Epoch 46/48\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1.6432 - accuracy: 0.5227\n",
      "Epoch 47/48\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 1.6324 - accuracy: 0.6136\n",
      "Epoch 48/48\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 1.6045 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff51040a3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7456 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:54:51,968]\u001b[0m Trial 67 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 170, 'num_epochs': 48}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/47\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.8408 - accuracy: 0.1818\n",
      "Epoch 2/47\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.5581 - accuracy: 0.4318\n",
      "Epoch 3/47\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3.2429 - accuracy: 0.4318\n",
      "Epoch 4/47\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 2.8662 - accuracy: 0.4318\n",
      "Epoch 5/47\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.7600 - accuracy: 0.6136\n",
      "Epoch 6/47\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.8057 - accuracy: 0.5227\n",
      "Epoch 7/47\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.7356 - accuracy: 0.6136\n",
      "Epoch 8/47\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.7364 - accuracy: 0.6136\n",
      "Epoch 9/47\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.6839 - accuracy: 0.6364\n",
      "Epoch 10/47\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.6620 - accuracy: 0.6591\n",
      "Epoch 11/47\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.6419 - accuracy: 0.6136\n",
      "Epoch 12/47\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.6024 - accuracy: 0.6136\n",
      "Epoch 13/47\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 2.5806 - accuracy: 0.6136\n",
      "Epoch 14/47\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.5502 - accuracy: 0.6136\n",
      "Epoch 15/47\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.5438 - accuracy: 0.6591\n",
      "Epoch 16/47\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.5537 - accuracy: 0.6136\n",
      "Epoch 17/47\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.6097 - accuracy: 0.6364\n",
      "Epoch 18/47\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.5333 - accuracy: 0.6136\n",
      "Epoch 19/47\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.5170 - accuracy: 0.6136\n",
      "Epoch 20/47\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.5316 - accuracy: 0.6136\n",
      "Epoch 21/47\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.5433 - accuracy: 0.6136\n",
      "Epoch 22/47\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.5079 - accuracy: 0.6364\n",
      "Epoch 23/47\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.5410 - accuracy: 0.6364\n",
      "Epoch 24/47\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.5447 - accuracy: 0.6364\n",
      "Epoch 25/47\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.5195 - accuracy: 0.6591\n",
      "Epoch 26/47\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.5045 - accuracy: 0.6136\n",
      "Epoch 27/47\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.5221 - accuracy: 0.6136\n",
      "Epoch 28/47\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 2.5181 - accuracy: 0.5909\n",
      "Epoch 29/47\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.4840 - accuracy: 0.6591\n",
      "Epoch 30/47\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.4803 - accuracy: 0.5909\n",
      "Epoch 31/47\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 2.4788 - accuracy: 0.6591\n",
      "Epoch 32/47\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.4519 - accuracy: 0.6591\n",
      "Epoch 33/47\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.4440 - accuracy: 0.5909\n",
      "Epoch 34/47\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 2.3979 - accuracy: 0.6136\n",
      "Epoch 35/47\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.3730 - accuracy: 0.6364\n",
      "Epoch 36/47\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.3651 - accuracy: 0.6136\n",
      "Epoch 37/47\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 2.3428 - accuracy: 0.6136\n",
      "Epoch 38/47\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.3141 - accuracy: 0.6136\n",
      "Epoch 39/47\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.3029 - accuracy: 0.6364\n",
      "Epoch 40/47\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.3108 - accuracy: 0.6364\n",
      "Epoch 41/47\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 2.2936 - accuracy: 0.6591\n",
      "Epoch 42/47\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.2913 - accuracy: 0.6364\n",
      "Epoch 43/47\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.2957 - accuracy: 0.6364\n",
      "Epoch 44/47\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.2706 - accuracy: 0.6591\n",
      "Epoch 45/47\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.2533 - accuracy: 0.6364\n",
      "Epoch 46/47\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.2570 - accuracy: 0.6818\n",
      "Epoch 47/47\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.2633 - accuracy: 0.6591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4d9ceedc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.0967 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:55:12,605]\u001b[0m Trial 68 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 106, 'num_epochs': 47}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/57\n",
      "1/1 [==============================] - 10s 10s/step - loss: 9.9345 - accuracy: 0.0000e+00\n",
      "Epoch 2/57\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 5.3241 - accuracy: 0.2045\n",
      "Epoch 3/57\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.7861 - accuracy: 0.2500\n",
      "Epoch 4/57\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.6274 - accuracy: 0.4091\n",
      "Epoch 5/57\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.4822 - accuracy: 0.3864\n",
      "Epoch 6/57\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.4051 - accuracy: 0.5000\n",
      "Epoch 7/57\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.3336 - accuracy: 0.4773\n",
      "Epoch 8/57\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 2.3407 - accuracy: 0.4773\n",
      "Epoch 9/57\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 2.2693 - accuracy: 0.5682\n",
      "Epoch 10/57\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 2.2410 - accuracy: 0.5682\n",
      "Epoch 11/57\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 2.2071 - accuracy: 0.6591\n",
      "Epoch 12/57\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.1823 - accuracy: 0.5682\n",
      "Epoch 13/57\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.1491 - accuracy: 0.6136\n",
      "Epoch 14/57\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.1346 - accuracy: 0.5455\n",
      "Epoch 15/57\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.1213 - accuracy: 0.6136\n",
      "Epoch 16/57\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0495 - accuracy: 0.6136\n",
      "Epoch 17/57\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.0351 - accuracy: 0.6136\n",
      "Epoch 18/57\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0006 - accuracy: 0.5909\n",
      "Epoch 19/57\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.9835 - accuracy: 0.6136\n",
      "Epoch 20/57\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.9724 - accuracy: 0.6136\n",
      "Epoch 21/57\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.9665 - accuracy: 0.6136\n",
      "Epoch 22/57\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.9469 - accuracy: 0.5682\n",
      "Epoch 23/57\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.9571 - accuracy: 0.5455\n",
      "Epoch 24/57\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.8924 - accuracy: 0.5909\n",
      "Epoch 25/57\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 1.9052 - accuracy: 0.6364\n",
      "Epoch 26/57\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.8967 - accuracy: 0.6136\n",
      "Epoch 27/57\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.9313 - accuracy: 0.6136\n",
      "Epoch 28/57\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.8768 - accuracy: 0.6136\n",
      "Epoch 29/57\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.8719 - accuracy: 0.6364\n",
      "Epoch 30/57\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.8551 - accuracy: 0.6818\n",
      "Epoch 31/57\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.5993 - accuracy: 0.6591\n",
      "Epoch 32/57\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.8519 - accuracy: 0.6591\n",
      "Epoch 33/57\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.5591 - accuracy: 0.6591\n",
      "Epoch 34/57\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.5211 - accuracy: 0.6591\n",
      "Epoch 35/57\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 1.4947 - accuracy: 0.6818\n",
      "Epoch 36/57\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.5305 - accuracy: 0.6591\n",
      "Epoch 37/57\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 1.4680 - accuracy: 0.6591\n",
      "Epoch 38/57\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.4523 - accuracy: 0.6364\n",
      "Epoch 39/57\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.4320 - accuracy: 0.6591\n",
      "Epoch 40/57\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 1.4541 - accuracy: 0.6591\n",
      "Epoch 41/57\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 1.4194 - accuracy: 0.6591\n",
      "Epoch 42/57\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.3709 - accuracy: 0.6591\n",
      "Epoch 43/57\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.3796 - accuracy: 0.6591\n",
      "Epoch 44/57\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.3570 - accuracy: 0.6818\n",
      "Epoch 45/57\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 1.3555 - accuracy: 0.6591\n",
      "Epoch 46/57\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.3192 - accuracy: 0.6818\n",
      "Epoch 47/57\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 1.2968 - accuracy: 0.6591\n",
      "Epoch 48/57\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.3086 - accuracy: 0.6591\n",
      "Epoch 49/57\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.2891 - accuracy: 0.7273\n",
      "Epoch 50/57\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.5926 - accuracy: 0.6591\n",
      "Epoch 51/57\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 1.2920 - accuracy: 0.6136\n",
      "Epoch 52/57\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.2900 - accuracy: 0.7045\n",
      "Epoch 53/57\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.2370 - accuracy: 0.7045\n",
      "Epoch 54/57\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.2111 - accuracy: 0.6818\n",
      "Epoch 55/57\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.2588 - accuracy: 0.6818\n",
      "Epoch 56/57\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.5751 - accuracy: 0.7045\n",
      "Epoch 57/57\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.2292 - accuracy: 0.7500\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5405e6dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.1041 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:55:37,027]\u001b[0m Trial 69 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 130, 'num_epochs': 57}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/65\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.4582 - accuracy: 0.0455\n",
      "Epoch 2/65\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.0809 - accuracy: 0.2045\n",
      "Epoch 3/65\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 2.3766 - accuracy: 0.3182\n",
      "Epoch 4/65\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.2909 - accuracy: 0.3409\n",
      "Epoch 5/65\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 2.2460 - accuracy: 0.3864\n",
      "Epoch 6/65\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 1.8701 - accuracy: 0.4318\n",
      "Epoch 7/65\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.8380 - accuracy: 0.4545\n",
      "Epoch 8/65\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.7982 - accuracy: 0.6136\n",
      "Epoch 9/65\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.7648 - accuracy: 0.6136\n",
      "Epoch 10/65\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.7344 - accuracy: 0.5455\n",
      "Epoch 11/65\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.7286 - accuracy: 0.5455\n",
      "Epoch 12/65\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.7071 - accuracy: 0.5455\n",
      "Epoch 13/65\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.7021 - accuracy: 0.6136\n",
      "Epoch 14/65\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.6715 - accuracy: 0.6136\n",
      "Epoch 15/65\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.6489 - accuracy: 0.6136\n",
      "Epoch 16/65\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.5980 - accuracy: 0.5909\n",
      "Epoch 17/65\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.5866 - accuracy: 0.6136\n",
      "Epoch 18/65\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.5630 - accuracy: 0.5909\n",
      "Epoch 19/65\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.5542 - accuracy: 0.6136\n",
      "Epoch 20/65\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.5098 - accuracy: 0.6136\n",
      "Epoch 21/65\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.4792 - accuracy: 0.6364\n",
      "Epoch 22/65\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.4845 - accuracy: 0.6591\n",
      "Epoch 23/65\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.4480 - accuracy: 0.6818\n",
      "Epoch 24/65\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.3896 - accuracy: 0.6818\n",
      "Epoch 25/65\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.3565 - accuracy: 0.6591\n",
      "Epoch 26/65\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 1.3851 - accuracy: 0.6818\n",
      "Epoch 27/65\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1.3558 - accuracy: 0.6591\n",
      "Epoch 28/65\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.3216 - accuracy: 0.6591\n",
      "Epoch 29/65\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.2940 - accuracy: 0.6818\n",
      "Epoch 30/65\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.3204 - accuracy: 0.6364\n",
      "Epoch 31/65\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.2644 - accuracy: 0.6591\n",
      "Epoch 32/65\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.2610 - accuracy: 0.6818\n",
      "Epoch 33/65\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.2567 - accuracy: 0.6818\n",
      "Epoch 34/65\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.2318 - accuracy: 0.7045\n",
      "Epoch 35/65\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.2278 - accuracy: 0.6818\n",
      "Epoch 36/65\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.2009 - accuracy: 0.6818\n",
      "Epoch 37/65\n",
      "1/1 [==============================] - 0s 187ms/step - loss: nan - accuracy: 0.7273\n",
      "Epoch 38/65\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/65\n",
      "1/1 [==============================] - 0s 152ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/65\n",
      "1/1 [==============================] - 0s 161ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/65\n",
      "1/1 [==============================] - 0s 212ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/65\n",
      "1/1 [==============================] - 0s 140ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/65\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/65\n",
      "1/1 [==============================] - 0s 213ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/65\n",
      "1/1 [==============================] - 0s 166ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/65\n",
      "1/1 [==============================] - 0s 196ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/65\n",
      "1/1 [==============================] - 0s 212ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/65\n",
      "1/1 [==============================] - 0s 162ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/65\n",
      "1/1 [==============================] - 0s 173ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/65\n",
      "1/1 [==============================] - 0s 187ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/65\n",
      "1/1 [==============================] - 0s 135ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/65\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/65\n",
      "1/1 [==============================] - 0s 265ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/65\n",
      "1/1 [==============================] - 0s 441ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/65\n",
      "1/1 [==============================] - 0s 420ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/65\n",
      "1/1 [==============================] - 0s 258ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/65\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/65\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/65\n",
      "1/1 [==============================] - 0s 220ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/65\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/65\n",
      "1/1 [==============================] - 0s 231ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/65\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/65\n",
      "1/1 [==============================] - 0s 338ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/65\n",
      "1/1 [==============================] - 0s 265ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/65\n",
      "1/1 [==============================] - 0s 268ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560d6d160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:56:01,941]\u001b[0m Trial 70 finished with value: 0.5 and parameters: {'embedding_output_dim': 145, 'num_epochs': 65}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/41\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.3750 - accuracy: 0.0682\n",
      "Epoch 2/41\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 4.1590 - accuracy: 0.5227\n",
      "Epoch 3/41\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 3.7288 - accuracy: 0.6364\n",
      "Epoch 4/41\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 3.4163 - accuracy: 0.6364\n",
      "Epoch 5/41\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 3.3717 - accuracy: 0.6364\n",
      "Epoch 6/41\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 2.7689 - accuracy: 0.6818\n",
      "Epoch 7/41\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.7669 - accuracy: 0.6364\n",
      "Epoch 8/41\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 2.6993 - accuracy: 0.6364\n",
      "Epoch 9/41\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 2.6856 - accuracy: 0.6591\n",
      "Epoch 10/41\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.6344 - accuracy: 0.6591\n",
      "Epoch 11/41\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 2.6368 - accuracy: 0.6364\n",
      "Epoch 12/41\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 2.6103 - accuracy: 0.6364\n",
      "Epoch 13/41\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 2.6035 - accuracy: 0.6136\n",
      "Epoch 14/41\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 2.5637 - accuracy: 0.6364\n",
      "Epoch 15/41\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 2.5384 - accuracy: 0.6591\n",
      "Epoch 16/41\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 2.5452 - accuracy: 0.6364\n",
      "Epoch 17/41\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 2.5062 - accuracy: 0.6364\n",
      "Epoch 18/41\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.4944 - accuracy: 0.6591\n",
      "Epoch 19/41\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 2.4506 - accuracy: 0.6591\n",
      "Epoch 20/41\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 2.4822 - accuracy: 0.6364\n",
      "Epoch 21/41\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.4307 - accuracy: 0.6818\n",
      "Epoch 22/41\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 2.4138 - accuracy: 0.6591\n",
      "Epoch 23/41\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.4151 - accuracy: 0.6818\n",
      "Epoch 24/41\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.3955 - accuracy: 0.6818\n",
      "Epoch 25/41\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 2.3716 - accuracy: 0.6818\n",
      "Epoch 26/41\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 2.3503 - accuracy: 0.6818\n",
      "Epoch 27/41\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.3288 - accuracy: 0.6818\n",
      "Epoch 28/41\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.0730 - accuracy: 0.6364\n",
      "Epoch 29/41\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 2.0040 - accuracy: 0.6364\n",
      "Epoch 30/41\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 1.9968 - accuracy: 0.6591\n",
      "Epoch 31/41\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.0046 - accuracy: 0.6591\n",
      "Epoch 32/41\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 2.0149 - accuracy: 0.6364\n",
      "Epoch 33/41\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.0233 - accuracy: 0.6818\n",
      "Epoch 34/41\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 2.0101 - accuracy: 0.6818\n",
      "Epoch 35/41\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 2.0344 - accuracy: 0.6818\n",
      "Epoch 36/41\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 2.0236 - accuracy: 0.7045\n",
      "Epoch 37/41\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.9889 - accuracy: 0.6818\n",
      "Epoch 38/41\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.9736 - accuracy: 0.7045\n",
      "Epoch 39/41\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.3170 - accuracy: 0.6591\n",
      "Epoch 40/41\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.9804 - accuracy: 0.6364\n",
      "Epoch 41/41\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 2.2912 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c615e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4814 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:56:25,406]\u001b[0m Trial 71 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 209, 'num_epochs': 41}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/71\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.5315 - accuracy: 0.0000e+00\n",
      "Epoch 2/71\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 6.1315 - accuracy: 0.4318\n",
      "Epoch 3/71\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 5.7058 - accuracy: 0.4318\n",
      "Epoch 4/71\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 5.6467 - accuracy: 0.4091\n",
      "Epoch 5/71\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 5.6185 - accuracy: 0.4318\n",
      "Epoch 6/71\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 5.5613 - accuracy: 0.4091\n",
      "Epoch 7/71\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 5.5574 - accuracy: 0.4091\n",
      "Epoch 8/71\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 5.5119 - accuracy: 0.4545\n",
      "Epoch 9/71\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 5.5128 - accuracy: 0.4091\n",
      "Epoch 10/71\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 5.4671 - accuracy: 0.4318\n",
      "Epoch 11/71\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 5.4471 - accuracy: 0.4318\n",
      "Epoch 12/71\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 5.4301 - accuracy: 0.4318\n",
      "Epoch 13/71\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 5.4174 - accuracy: 0.4318\n",
      "Epoch 14/71\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 5.3952 - accuracy: 0.4318\n",
      "Epoch 15/71\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 5.3856 - accuracy: 0.4318\n",
      "Epoch 16/71\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 5.3784 - accuracy: 0.4318\n",
      "Epoch 17/71\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 5.3552 - accuracy: 0.4318\n",
      "Epoch 18/71\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 5.3481 - accuracy: 0.4545\n",
      "Epoch 19/71\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 5.3313 - accuracy: 0.4545\n",
      "Epoch 20/71\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 5.3372 - accuracy: 0.4318\n",
      "Epoch 21/71\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 5.3064 - accuracy: 0.4773\n",
      "Epoch 22/71\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 5.2936 - accuracy: 0.4545\n",
      "Epoch 23/71\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 5.2970 - accuracy: 0.4318\n",
      "Epoch 24/71\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 5.2867 - accuracy: 0.4545\n",
      "Epoch 25/71\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 5.2576 - accuracy: 0.4773\n",
      "Epoch 26/71\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 5.2887 - accuracy: 0.4545\n",
      "Epoch 27/71\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 5.2448 - accuracy: 0.4773\n",
      "Epoch 28/71\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 5.5762 - accuracy: 0.4545\n",
      "Epoch 29/71\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 5.3337 - accuracy: 0.4318\n",
      "Epoch 30/71\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 5.2796 - accuracy: 0.4318\n",
      "Epoch 31/71\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 5.1270 - accuracy: 0.4545\n",
      "Epoch 32/71\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 5.0669 - accuracy: 0.4091\n",
      "Epoch 33/71\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 4.8492 - accuracy: 0.4091\n",
      "Epoch 34/71\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 4.3506 - accuracy: 0.3864\n",
      "Epoch 35/71\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.7842 - accuracy: 0.3864\n",
      "Epoch 36/71\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.8167 - accuracy: 0.3864\n",
      "Epoch 37/71\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 1.6592 - accuracy: 0.3409\n",
      "Epoch 38/71\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.6302 - accuracy: 0.2955\n",
      "Epoch 39/71\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 1.6159 - accuracy: 0.3409\n",
      "Epoch 40/71\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 1.5852 - accuracy: 0.4773\n",
      "Epoch 41/71\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.6014 - accuracy: 0.4318\n",
      "Epoch 42/71\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 1.5606 - accuracy: 0.4773\n",
      "Epoch 43/71\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.5669 - accuracy: 0.4545\n",
      "Epoch 44/71\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.5225 - accuracy: 0.4773\n",
      "Epoch 45/71\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1.5026 - accuracy: 0.4773\n",
      "Epoch 46/71\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.4883 - accuracy: 0.4773\n",
      "Epoch 47/71\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.4685 - accuracy: 0.5227\n",
      "Epoch 48/71\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 1.4537 - accuracy: 0.5000\n",
      "Epoch 49/71\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1.4071 - accuracy: 0.5227\n",
      "Epoch 50/71\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.4284 - accuracy: 0.5455\n",
      "Epoch 51/71\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.3803 - accuracy: 0.5682\n",
      "Epoch 52/71\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.3699 - accuracy: 0.5682\n",
      "Epoch 53/71\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 1.3533 - accuracy: 0.5682\n",
      "Epoch 54/71\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.3414 - accuracy: 0.5909\n",
      "Epoch 55/71\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 1.3037 - accuracy: 0.6136\n",
      "Epoch 56/71\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 1.2985 - accuracy: 0.6136\n",
      "Epoch 57/71\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.2628 - accuracy: 0.6136\n",
      "Epoch 58/71\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 1.2519 - accuracy: 0.6591\n",
      "Epoch 59/71\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1.2376 - accuracy: 0.6136\n",
      "Epoch 60/71\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 1.2285 - accuracy: 0.6136\n",
      "Epoch 61/71\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.2027 - accuracy: 0.6591\n",
      "Epoch 62/71\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.1772 - accuracy: 0.6591\n",
      "Epoch 63/71\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 1.1706 - accuracy: 0.6818\n",
      "Epoch 64/71\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 1.1518 - accuracy: 0.6591\n",
      "Epoch 65/71\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 1.1615 - accuracy: 0.6591\n",
      "Epoch 66/71\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 1.1374 - accuracy: 0.6364\n",
      "Epoch 67/71\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 1.1281 - accuracy: 0.6591\n",
      "Epoch 68/71\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.1150 - accuracy: 0.6364\n",
      "Epoch 69/71\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.1006 - accuracy: 0.6591\n",
      "Epoch 70/71\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.0912 - accuracy: 0.6591\n",
      "Epoch 71/71\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 1.0739 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5401413a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0457 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:57:02,082]\u001b[0m Trial 72 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 243, 'num_epochs': 71}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/49\n",
      "1/1 [==============================] - 10s 10s/step - loss: 10.3134 - accuracy: 0.0909\n",
      "Epoch 2/49\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 3.0335 - accuracy: 0.3864\n",
      "Epoch 3/49\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 2.7843 - accuracy: 0.6364\n",
      "Epoch 4/49\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.7000 - accuracy: 0.6591\n",
      "Epoch 5/49\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.6296 - accuracy: 0.6364\n",
      "Epoch 6/49\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.6076 - accuracy: 0.6364\n",
      "Epoch 7/49\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.5792 - accuracy: 0.5909\n",
      "Epoch 8/49\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.5122 - accuracy: 0.6591\n",
      "Epoch 9/49\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.5410 - accuracy: 0.6136\n",
      "Epoch 10/49\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 2.4978 - accuracy: 0.6136\n",
      "Epoch 11/49\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.4583 - accuracy: 0.6364\n",
      "Epoch 12/49\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 2.4329 - accuracy: 0.6591\n",
      "Epoch 13/49\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.3882 - accuracy: 0.6591\n",
      "Epoch 14/49\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.3680 - accuracy: 0.6136\n",
      "Epoch 15/49\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.3649 - accuracy: 0.7045\n",
      "Epoch 16/49\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 2.3215 - accuracy: 0.7273\n",
      "Epoch 17/49\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 2.2973 - accuracy: 0.7045\n",
      "Epoch 18/49\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.2611 - accuracy: 0.7045\n",
      "Epoch 19/49\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 2.2329 - accuracy: 0.6818\n",
      "Epoch 20/49\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.2391 - accuracy: 0.6818\n",
      "Epoch 21/49\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 2.2062 - accuracy: 0.7045\n",
      "Epoch 22/49\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2.1876 - accuracy: 0.7273\n",
      "Epoch 23/49\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.1544 - accuracy: 0.7273\n",
      "Epoch 24/49\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 2.1364 - accuracy: 0.7273\n",
      "Epoch 25/49\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.7905 - accuracy: 0.7045\n",
      "Epoch 26/49\n",
      "1/1 [==============================] - 0s 232ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 27/49\n",
      "1/1 [==============================] - 0s 195ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 28/49\n",
      "1/1 [==============================] - 0s 224ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 29/49\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 30/49\n",
      "1/1 [==============================] - 0s 223ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 31/49\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 32/49\n",
      "1/1 [==============================] - 0s 224ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 33/49\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 34/49\n",
      "1/1 [==============================] - 0s 244ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 35/49\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 36/49\n",
      "1/1 [==============================] - 0s 207ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 37/49\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 38/49\n",
      "1/1 [==============================] - 0s 253ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/49\n",
      "1/1 [==============================] - 0s 187ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/49\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/49\n",
      "1/1 [==============================] - 0s 259ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/49\n",
      "1/1 [==============================] - 0s 224ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/49\n",
      "1/1 [==============================] - 0s 351ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/49\n",
      "1/1 [==============================] - 0s 194ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/49\n",
      "1/1 [==============================] - 0s 174ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/49\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/49\n",
      "1/1 [==============================] - 0s 260ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/49\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/49\n",
      "1/1 [==============================] - 0s 206ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c3f7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:57:23,877]\u001b[0m Trial 73 finished with value: 0.5 and parameters: {'embedding_output_dim': 172, 'num_epochs': 49}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/55\n",
      "1/1 [==============================] - 10s 10s/step - loss: 13.1659 - accuracy: 0.0455\n",
      "Epoch 2/55\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 9.2497 - accuracy: 0.0455\n",
      "Epoch 3/55\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 5.0378 - accuracy: 0.0455\n",
      "Epoch 4/55\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 3.6771 - accuracy: 0.0455\n",
      "Epoch 5/55\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 3.5060 - accuracy: 0.0455\n",
      "Epoch 6/55\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 3.4609 - accuracy: 0.0455\n",
      "Epoch 7/55\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 3.3606 - accuracy: 0.0682\n",
      "Epoch 8/55\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 3.3037 - accuracy: 0.0682\n",
      "Epoch 9/55\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 3.2082 - accuracy: 0.1818\n",
      "Epoch 10/55\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 3.1593 - accuracy: 0.4091\n",
      "Epoch 11/55\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 3.1191 - accuracy: 0.5000\n",
      "Epoch 12/55\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 3.0832 - accuracy: 0.4773\n",
      "Epoch 13/55\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 3.0803 - accuracy: 0.5227\n",
      "Epoch 14/55\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 3.0738 - accuracy: 0.5000\n",
      "Epoch 15/55\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 3.0229 - accuracy: 0.5455\n",
      "Epoch 16/55\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 2.9939 - accuracy: 0.5227\n",
      "Epoch 17/55\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 2.9528 - accuracy: 0.5682\n",
      "Epoch 18/55\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 2.9452 - accuracy: 0.5909\n",
      "Epoch 19/55\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 2.9331 - accuracy: 0.5682\n",
      "Epoch 20/55\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 2.8883 - accuracy: 0.5909\n",
      "Epoch 21/55\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 2.8618 - accuracy: 0.6136\n",
      "Epoch 22/55\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 2.8443 - accuracy: 0.5682\n",
      "Epoch 23/55\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 2.8096 - accuracy: 0.5455\n",
      "Epoch 24/55\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 2.8078 - accuracy: 0.5682\n",
      "Epoch 25/55\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 2.7668 - accuracy: 0.5909\n",
      "Epoch 26/55\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 2.7499 - accuracy: 0.5909\n",
      "Epoch 27/55\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 2.7496 - accuracy: 0.5682\n",
      "Epoch 28/55\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 2.4770 - accuracy: 0.5682\n",
      "Epoch 29/55\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 2.4167 - accuracy: 0.5909\n",
      "Epoch 30/55\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 2.3939 - accuracy: 0.5909\n",
      "Epoch 31/55\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 2.3771 - accuracy: 0.6136\n",
      "Epoch 32/55\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 2.3257 - accuracy: 0.6136\n",
      "Epoch 33/55\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 2.3252 - accuracy: 0.6818\n",
      "Epoch 34/55\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 2.3364 - accuracy: 0.6136\n",
      "Epoch 35/55\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 2.3101 - accuracy: 0.6591\n",
      "Epoch 36/55\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 2.0534 - accuracy: 0.6364\n",
      "Epoch 37/55\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 2.0529 - accuracy: 0.6591\n",
      "Epoch 38/55\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.4690 - accuracy: 0.6591\n",
      "Epoch 39/55\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.3622 - accuracy: 0.6364\n",
      "Epoch 40/55\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.3534 - accuracy: 0.6591\n",
      "Epoch 41/55\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 1.0423 - accuracy: 0.6818\n",
      "Epoch 42/55\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.0571 - accuracy: 0.6591\n",
      "Epoch 43/55\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.0192 - accuracy: 0.6818\n",
      "Epoch 44/55\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.0354 - accuracy: 0.6364\n",
      "Epoch 45/55\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 1.0427 - accuracy: 0.6818\n",
      "Epoch 46/55\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.0105 - accuracy: 0.6364\n",
      "Epoch 47/55\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.9839 - accuracy: 0.6364\n",
      "Epoch 48/55\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.9988 - accuracy: 0.6136\n",
      "Epoch 49/55\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.0024 - accuracy: 0.6591\n",
      "Epoch 50/55\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.9943 - accuracy: 0.5909\n",
      "Epoch 51/55\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.9835 - accuracy: 0.6136\n",
      "Epoch 52/55\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.9413 - accuracy: 0.6591\n",
      "Epoch 53/55\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.8958 - accuracy: 0.6591\n",
      "Epoch 54/55\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.8777 - accuracy: 0.6818\n",
      "Epoch 55/55\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.8879 - accuracy: 0.6818\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5612a0f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4698 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:57:56,254]\u001b[0m Trial 74 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 243, 'num_epochs': 55}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/31\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.2870 - accuracy: 0.1591\n",
      "Epoch 2/31\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 3.4999 - accuracy: 0.5227\n",
      "Epoch 3/31\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 3.4777 - accuracy: 0.6136\n",
      "Epoch 4/31\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.8464 - accuracy: 0.5682\n",
      "Epoch 5/31\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.2927 - accuracy: 0.6136\n",
      "Epoch 6/31\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.5220 - accuracy: 0.5909\n",
      "Epoch 7/31\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.9473 - accuracy: 0.4545\n",
      "Epoch 8/31\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.9396 - accuracy: 0.4545\n",
      "Epoch 9/31\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.9256 - accuracy: 0.4318\n",
      "Epoch 10/31\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.9682 - accuracy: 0.4545\n",
      "Epoch 11/31\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.8720 - accuracy: 0.5455\n",
      "Epoch 12/31\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.8766 - accuracy: 0.4773\n",
      "Epoch 13/31\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.8122 - accuracy: 0.4545\n",
      "Epoch 14/31\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.7661 - accuracy: 0.5000\n",
      "Epoch 15/31\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.7528 - accuracy: 0.5227\n",
      "Epoch 16/31\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.6687 - accuracy: 0.5909\n",
      "Epoch 17/31\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.6606 - accuracy: 0.6136\n",
      "Epoch 18/31\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.6088 - accuracy: 0.5909\n",
      "Epoch 19/31\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.6200 - accuracy: 0.6364\n",
      "Epoch 20/31\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.5731 - accuracy: 0.6591\n",
      "Epoch 21/31\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.5754 - accuracy: 0.6364\n",
      "Epoch 22/31\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.5521 - accuracy: 0.6591\n",
      "Epoch 23/31\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.5703 - accuracy: 0.6136\n",
      "Epoch 24/31\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.5098 - accuracy: 0.6591\n",
      "Epoch 25/31\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.4911 - accuracy: 0.6364\n",
      "Epoch 26/31\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.4878 - accuracy: 0.6818\n",
      "Epoch 27/31\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.4589 - accuracy: 0.6364\n",
      "Epoch 28/31\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.4190 - accuracy: 0.6364\n",
      "Epoch 29/31\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.3863 - accuracy: 0.6136\n",
      "Epoch 30/31\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.3836 - accuracy: 0.6591\n",
      "Epoch 31/31\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.3808 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff510635f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5593 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:58:12,624]\u001b[0m Trial 75 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 91, 'num_epochs': 31}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/85\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.7485 - accuracy: 0.0455\n",
      "Epoch 2/85\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 3.7724 - accuracy: 0.5455\n",
      "Epoch 3/85\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 3.3827 - accuracy: 0.6136\n",
      "Epoch 4/85\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.0117 - accuracy: 0.6364\n",
      "Epoch 5/85\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 3.3039 - accuracy: 0.6591\n",
      "Epoch 6/85\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.2768 - accuracy: 0.6818\n",
      "Epoch 7/85\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 3.2687 - accuracy: 0.6136\n",
      "Epoch 8/85\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 3.2329 - accuracy: 0.6136\n",
      "Epoch 9/85\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 3.1901 - accuracy: 0.6591\n",
      "Epoch 10/85\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 3.2019 - accuracy: 0.6364\n",
      "Epoch 11/85\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 3.1581 - accuracy: 0.6364\n",
      "Epoch 12/85\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 3.1325 - accuracy: 0.6136\n",
      "Epoch 13/85\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.1122 - accuracy: 0.6364\n",
      "Epoch 14/85\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 3.0987 - accuracy: 0.6136\n",
      "Epoch 15/85\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 3.0767 - accuracy: 0.6818\n",
      "Epoch 16/85\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.0545 - accuracy: 0.6364\n",
      "Epoch 17/85\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 3.0385 - accuracy: 0.6364\n",
      "Epoch 18/85\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 3.0129 - accuracy: 0.6364\n",
      "Epoch 19/85\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 3.0179 - accuracy: 0.6364\n",
      "Epoch 20/85\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.9786 - accuracy: 0.6591\n",
      "Epoch 21/85\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 2.9632 - accuracy: 0.6591\n",
      "Epoch 22/85\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 2.9412 - accuracy: 0.6364\n",
      "Epoch 23/85\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 2.9385 - accuracy: 0.6364\n",
      "Epoch 24/85\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 2.9239 - accuracy: 0.6364\n",
      "Epoch 25/85\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 2.9103 - accuracy: 0.6591\n",
      "Epoch 26/85\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 2.9056 - accuracy: 0.6591\n",
      "Epoch 27/85\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.8894 - accuracy: 0.6364\n",
      "Epoch 28/85\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.8649 - accuracy: 0.6591\n",
      "Epoch 29/85\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 2.8699 - accuracy: 0.6818\n",
      "Epoch 30/85\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 2.8448 - accuracy: 0.6818\n",
      "Epoch 31/85\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 2.8439 - accuracy: 0.6818\n",
      "Epoch 32/85\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 2.8234 - accuracy: 0.7045\n",
      "Epoch 33/85\n",
      "1/1 [==============================] - 0s 271ms/step - loss: nan - accuracy: 0.7273\n",
      "Epoch 34/85\n",
      "1/1 [==============================] - 0s 274ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 35/85\n",
      "1/1 [==============================] - 0s 367ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 36/85\n",
      "1/1 [==============================] - 0s 321ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 37/85\n",
      "1/1 [==============================] - 0s 287ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 38/85\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/85\n",
      "1/1 [==============================] - 0s 257ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/85\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/85\n",
      "1/1 [==============================] - 0s 272ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/85\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/85\n",
      "1/1 [==============================] - 0s 253ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/85\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/85\n",
      "1/1 [==============================] - 0s 290ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/85\n",
      "1/1 [==============================] - 0s 225ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/85\n",
      "1/1 [==============================] - 0s 221ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/85\n",
      "1/1 [==============================] - 0s 218ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/85\n",
      "1/1 [==============================] - 0s 235ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/85\n",
      "1/1 [==============================] - 0s 216ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/85\n",
      "1/1 [==============================] - 0s 232ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/85\n",
      "1/1 [==============================] - 0s 319ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/85\n",
      "1/1 [==============================] - 0s 193ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/85\n",
      "1/1 [==============================] - 0s 233ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/85\n",
      "1/1 [==============================] - 0s 278ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/85\n",
      "1/1 [==============================] - 0s 259ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/85\n",
      "1/1 [==============================] - 0s 218ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/85\n",
      "1/1 [==============================] - 0s 268ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/85\n",
      "1/1 [==============================] - 0s 206ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/85\n",
      "1/1 [==============================] - 0s 267ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/85\n",
      "1/1 [==============================] - 0s 395ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/85\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/85\n",
      "1/1 [==============================] - 0s 308ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/85\n",
      "1/1 [==============================] - 0s 344ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/85\n",
      "1/1 [==============================] - 0s 356ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/85\n",
      "1/1 [==============================] - 0s 318ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/85\n",
      "1/1 [==============================] - 0s 271ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/85\n",
      "1/1 [==============================] - 0s 305ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/85\n",
      "1/1 [==============================] - 0s 297ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/85\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/85\n",
      "1/1 [==============================] - 0s 344ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/85\n",
      "1/1 [==============================] - 0s 307ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/85\n",
      "1/1 [==============================] - 0s 289ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/85\n",
      "1/1 [==============================] - 0s 289ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/85\n",
      "1/1 [==============================] - 0s 246ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/85\n",
      "1/1 [==============================] - 0s 267ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/85\n",
      "1/1 [==============================] - 0s 271ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/85\n",
      "1/1 [==============================] - 0s 298ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/85\n",
      "1/1 [==============================] - 0s 327ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/85\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/85\n",
      "1/1 [==============================] - 0s 274ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/85\n",
      "1/1 [==============================] - 0s 338ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/85\n",
      "1/1 [==============================] - 0s 307ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/85\n",
      "1/1 [==============================] - 0s 360ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/85\n",
      "1/1 [==============================] - 0s 343ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c036e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:58:46,379]\u001b[0m Trial 76 finished with value: 0.5 and parameters: {'embedding_output_dim': 200, 'num_epochs': 85}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/56\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.0097 - accuracy: 0.0455\n",
      "Epoch 2/56\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6.8680 - accuracy: 0.4545\n",
      "Epoch 3/56\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 4.9894 - accuracy: 0.4318\n",
      "Epoch 4/56\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 3.1623 - accuracy: 0.4318\n",
      "Epoch 5/56\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 3.0012 - accuracy: 0.6136\n",
      "Epoch 6/56\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.9936 - accuracy: 0.5682\n",
      "Epoch 7/56\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 2.9572 - accuracy: 0.5682\n",
      "Epoch 8/56\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.9623 - accuracy: 0.5227\n",
      "Epoch 9/56\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.9256 - accuracy: 0.5682\n",
      "Epoch 10/56\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.9055 - accuracy: 0.5682\n",
      "Epoch 11/56\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.8668 - accuracy: 0.5227\n",
      "Epoch 12/56\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2.8572 - accuracy: 0.5909\n",
      "Epoch 13/56\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.8375 - accuracy: 0.5455\n",
      "Epoch 14/56\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 2.8147 - accuracy: 0.5909\n",
      "Epoch 15/56\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.7943 - accuracy: 0.6364\n",
      "Epoch 16/56\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 2.7512 - accuracy: 0.6136\n",
      "Epoch 17/56\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 2.7347 - accuracy: 0.6136\n",
      "Epoch 18/56\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.6903 - accuracy: 0.6364\n",
      "Epoch 19/56\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 2.6845 - accuracy: 0.6364\n",
      "Epoch 20/56\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 2.9793 - accuracy: 0.6364\n",
      "Epoch 21/56\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.6892 - accuracy: 0.6136\n",
      "Epoch 22/56\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.6502 - accuracy: 0.6136\n",
      "Epoch 23/56\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.6161 - accuracy: 0.6591\n",
      "Epoch 24/56\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 2.6041 - accuracy: 0.6364\n",
      "Epoch 25/56\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 2.5750 - accuracy: 0.6818\n",
      "Epoch 26/56\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.6009 - accuracy: 0.6364\n",
      "Epoch 27/56\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 2.5872 - accuracy: 0.6591\n",
      "Epoch 28/56\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 2.5755 - accuracy: 0.6818\n",
      "Epoch 29/56\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 2.5477 - accuracy: 0.7045\n",
      "Epoch 30/56\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.5467 - accuracy: 0.7045\n",
      "Epoch 31/56\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 2.5367 - accuracy: 0.7273\n",
      "Epoch 32/56\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.5032 - accuracy: 0.6818\n",
      "Epoch 33/56\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.5319 - accuracy: 0.7045\n",
      "Epoch 34/56\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.5171 - accuracy: 0.7045\n",
      "Epoch 35/56\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 2.4967 - accuracy: 0.7045\n",
      "Epoch 36/56\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.4861 - accuracy: 0.7273\n",
      "Epoch 37/56\n",
      "1/1 [==============================] - 0s 174ms/step - loss: nan - accuracy: 0.6818\n",
      "Epoch 38/56\n",
      "1/1 [==============================] - 0s 225ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/56\n",
      "1/1 [==============================] - 0s 162ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/56\n",
      "1/1 [==============================] - 0s 201ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/56\n",
      "1/1 [==============================] - 0s 286ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/56\n",
      "1/1 [==============================] - 0s 153ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/56\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/56\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/56\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/56\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/56\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/56\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/56\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/56\n",
      "1/1 [==============================] - 0s 233ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/56\n",
      "1/1 [==============================] - 0s 263ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/56\n",
      "1/1 [==============================] - 0s 269ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/56\n",
      "1/1 [==============================] - 0s 230ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/56\n",
      "1/1 [==============================] - 0s 325ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/56\n",
      "1/1 [==============================] - 0s 194ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/56\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560a0fe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:59:10,031]\u001b[0m Trial 77 finished with value: 0.5 and parameters: {'embedding_output_dim': 153, 'num_epochs': 56}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/12\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.2369 - accuracy: 0.0682\n",
      "Epoch 2/12\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 3.4805 - accuracy: 0.4545\n",
      "Epoch 3/12\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 3.0711 - accuracy: 0.5682\n",
      "Epoch 4/12\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 2.8006 - accuracy: 0.5909\n",
      "Epoch 5/12\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 2.5408 - accuracy: 0.5455\n",
      "Epoch 6/12\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 2.2270 - accuracy: 0.5455\n",
      "Epoch 7/12\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.2620 - accuracy: 0.5682\n",
      "Epoch 8/12\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 2.1528 - accuracy: 0.5227\n",
      "Epoch 9/12\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.1858 - accuracy: 0.5455\n",
      "Epoch 10/12\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 2.1696 - accuracy: 0.5227\n",
      "Epoch 11/12\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 2.1774 - accuracy: 0.5227\n",
      "Epoch 12/12\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2.1580 - accuracy: 0.5455\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c068e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0045 - accuracy: 0.4545\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:59:23,510]\u001b[0m Trial 78 finished with value: 0.4545454680919647 and parameters: {'embedding_output_dim': 168, 'num_epochs': 12}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/24\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.4610 - accuracy: 0.0227\n",
      "Epoch 2/24\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 4.7460 - accuracy: 0.4318\n",
      "Epoch 3/24\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 4.5504 - accuracy: 0.4318\n",
      "Epoch 4/24\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 4.2359 - accuracy: 0.4318\n",
      "Epoch 5/24\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 4.1605 - accuracy: 0.4318\n",
      "Epoch 6/24\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 4.1467 - accuracy: 0.4318\n",
      "Epoch 7/24\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 4.1251 - accuracy: 0.4318\n",
      "Epoch 8/24\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 4.1116 - accuracy: 0.4318\n",
      "Epoch 9/24\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 3.5535 - accuracy: 0.4318\n",
      "Epoch 10/24\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 3.4922 - accuracy: 0.4318\n",
      "Epoch 11/24\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 3.4864 - accuracy: 0.4318\n",
      "Epoch 12/24\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 3.4570 - accuracy: 0.4318\n",
      "Epoch 13/24\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 3.4176 - accuracy: 0.4318\n",
      "Epoch 14/24\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 3.4113 - accuracy: 0.4318\n",
      "Epoch 15/24\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 3.4115 - accuracy: 0.4318\n",
      "Epoch 16/24\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 3.3983 - accuracy: 0.4318\n",
      "Epoch 17/24\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 3.3744 - accuracy: 0.4318\n",
      "Epoch 18/24\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 3.3691 - accuracy: 0.4318\n",
      "Epoch 19/24\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 3.3657 - accuracy: 0.4318\n",
      "Epoch 20/24\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 3.3449 - accuracy: 0.4318\n",
      "Epoch 21/24\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 3.3593 - accuracy: 0.4318\n",
      "Epoch 22/24\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 3.3591 - accuracy: 0.4318\n",
      "Epoch 23/24\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 3.3622 - accuracy: 0.4318\n",
      "Epoch 24/24\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 3.3423 - accuracy: 0.4318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560cab700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4538 - accuracy: 0.3182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 20:59:42,787]\u001b[0m Trial 79 finished with value: 0.3181818127632141 and parameters: {'embedding_output_dim': 256, 'num_epochs': 24}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/147\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.8349 - accuracy: 0.0682\n",
      "Epoch 2/147\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 7.8944 - accuracy: 0.1591\n",
      "Epoch 3/147\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.5712 - accuracy: 0.2045\n",
      "Epoch 4/147\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 6.1394 - accuracy: 0.1591\n",
      "Epoch 5/147\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 6.4625 - accuracy: 0.2727\n",
      "Epoch 6/147\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.2728 - accuracy: 0.2500\n",
      "Epoch 7/147\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 6.4643 - accuracy: 0.2727\n",
      "Epoch 8/147\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 6.0939 - accuracy: 0.3182\n",
      "Epoch 9/147\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 6.4162 - accuracy: 0.3182\n",
      "Epoch 10/147\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 6.4146 - accuracy: 0.3182\n",
      "Epoch 11/147\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 6.3687 - accuracy: 0.4091\n",
      "Epoch 12/147\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 6.4076 - accuracy: 0.3409\n",
      "Epoch 13/147\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 6.3513 - accuracy: 0.3409\n",
      "Epoch 14/147\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 6.1387 - accuracy: 0.3409\n",
      "Epoch 15/147\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 6.0409 - accuracy: 0.4318\n",
      "Epoch 16/147\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 6.0739 - accuracy: 0.4318\n",
      "Epoch 17/147\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 6.0282 - accuracy: 0.4091\n",
      "Epoch 18/147\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 6.0336 - accuracy: 0.4318\n",
      "Epoch 19/147\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 6.0320 - accuracy: 0.4318\n",
      "Epoch 20/147\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 6.0165 - accuracy: 0.4318\n",
      "Epoch 21/147\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 6.0018 - accuracy: 0.4318\n",
      "Epoch 22/147\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 5.9819 - accuracy: 0.4318\n",
      "Epoch 23/147\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 5.9892 - accuracy: 0.4318\n",
      "Epoch 24/147\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 5.9908 - accuracy: 0.4318\n",
      "Epoch 25/147\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 5.9231 - accuracy: 0.4318\n",
      "Epoch 26/147\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 5.9552 - accuracy: 0.4318\n",
      "Epoch 27/147\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 5.9307 - accuracy: 0.4318\n",
      "Epoch 28/147\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 5.8908 - accuracy: 0.4318\n",
      "Epoch 29/147\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 5.9199 - accuracy: 0.4318\n",
      "Epoch 30/147\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 5.8975 - accuracy: 0.4318\n",
      "Epoch 31/147\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 5.8868 - accuracy: 0.4318\n",
      "Epoch 32/147\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 5.8620 - accuracy: 0.4318\n",
      "Epoch 33/147\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 5.8540 - accuracy: 0.4318\n",
      "Epoch 34/147\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.8464 - accuracy: 0.4318\n",
      "Epoch 35/147\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.8490 - accuracy: 0.4318\n",
      "Epoch 36/147\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 5.8415 - accuracy: 0.4318\n",
      "Epoch 37/147\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 5.8191 - accuracy: 0.4318\n",
      "Epoch 38/147\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 5.8167 - accuracy: 0.4318\n",
      "Epoch 39/147\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.7900 - accuracy: 0.4318\n",
      "Epoch 40/147\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.8203 - accuracy: 0.4318\n",
      "Epoch 41/147\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 5.7940 - accuracy: 0.4318\n",
      "Epoch 42/147\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.7665 - accuracy: 0.4318\n",
      "Epoch 43/147\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 5.7627 - accuracy: 0.4318\n",
      "Epoch 44/147\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 5.7661 - accuracy: 0.4318\n",
      "Epoch 45/147\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 5.7576 - accuracy: 0.4318\n",
      "Epoch 46/147\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 5.7729 - accuracy: 0.4318\n",
      "Epoch 47/147\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 5.7312 - accuracy: 0.4318\n",
      "Epoch 48/147\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 5.7446 - accuracy: 0.4318\n",
      "Epoch 49/147\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 5.7319 - accuracy: 0.4318\n",
      "Epoch 50/147\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 5.7545 - accuracy: 0.4318\n",
      "Epoch 51/147\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 5.7122 - accuracy: 0.4318\n",
      "Epoch 52/147\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 5.7385 - accuracy: 0.4318\n",
      "Epoch 53/147\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.7159 - accuracy: 0.4318\n",
      "Epoch 54/147\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 5.6848 - accuracy: 0.4318\n",
      "Epoch 55/147\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 5.7143 - accuracy: 0.4318\n",
      "Epoch 56/147\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 5.7077 - accuracy: 0.4318\n",
      "Epoch 57/147\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 5.6919 - accuracy: 0.4318\n",
      "Epoch 58/147\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 5.6961 - accuracy: 0.4318\n",
      "Epoch 59/147\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 5.7012 - accuracy: 0.4318\n",
      "Epoch 60/147\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 5.6947 - accuracy: 0.4318\n",
      "Epoch 61/147\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 5.6673 - accuracy: 0.4318\n",
      "Epoch 62/147\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 5.6831 - accuracy: 0.4318\n",
      "Epoch 63/147\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.6755 - accuracy: 0.4318\n",
      "Epoch 64/147\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.6560 - accuracy: 0.4318\n",
      "Epoch 65/147\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.6616 - accuracy: 0.4318\n",
      "Epoch 66/147\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.6470 - accuracy: 0.4318\n",
      "Epoch 67/147\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.6647 - accuracy: 0.4318\n",
      "Epoch 68/147\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.6499 - accuracy: 0.4318\n",
      "Epoch 69/147\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.6506 - accuracy: 0.4318\n",
      "Epoch 70/147\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.6508 - accuracy: 0.4318\n",
      "Epoch 71/147\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.6472 - accuracy: 0.4318\n",
      "Epoch 72/147\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.6366 - accuracy: 0.4318\n",
      "Epoch 73/147\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.6368 - accuracy: 0.4318\n",
      "Epoch 74/147\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 5.6192 - accuracy: 0.4318\n",
      "Epoch 75/147\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.6091 - accuracy: 0.4318\n",
      "Epoch 76/147\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.6282 - accuracy: 0.4318\n",
      "Epoch 77/147\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.6220 - accuracy: 0.4318\n",
      "Epoch 78/147\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 5.6219 - accuracy: 0.4318\n",
      "Epoch 79/147\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 5.6081 - accuracy: 0.4318\n",
      "Epoch 80/147\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 5.6112 - accuracy: 0.4318\n",
      "Epoch 81/147\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 5.6161 - accuracy: 0.4318\n",
      "Epoch 82/147\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 5.5847 - accuracy: 0.4318\n",
      "Epoch 83/147\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 5.5994 - accuracy: 0.4318\n",
      "Epoch 84/147\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.6274 - accuracy: 0.4318\n",
      "Epoch 85/147\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.5947 - accuracy: 0.4318\n",
      "Epoch 86/147\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 5.6236 - accuracy: 0.4318\n",
      "Epoch 87/147\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 5.6015 - accuracy: 0.4318\n",
      "Epoch 88/147\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 5.5949 - accuracy: 0.4318\n",
      "Epoch 89/147\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.5922 - accuracy: 0.4318\n",
      "Epoch 90/147\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.5955 - accuracy: 0.4318\n",
      "Epoch 91/147\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.6046 - accuracy: 0.4318\n",
      "Epoch 92/147\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.5650 - accuracy: 0.4545\n",
      "Epoch 93/147\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.5760 - accuracy: 0.4318\n",
      "Epoch 94/147\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.6118 - accuracy: 0.4545\n",
      "Epoch 95/147\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6238 - accuracy: 0.4545\n",
      "Epoch 96/147\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.5696 - accuracy: 0.4545\n",
      "Epoch 97/147\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 5.5556 - accuracy: 0.4545\n",
      "Epoch 98/147\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 5.5465 - accuracy: 0.4318\n",
      "Epoch 99/147\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 5.5602 - accuracy: 0.4773\n",
      "Epoch 100/147\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.5488 - accuracy: 0.4773\n",
      "Epoch 101/147\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.5861 - accuracy: 0.4318\n",
      "Epoch 102/147\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.5652 - accuracy: 0.4545\n",
      "Epoch 103/147\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.5603 - accuracy: 0.4318\n",
      "Epoch 104/147\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 5.5405 - accuracy: 0.4545\n",
      "Epoch 105/147\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.5501 - accuracy: 0.4545\n",
      "Epoch 106/147\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.5374 - accuracy: 0.4773\n",
      "Epoch 107/147\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 5.5248 - accuracy: 0.4318\n",
      "Epoch 108/147\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 5.5048 - accuracy: 0.4545\n",
      "Epoch 109/147\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.5163 - accuracy: 0.4773\n",
      "Epoch 110/147\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.5543 - accuracy: 0.4318\n",
      "Epoch 111/147\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.5122 - accuracy: 0.4318\n",
      "Epoch 112/147\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.5438 - accuracy: 0.4545\n",
      "Epoch 113/147\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 5.5323 - accuracy: 0.5227\n",
      "Epoch 114/147\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 5.5062 - accuracy: 0.4773\n",
      "Epoch 115/147\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.8400 - accuracy: 0.5000\n",
      "Epoch 116/147\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 5.5388 - accuracy: 0.4091\n",
      "Epoch 117/147\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.5371 - accuracy: 0.4318\n",
      "Epoch 118/147\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.5306 - accuracy: 0.4773\n",
      "Epoch 119/147\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.5293 - accuracy: 0.5000\n",
      "Epoch 120/147\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.5514 - accuracy: 0.4545\n",
      "Epoch 121/147\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.5173 - accuracy: 0.5455\n",
      "Epoch 122/147\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.8757 - accuracy: 0.5000\n",
      "Epoch 123/147\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.5174 - accuracy: 0.5227\n",
      "Epoch 124/147\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.5632 - accuracy: 0.5227\n",
      "Epoch 125/147\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.5246 - accuracy: 0.5455\n",
      "Epoch 126/147\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 5.8698 - accuracy: 0.4773\n",
      "Epoch 127/147\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.5512 - accuracy: 0.4318\n",
      "Epoch 128/147\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.5442 - accuracy: 0.4545\n",
      "Epoch 129/147\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.5349 - accuracy: 0.4773\n",
      "Epoch 130/147\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.5215 - accuracy: 0.4545\n",
      "Epoch 131/147\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.5174 - accuracy: 0.4318\n",
      "Epoch 132/147\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 5.5297 - accuracy: 0.4773\n",
      "Epoch 133/147\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 5.5276 - accuracy: 0.4773\n",
      "Epoch 134/147\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 5.5101 - accuracy: 0.4545\n",
      "Epoch 135/147\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.5070 - accuracy: 0.5227\n",
      "Epoch 136/147\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.5146 - accuracy: 0.4773\n",
      "Epoch 137/147\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.5144 - accuracy: 0.4773\n",
      "Epoch 138/147\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.5245 - accuracy: 0.4545\n",
      "Epoch 139/147\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 5.5092 - accuracy: 0.4545\n",
      "Epoch 140/147\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 5.5196 - accuracy: 0.4545\n",
      "Epoch 141/147\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.5310 - accuracy: 0.4545\n",
      "Epoch 142/147\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.5091 - accuracy: 0.5000\n",
      "Epoch 143/147\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.5057 - accuracy: 0.5455\n",
      "Epoch 144/147\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 5.4964 - accuracy: 0.5000\n",
      "Epoch 145/147\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.4844 - accuracy: 0.5227\n",
      "Epoch 146/147\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 5.5002 - accuracy: 0.5227\n",
      "Epoch 147/147\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.4636 - accuracy: 0.5909\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c61ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.4527 - accuracy: 0.3182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:00:12,953]\u001b[0m Trial 80 finished with value: 0.3181818127632141 and parameters: {'embedding_output_dim': 51, 'num_epochs': 147}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/71\n",
      "1/1 [==============================] - 10s 10s/step - loss: 6.7393 - accuracy: 0.0909\n",
      "Epoch 2/71\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 3.5101 - accuracy: 0.3182\n",
      "Epoch 3/71\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 3.3103 - accuracy: 0.5227\n",
      "Epoch 4/71\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 3.2083 - accuracy: 0.6364\n",
      "Epoch 5/71\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 3.1474 - accuracy: 0.6591\n",
      "Epoch 6/71\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 3.0945 - accuracy: 0.6136\n",
      "Epoch 7/71\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 3.1032 - accuracy: 0.5909\n",
      "Epoch 8/71\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 3.0882 - accuracy: 0.5909\n",
      "Epoch 9/71\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 3.0561 - accuracy: 0.6136\n",
      "Epoch 10/71\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 3.0185 - accuracy: 0.6364\n",
      "Epoch 11/71\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 3.0163 - accuracy: 0.6591\n",
      "Epoch 12/71\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 2.9841 - accuracy: 0.6591\n",
      "Epoch 13/71\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 2.9446 - accuracy: 0.6591\n",
      "Epoch 14/71\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 2.6312 - accuracy: 0.6818\n",
      "Epoch 15/71\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 2.6170 - accuracy: 0.7045\n",
      "Epoch 16/71\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 2.5944 - accuracy: 0.7045\n",
      "Epoch 17/71\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 2.5896 - accuracy: 0.6818\n",
      "Epoch 18/71\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 2.3190 - accuracy: 0.6818\n",
      "Epoch 19/71\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 2.2747 - accuracy: 0.6818\n",
      "Epoch 20/71\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 2.3202 - accuracy: 0.6591\n",
      "Epoch 21/71\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 2.3430 - accuracy: 0.6136\n",
      "Epoch 22/71\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 2.3305 - accuracy: 0.6591\n",
      "Epoch 23/71\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 2.2828 - accuracy: 0.6364\n",
      "Epoch 24/71\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.2935 - accuracy: 0.6364\n",
      "Epoch 25/71\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 2.3057 - accuracy: 0.6364\n",
      "Epoch 26/71\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.2486 - accuracy: 0.6591\n",
      "Epoch 27/71\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.2409 - accuracy: 0.6591\n",
      "Epoch 28/71\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 2.2125 - accuracy: 0.6818\n",
      "Epoch 29/71\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 2.1670 - accuracy: 0.7045\n",
      "Epoch 30/71\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.1636 - accuracy: 0.7045\n",
      "Epoch 31/71\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 2.1759 - accuracy: 0.7045\n",
      "Epoch 32/71\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 2.1698 - accuracy: 0.7273\n",
      "Epoch 33/71\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 2.1612 - accuracy: 0.7045\n",
      "Epoch 34/71\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 2.1560 - accuracy: 0.7045\n",
      "Epoch 35/71\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 2.1408 - accuracy: 0.7045\n",
      "Epoch 36/71\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 2.1373 - accuracy: 0.7045\n",
      "Epoch 37/71\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 2.1434 - accuracy: 0.7273\n",
      "Epoch 38/71\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 2.1452 - accuracy: 0.7045\n",
      "Epoch 39/71\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 2.1183 - accuracy: 0.7273\n",
      "Epoch 40/71\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 2.1030 - accuracy: 0.7045\n",
      "Epoch 41/71\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 2.1042 - accuracy: 0.7273\n",
      "Epoch 42/71\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 2.1000 - accuracy: 0.7045\n",
      "Epoch 43/71\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 2.0584 - accuracy: 0.7500\n",
      "Epoch 44/71\n",
      "1/1 [==============================] - 0s 317ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 45/71\n",
      "1/1 [==============================] - 0s 368ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/71\n",
      "1/1 [==============================] - 0s 370ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/71\n",
      "1/1 [==============================] - 0s 384ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/71\n",
      "1/1 [==============================] - 0s 367ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/71\n",
      "1/1 [==============================] - 0s 319ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/71\n",
      "1/1 [==============================] - 0s 375ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/71\n",
      "1/1 [==============================] - 0s 339ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/71\n",
      "1/1 [==============================] - 0s 325ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/71\n",
      "1/1 [==============================] - 0s 330ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/71\n",
      "1/1 [==============================] - 0s 327ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/71\n",
      "1/1 [==============================] - 0s 357ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/71\n",
      "1/1 [==============================] - 0s 279ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/71\n",
      "1/1 [==============================] - 0s 291ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/71\n",
      "1/1 [==============================] - 0s 289ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/71\n",
      "1/1 [==============================] - 0s 286ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/71\n",
      "1/1 [==============================] - 0s 278ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/71\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/71\n",
      "1/1 [==============================] - 0s 289ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/71\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/71\n",
      "1/1 [==============================] - 0s 343ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/71\n",
      "1/1 [==============================] - 0s 388ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/71\n",
      "1/1 [==============================] - 0s 337ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/71\n",
      "1/1 [==============================] - 0s 337ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/71\n",
      "1/1 [==============================] - 0s 342ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/71\n",
      "1/1 [==============================] - 0s 413ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/71\n",
      "1/1 [==============================] - 0s 362ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/71\n",
      "1/1 [==============================] - 0s 318ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c3f7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:00:48,091]\u001b[0m Trial 81 finished with value: 0.5 and parameters: {'embedding_output_dim': 240, 'num_epochs': 71}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/45\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.9140 - accuracy: 0.0682\n",
      "Epoch 2/45\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 3.8136 - accuracy: 0.4091\n",
      "Epoch 3/45\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 4.0449 - accuracy: 0.4318\n",
      "Epoch 4/45\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 3.9994 - accuracy: 0.4318\n",
      "Epoch 5/45\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 3.9716 - accuracy: 0.4318\n",
      "Epoch 6/45\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 3.9437 - accuracy: 0.5000\n",
      "Epoch 7/45\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 3.8960 - accuracy: 0.4773\n",
      "Epoch 8/45\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 3.8820 - accuracy: 0.4773\n",
      "Epoch 9/45\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 3.6360 - accuracy: 0.5455\n",
      "Epoch 10/45\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 3.5279 - accuracy: 0.5227\n",
      "Epoch 11/45\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 3.5152 - accuracy: 0.5909\n",
      "Epoch 12/45\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 3.3446 - accuracy: 0.5682\n",
      "Epoch 13/45\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 3.0062 - accuracy: 0.5682\n",
      "Epoch 14/45\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 2.4519 - accuracy: 0.5455\n",
      "Epoch 15/45\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.4146 - accuracy: 0.5909\n",
      "Epoch 16/45\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 2.4205 - accuracy: 0.5909\n",
      "Epoch 17/45\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 2.4377 - accuracy: 0.5682\n",
      "Epoch 18/45\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 2.4042 - accuracy: 0.6136\n",
      "Epoch 19/45\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 2.4184 - accuracy: 0.5682\n",
      "Epoch 20/45\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.3907 - accuracy: 0.6364\n",
      "Epoch 21/45\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 2.3828 - accuracy: 0.6364\n",
      "Epoch 22/45\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 2.3590 - accuracy: 0.5909\n",
      "Epoch 23/45\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 2.3206 - accuracy: 0.5909\n",
      "Epoch 24/45\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 2.2860 - accuracy: 0.6136\n",
      "Epoch 25/45\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 2.2847 - accuracy: 0.6364\n",
      "Epoch 26/45\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 2.2216 - accuracy: 0.5909\n",
      "Epoch 27/45\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 2.2102 - accuracy: 0.5682\n",
      "Epoch 28/45\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.1539 - accuracy: 0.6136\n",
      "Epoch 29/45\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 2.1444 - accuracy: 0.5909\n",
      "Epoch 30/45\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 2.1019 - accuracy: 0.5909\n",
      "Epoch 31/45\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.0907 - accuracy: 0.6364\n",
      "Epoch 32/45\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 2.0639 - accuracy: 0.6136\n",
      "Epoch 33/45\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 2.0513 - accuracy: 0.6136\n",
      "Epoch 34/45\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 2.0355 - accuracy: 0.6136\n",
      "Epoch 35/45\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.0256 - accuracy: 0.6591\n",
      "Epoch 36/45\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 2.0237 - accuracy: 0.6136\n",
      "Epoch 37/45\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 1.9981 - accuracy: 0.6136\n",
      "Epoch 38/45\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.9940 - accuracy: 0.6591\n",
      "Epoch 39/45\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.9634 - accuracy: 0.6591\n",
      "Epoch 40/45\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 1.9904 - accuracy: 0.6818\n",
      "Epoch 41/45\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.9636 - accuracy: 0.6591\n",
      "Epoch 42/45\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 1.9498 - accuracy: 0.6591\n",
      "Epoch 43/45\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.9287 - accuracy: 0.6818\n",
      "Epoch 44/45\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 1.9378 - accuracy: 0.6818\n",
      "Epoch 45/45\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 1.9408 - accuracy: 0.6818\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff578b82ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3341 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:01:13,806]\u001b[0m Trial 82 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 227, 'num_epochs': 45}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/79\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.1733 - accuracy: 0.0227\n",
      "Epoch 2/79\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 5.3315 - accuracy: 0.2727\n",
      "Epoch 3/79\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 4.4549 - accuracy: 0.2727\n",
      "Epoch 4/79\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 3.0126 - accuracy: 0.4091\n",
      "Epoch 5/79\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 2.9120 - accuracy: 0.4091\n",
      "Epoch 6/79\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 2.8656 - accuracy: 0.4773\n",
      "Epoch 7/79\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.8224 - accuracy: 0.5000\n",
      "Epoch 8/79\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.8055 - accuracy: 0.5682\n",
      "Epoch 9/79\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 2.8133 - accuracy: 0.6364\n",
      "Epoch 10/79\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 2.7908 - accuracy: 0.6591\n",
      "Epoch 11/79\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 2.7462 - accuracy: 0.6591\n",
      "Epoch 12/79\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 2.7085 - accuracy: 0.6818\n",
      "Epoch 13/79\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.7170 - accuracy: 0.6818\n",
      "Epoch 14/79\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 2.6763 - accuracy: 0.6364\n",
      "Epoch 15/79\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.6581 - accuracy: 0.6818\n",
      "Epoch 16/79\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 2.6619 - accuracy: 0.6364\n",
      "Epoch 17/79\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 2.6589 - accuracy: 0.6136\n",
      "Epoch 18/79\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 2.6170 - accuracy: 0.6591\n",
      "Epoch 19/79\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 2.6105 - accuracy: 0.6364\n",
      "Epoch 20/79\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.6222 - accuracy: 0.6136\n",
      "Epoch 21/79\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 2.5936 - accuracy: 0.5909\n",
      "Epoch 22/79\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 2.5921 - accuracy: 0.5682\n",
      "Epoch 23/79\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 2.5912 - accuracy: 0.5909\n",
      "Epoch 24/79\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 2.5590 - accuracy: 0.5909\n",
      "Epoch 25/79\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 2.5396 - accuracy: 0.5909\n",
      "Epoch 26/79\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 2.5562 - accuracy: 0.5909\n",
      "Epoch 27/79\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 2.5046 - accuracy: 0.5909\n",
      "Epoch 28/79\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 2.5650 - accuracy: 0.5909\n",
      "Epoch 29/79\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 2.4965 - accuracy: 0.5909\n",
      "Epoch 30/79\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 2.5103 - accuracy: 0.5909\n",
      "Epoch 31/79\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 2.4871 - accuracy: 0.6136\n",
      "Epoch 32/79\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 2.4851 - accuracy: 0.6136\n",
      "Epoch 33/79\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 2.4802 - accuracy: 0.5909\n",
      "Epoch 34/79\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 2.4612 - accuracy: 0.6136\n",
      "Epoch 35/79\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 2.4653 - accuracy: 0.6364\n",
      "Epoch 36/79\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 2.4516 - accuracy: 0.6364\n",
      "Epoch 37/79\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.4336 - accuracy: 0.6136\n",
      "Epoch 38/79\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 2.4333 - accuracy: 0.6364\n",
      "Epoch 39/79\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 2.4307 - accuracy: 0.6364\n",
      "Epoch 40/79\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 2.4041 - accuracy: 0.6364\n",
      "Epoch 41/79\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.4019 - accuracy: 0.6364\n",
      "Epoch 42/79\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.3857 - accuracy: 0.6364\n",
      "Epoch 43/79\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 2.3772 - accuracy: 0.6591\n",
      "Epoch 44/79\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.3645 - accuracy: 0.6591\n",
      "Epoch 45/79\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 2.3569 - accuracy: 0.6591\n",
      "Epoch 46/79\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 2.3272 - accuracy: 0.6818\n",
      "Epoch 47/79\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.3430 - accuracy: 0.6818\n",
      "Epoch 48/79\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 2.3275 - accuracy: 0.6364\n",
      "Epoch 49/79\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 2.3061 - accuracy: 0.7045\n",
      "Epoch 50/79\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 2.3020 - accuracy: 0.7045\n",
      "Epoch 51/79\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 2.3085 - accuracy: 0.6364\n",
      "Epoch 52/79\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 2.2899 - accuracy: 0.6136\n",
      "Epoch 53/79\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 2.2645 - accuracy: 0.6818\n",
      "Epoch 54/79\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 2.2555 - accuracy: 0.6136\n",
      "Epoch 55/79\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.2307 - accuracy: 0.6591\n",
      "Epoch 56/79\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.2163 - accuracy: 0.6591\n",
      "Epoch 57/79\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 2.2124 - accuracy: 0.7273\n",
      "Epoch 58/79\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 2.2121 - accuracy: 0.7045\n",
      "Epoch 59/79\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 2.2351 - accuracy: 0.7045\n",
      "Epoch 60/79\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 2.2324 - accuracy: 0.7045\n",
      "Epoch 61/79\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 2.2251 - accuracy: 0.6364\n",
      "Epoch 62/79\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.2481 - accuracy: 0.6818\n",
      "Epoch 63/79\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 2.2165 - accuracy: 0.6818\n",
      "Epoch 64/79\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 2.2318 - accuracy: 0.6591\n",
      "Epoch 65/79\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.2234 - accuracy: 0.7273\n",
      "Epoch 66/79\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 2.2075 - accuracy: 0.6818\n",
      "Epoch 67/79\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 2.2097 - accuracy: 0.6591\n",
      "Epoch 68/79\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 2.1915 - accuracy: 0.7045\n",
      "Epoch 69/79\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.2312 - accuracy: 0.6818\n",
      "Epoch 70/79\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.2053 - accuracy: 0.6818\n",
      "Epoch 71/79\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 2.1781 - accuracy: 0.6818\n",
      "Epoch 72/79\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 2.2083 - accuracy: 0.7045\n",
      "Epoch 73/79\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 2.1898 - accuracy: 0.6818\n",
      "Epoch 74/79\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.1839 - accuracy: 0.7273\n",
      "Epoch 75/79\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 2.1724 - accuracy: 0.6818\n",
      "Epoch 76/79\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 2.1763 - accuracy: 0.7273\n",
      "Epoch 77/79\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 2.1676 - accuracy: 0.7045\n",
      "Epoch 78/79\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 2.1620 - accuracy: 0.7500\n",
      "Epoch 79/79\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 2.1669 - accuracy: 0.7273\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff570181b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0644 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:01:50,716]\u001b[0m Trial 83 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 209, 'num_epochs': 79}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/45\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.4718 - accuracy: 0.0455\n",
      "Epoch 2/45\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 3.5420 - accuracy: 0.5455\n",
      "Epoch 3/45\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 3.4225 - accuracy: 0.5682\n",
      "Epoch 4/45\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 3.4083 - accuracy: 0.6136\n",
      "Epoch 5/45\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 3.4009 - accuracy: 0.6136\n",
      "Epoch 6/45\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 2.9893 - accuracy: 0.6136\n",
      "Epoch 7/45\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.6927 - accuracy: 0.6136\n",
      "Epoch 8/45\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.6441 - accuracy: 0.6136\n",
      "Epoch 9/45\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.6220 - accuracy: 0.6364\n",
      "Epoch 10/45\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 2.5503 - accuracy: 0.6136\n",
      "Epoch 11/45\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.5520 - accuracy: 0.6136\n",
      "Epoch 12/45\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 2.2816 - accuracy: 0.6136\n",
      "Epoch 13/45\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 2.2223 - accuracy: 0.6364\n",
      "Epoch 14/45\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 2.1802 - accuracy: 0.6364\n",
      "Epoch 15/45\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.1743 - accuracy: 0.6364\n",
      "Epoch 16/45\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 2.1592 - accuracy: 0.6591\n",
      "Epoch 17/45\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.1438 - accuracy: 0.6364\n",
      "Epoch 18/45\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.1129 - accuracy: 0.6364\n",
      "Epoch 19/45\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 2.0903 - accuracy: 0.6591\n",
      "Epoch 20/45\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0610 - accuracy: 0.6364\n",
      "Epoch 21/45\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 2.0338 - accuracy: 0.6136\n",
      "Epoch 22/45\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 2.0157 - accuracy: 0.6364\n",
      "Epoch 23/45\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.0079 - accuracy: 0.6136\n",
      "Epoch 24/45\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 1.9901 - accuracy: 0.6591\n",
      "Epoch 25/45\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 2.0018 - accuracy: 0.6136\n",
      "Epoch 26/45\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.9716 - accuracy: 0.6591\n",
      "Epoch 27/45\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.9475 - accuracy: 0.6364\n",
      "Epoch 28/45\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 1.9328 - accuracy: 0.6818\n",
      "Epoch 29/45\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 1.9159 - accuracy: 0.7045\n",
      "Epoch 30/45\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.9031 - accuracy: 0.6591\n",
      "Epoch 31/45\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.8834 - accuracy: 0.7273\n",
      "Epoch 32/45\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.8742 - accuracy: 0.6818\n",
      "Epoch 33/45\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 1.8721 - accuracy: 0.7045\n",
      "Epoch 34/45\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.8495 - accuracy: 0.7273\n",
      "Epoch 35/45\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.8398 - accuracy: 0.7500\n",
      "Epoch 36/45\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.2005 - accuracy: 0.7500\n",
      "Epoch 37/45\n",
      "1/1 [==============================] - 0s 336ms/step - loss: nan - accuracy: 0.6818\n",
      "Epoch 38/45\n",
      "1/1 [==============================] - 0s 267ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/45\n",
      "1/1 [==============================] - 0s 259ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/45\n",
      "1/1 [==============================] - 0s 302ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/45\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/45\n",
      "1/1 [==============================] - 0s 304ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/45\n",
      "1/1 [==============================] - 0s 298ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/45\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/45\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c38dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:02:13,792]\u001b[0m Trial 84 finished with value: 0.5 and parameters: {'embedding_output_dim': 181, 'num_epochs': 45}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/67\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.4022 - accuracy: 0.0000e+00\n",
      "Epoch 2/67\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 3.8590 - accuracy: 0.2045\n",
      "Epoch 3/67\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 4.2370 - accuracy: 0.2955\n",
      "Epoch 4/67\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 3.6988 - accuracy: 0.3409\n",
      "Epoch 5/67\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 3.3118 - accuracy: 0.3409\n",
      "Epoch 6/67\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 3.2305 - accuracy: 0.3864\n",
      "Epoch 7/67\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.2152 - accuracy: 0.3636\n",
      "Epoch 8/67\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 3.1938 - accuracy: 0.3636\n",
      "Epoch 9/67\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.8527 - accuracy: 0.4318\n",
      "Epoch 10/67\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.8355 - accuracy: 0.4091\n",
      "Epoch 11/67\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.8198 - accuracy: 0.4091\n",
      "Epoch 12/67\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 3.0826 - accuracy: 0.4318\n",
      "Epoch 13/67\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.8303 - accuracy: 0.5000\n",
      "Epoch 14/67\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.7590 - accuracy: 0.4318\n",
      "Epoch 15/67\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.7606 - accuracy: 0.4545\n",
      "Epoch 16/67\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.7770 - accuracy: 0.5455\n",
      "Epoch 17/67\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.7537 - accuracy: 0.5227\n",
      "Epoch 18/67\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.7613 - accuracy: 0.4773\n",
      "Epoch 19/67\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.7527 - accuracy: 0.5227\n",
      "Epoch 20/67\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.7083 - accuracy: 0.5455\n",
      "Epoch 21/67\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.7160 - accuracy: 0.5455\n",
      "Epoch 22/67\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.7594 - accuracy: 0.5227\n",
      "Epoch 23/67\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.7275 - accuracy: 0.5227\n",
      "Epoch 24/67\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.6840 - accuracy: 0.5682\n",
      "Epoch 25/67\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.6865 - accuracy: 0.5455\n",
      "Epoch 26/67\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.6586 - accuracy: 0.5227\n",
      "Epoch 27/67\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.6887 - accuracy: 0.5682\n",
      "Epoch 28/67\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.6750 - accuracy: 0.5455\n",
      "Epoch 29/67\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.6282 - accuracy: 0.5909\n",
      "Epoch 30/67\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.6487 - accuracy: 0.5682\n",
      "Epoch 31/67\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6180 - accuracy: 0.5682\n",
      "Epoch 32/67\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.6123 - accuracy: 0.5909\n",
      "Epoch 33/67\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.6340 - accuracy: 0.5909\n",
      "Epoch 34/67\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.6037 - accuracy: 0.5909\n",
      "Epoch 35/67\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.5623 - accuracy: 0.5909\n",
      "Epoch 36/67\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.5702 - accuracy: 0.6136\n",
      "Epoch 37/67\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 2.5717 - accuracy: 0.5909\n",
      "Epoch 38/67\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.5926 - accuracy: 0.6136\n",
      "Epoch 39/67\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.5541 - accuracy: 0.5909\n",
      "Epoch 40/67\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.5875 - accuracy: 0.5909\n",
      "Epoch 41/67\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.5425 - accuracy: 0.6136\n",
      "Epoch 42/67\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.5309 - accuracy: 0.5909\n",
      "Epoch 43/67\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.5391 - accuracy: 0.6136\n",
      "Epoch 44/67\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.5075 - accuracy: 0.5909\n",
      "Epoch 45/67\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.4892 - accuracy: 0.6136\n",
      "Epoch 46/67\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.5217 - accuracy: 0.6136\n",
      "Epoch 47/67\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.5127 - accuracy: 0.6136\n",
      "Epoch 48/67\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.5297 - accuracy: 0.5909\n",
      "Epoch 49/67\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.5043 - accuracy: 0.6364\n",
      "Epoch 50/67\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.4907 - accuracy: 0.6364\n",
      "Epoch 51/67\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.4938 - accuracy: 0.6136\n",
      "Epoch 52/67\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4954 - accuracy: 0.6136\n",
      "Epoch 53/67\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.4581 - accuracy: 0.6364\n",
      "Epoch 54/67\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.4496 - accuracy: 0.6136\n",
      "Epoch 55/67\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.4430 - accuracy: 0.6136\n",
      "Epoch 56/67\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.4230 - accuracy: 0.6136\n",
      "Epoch 57/67\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.4093 - accuracy: 0.6136\n",
      "Epoch 58/67\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.4450 - accuracy: 0.6591\n",
      "Epoch 59/67\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.4210 - accuracy: 0.6364\n",
      "Epoch 60/67\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.4440 - accuracy: 0.6591\n",
      "Epoch 61/67\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.4112 - accuracy: 0.6136\n",
      "Epoch 62/67\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.3995 - accuracy: 0.6364\n",
      "Epoch 63/67\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3988 - accuracy: 0.6364\n",
      "Epoch 64/67\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.3946 - accuracy: 0.6591\n",
      "Epoch 65/67\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.3981 - accuracy: 0.6591\n",
      "Epoch 66/67\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.3850 - accuracy: 0.6364\n",
      "Epoch 67/67\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.3822 - accuracy: 0.6591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff4e8b3b670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.3229 - accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:02:34,351]\u001b[0m Trial 85 finished with value: 0.8181818127632141 and parameters: {'embedding_output_dim': 67, 'num_epochs': 67}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/68\n",
      "1/1 [==============================] - 9s 9s/step - loss: 11.0809 - accuracy: 0.0227\n",
      "Epoch 2/68\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 5.2811 - accuracy: 0.2727\n",
      "Epoch 3/68\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 4.3027 - accuracy: 0.3636\n",
      "Epoch 4/68\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 4.0915 - accuracy: 0.4091\n",
      "Epoch 5/68\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 4.0228 - accuracy: 0.5000\n",
      "Epoch 6/68\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 4.0142 - accuracy: 0.5909\n",
      "Epoch 7/68\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 3.9993 - accuracy: 0.5682\n",
      "Epoch 8/68\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 3.7117 - accuracy: 0.5455\n",
      "Epoch 9/68\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3.9737 - accuracy: 0.4773\n",
      "Epoch 10/68\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 3.9599 - accuracy: 0.4318\n",
      "Epoch 11/68\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 3.6733 - accuracy: 0.5000\n",
      "Epoch 12/68\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.6871 - accuracy: 0.4545\n",
      "Epoch 13/68\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 3.6470 - accuracy: 0.4318\n",
      "Epoch 14/68\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 3.6272 - accuracy: 0.5227\n",
      "Epoch 15/68\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3.6397 - accuracy: 0.4318\n",
      "Epoch 16/68\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 3.6213 - accuracy: 0.5000\n",
      "Epoch 17/68\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 3.6362 - accuracy: 0.4318\n",
      "Epoch 18/68\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.6175 - accuracy: 0.4318\n",
      "Epoch 19/68\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 3.5994 - accuracy: 0.4318\n",
      "Epoch 20/68\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 3.5846 - accuracy: 0.4773\n",
      "Epoch 21/68\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 3.5798 - accuracy: 0.5000\n",
      "Epoch 22/68\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 3.5627 - accuracy: 0.4545\n",
      "Epoch 23/68\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 3.5622 - accuracy: 0.4773\n",
      "Epoch 24/68\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 3.5394 - accuracy: 0.4318\n",
      "Epoch 25/68\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.5249 - accuracy: 0.4773\n",
      "Epoch 26/68\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 3.5148 - accuracy: 0.4545\n",
      "Epoch 27/68\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 3.5180 - accuracy: 0.5000\n",
      "Epoch 28/68\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.4815 - accuracy: 0.5455\n",
      "Epoch 29/68\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 3.3034 - accuracy: 0.5000\n",
      "Epoch 30/68\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.8414 - accuracy: 0.5455\n",
      "Epoch 31/68\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.8448 - accuracy: 0.5455\n",
      "Epoch 32/68\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.8837 - accuracy: 0.4773\n",
      "Epoch 33/68\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 2.8902 - accuracy: 0.4545\n",
      "Epoch 34/68\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.9226 - accuracy: 0.4773\n",
      "Epoch 35/68\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.9682 - accuracy: 0.5455\n",
      "Epoch 36/68\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.0182 - accuracy: 0.4773\n",
      "Epoch 37/68\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.9692 - accuracy: 0.5000\n",
      "Epoch 38/68\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.0236 - accuracy: 0.4545\n",
      "Epoch 39/68\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.9817 - accuracy: 0.5455\n",
      "Epoch 40/68\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0313 - accuracy: 0.5000\n",
      "Epoch 41/68\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 3.0479 - accuracy: 0.4545\n",
      "Epoch 42/68\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0040 - accuracy: 0.5455\n",
      "Epoch 43/68\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.0552 - accuracy: 0.4773\n",
      "Epoch 44/68\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 3.0263 - accuracy: 0.5455\n",
      "Epoch 45/68\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.1153 - accuracy: 0.5000\n",
      "Epoch 46/68\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 3.0335 - accuracy: 0.4773\n",
      "Epoch 47/68\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.0191 - accuracy: 0.5000\n",
      "Epoch 48/68\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.9733 - accuracy: 0.5000\n",
      "Epoch 49/68\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.9501 - accuracy: 0.5909\n",
      "Epoch 50/68\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.9915 - accuracy: 0.5455\n",
      "Epoch 51/68\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.9648 - accuracy: 0.5227\n",
      "Epoch 52/68\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9846 - accuracy: 0.5227\n",
      "Epoch 53/68\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.9707 - accuracy: 0.5455\n",
      "Epoch 54/68\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.9292 - accuracy: 0.5455\n",
      "Epoch 55/68\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.9357 - accuracy: 0.5909\n",
      "Epoch 56/68\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.8989 - accuracy: 0.5682\n",
      "Epoch 57/68\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.9144 - accuracy: 0.5909\n",
      "Epoch 58/68\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.9052 - accuracy: 0.5000\n",
      "Epoch 59/68\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.8779 - accuracy: 0.5682\n",
      "Epoch 60/68\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.8606 - accuracy: 0.5455\n",
      "Epoch 61/68\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.8521 - accuracy: 0.5682\n",
      "Epoch 62/68\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.8581 - accuracy: 0.5455\n",
      "Epoch 63/68\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.8397 - accuracy: 0.5455\n",
      "Epoch 64/68\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.8345 - accuracy: 0.5682\n",
      "Epoch 65/68\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.8553 - accuracy: 0.5227\n",
      "Epoch 66/68\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.8423 - accuracy: 0.5682\n",
      "Epoch 67/68\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.7961 - accuracy: 0.5909\n",
      "Epoch 68/68\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.8020 - accuracy: 0.5909\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5609d68b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.2806 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:02:53,549]\u001b[0m Trial 86 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 71, 'num_epochs': 68}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/62\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.0491 - accuracy: 0.0909\n",
      "Epoch 2/62\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 3.4444 - accuracy: 0.3636\n",
      "Epoch 3/62\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 3.1045 - accuracy: 0.3409\n",
      "Epoch 4/62\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 2.7409 - accuracy: 0.5682\n",
      "Epoch 5/62\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 2.7044 - accuracy: 0.5455\n",
      "Epoch 6/62\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 2.6772 - accuracy: 0.5455\n",
      "Epoch 7/62\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 2.6541 - accuracy: 0.5455\n",
      "Epoch 8/62\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 2.6295 - accuracy: 0.6591\n",
      "Epoch 9/62\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 2.5885 - accuracy: 0.7273\n",
      "Epoch 10/62\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 2.5772 - accuracy: 0.6818\n",
      "Epoch 11/62\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 2.5255 - accuracy: 0.7045\n",
      "Epoch 12/62\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 2.4942 - accuracy: 0.6591\n",
      "Epoch 13/62\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 2.4678 - accuracy: 0.6591\n",
      "Epoch 14/62\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 2.4281 - accuracy: 0.6136\n",
      "Epoch 15/62\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.4102 - accuracy: 0.6591\n",
      "Epoch 16/62\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 2.3827 - accuracy: 0.6818\n",
      "Epoch 17/62\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 2.3644 - accuracy: 0.6364\n",
      "Epoch 18/62\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 2.3448 - accuracy: 0.6364\n",
      "Epoch 19/62\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 2.3261 - accuracy: 0.6364\n",
      "Epoch 20/62\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 2.0379 - accuracy: 0.6591\n",
      "Epoch 21/62\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 1.9927 - accuracy: 0.6364\n",
      "Epoch 22/62\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 1.9770 - accuracy: 0.6591\n",
      "Epoch 23/62\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1.9918 - accuracy: 0.6591\n",
      "Epoch 24/62\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.9789 - accuracy: 0.6364\n",
      "Epoch 25/62\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.9448 - accuracy: 0.6818\n",
      "Epoch 26/62\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 1.9402 - accuracy: 0.7045\n",
      "Epoch 27/62\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.9017 - accuracy: 0.7500\n",
      "Epoch 28/62\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.9106 - accuracy: 0.6818\n",
      "Epoch 29/62\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 1.8932 - accuracy: 0.6591\n",
      "Epoch 30/62\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.8603 - accuracy: 0.7500\n",
      "Epoch 31/62\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 1.8841 - accuracy: 0.6818\n",
      "Epoch 32/62\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.8530 - accuracy: 0.7273\n",
      "Epoch 33/62\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 1.8479 - accuracy: 0.7273\n",
      "Epoch 34/62\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 1.8239 - accuracy: 0.6818\n",
      "Epoch 35/62\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 1.8141 - accuracy: 0.7273\n",
      "Epoch 36/62\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 1.8238 - accuracy: 0.7273\n",
      "Epoch 37/62\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 2.1221 - accuracy: 0.7273\n",
      "Epoch 38/62\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 2.1143 - accuracy: 0.7273\n",
      "Epoch 39/62\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 2.1210 - accuracy: 0.7273\n",
      "Epoch 40/62\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 2.1308 - accuracy: 0.7273\n",
      "Epoch 41/62\n",
      "1/1 [==============================] - 0s 337ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 42/62\n",
      "1/1 [==============================] - 0s 320ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/62\n",
      "1/1 [==============================] - 0s 321ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/62\n",
      "1/1 [==============================] - 0s 322ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/62\n",
      "1/1 [==============================] - 0s 368ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/62\n",
      "1/1 [==============================] - 0s 339ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/62\n",
      "1/1 [==============================] - 0s 325ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/62\n",
      "1/1 [==============================] - 0s 303ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/62\n",
      "1/1 [==============================] - 0s 279ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/62\n",
      "1/1 [==============================] - 0s 235ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/62\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/62\n",
      "1/1 [==============================] - 0s 455ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/62\n",
      "1/1 [==============================] - 0s 269ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/62\n",
      "1/1 [==============================] - 0s 406ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/62\n",
      "1/1 [==============================] - 0s 305ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/62\n",
      "1/1 [==============================] - 0s 284ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/62\n",
      "1/1 [==============================] - 0s 320ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/62\n",
      "1/1 [==============================] - 0s 263ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/62\n",
      "1/1 [==============================] - 0s 317ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/62\n",
      "1/1 [==============================] - 0s 398ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/62\n",
      "1/1 [==============================] - 0s 323ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/62\n",
      "1/1 [==============================] - 0s 353ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560e13a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:03:26,007]\u001b[0m Trial 87 finished with value: 0.5 and parameters: {'embedding_output_dim': 243, 'num_epochs': 62}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/90\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.6500 - accuracy: 0.1364\n",
      "Epoch 2/90\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 2.5838 - accuracy: 0.4318\n",
      "Epoch 3/90\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 2.5296 - accuracy: 0.4318\n",
      "Epoch 4/90\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.4884 - accuracy: 0.4318\n",
      "Epoch 5/90\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 2.1822 - accuracy: 0.4318\n",
      "Epoch 6/90\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 2.1111 - accuracy: 0.4318\n",
      "Epoch 7/90\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.0809 - accuracy: 0.4545\n",
      "Epoch 8/90\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 2.0759 - accuracy: 0.4545\n",
      "Epoch 9/90\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 2.0728 - accuracy: 0.4545\n",
      "Epoch 10/90\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.0286 - accuracy: 0.5227\n",
      "Epoch 11/90\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 2.0292 - accuracy: 0.5000\n",
      "Epoch 12/90\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 1.9775 - accuracy: 0.5909\n",
      "Epoch 13/90\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.9775 - accuracy: 0.5909\n",
      "Epoch 14/90\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.9426 - accuracy: 0.6136\n",
      "Epoch 15/90\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 1.6497 - accuracy: 0.6591\n",
      "Epoch 16/90\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.6598 - accuracy: 0.6364\n",
      "Epoch 17/90\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 1.5833 - accuracy: 0.6591\n",
      "Epoch 18/90\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.5764 - accuracy: 0.6364\n",
      "Epoch 19/90\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1.5454 - accuracy: 0.6591\n",
      "Epoch 20/90\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1.5336 - accuracy: 0.6591\n",
      "Epoch 21/90\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.5396 - accuracy: 0.6591\n",
      "Epoch 22/90\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.5031 - accuracy: 0.6136\n",
      "Epoch 23/90\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.4778 - accuracy: 0.6591\n",
      "Epoch 24/90\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 1.4450 - accuracy: 0.6818\n",
      "Epoch 25/90\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.4074 - accuracy: 0.6591\n",
      "Epoch 26/90\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 1.4208 - accuracy: 0.6364\n",
      "Epoch 27/90\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.3728 - accuracy: 0.6818\n",
      "Epoch 28/90\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 1.3464 - accuracy: 0.6591\n",
      "Epoch 29/90\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.3240 - accuracy: 0.6818\n",
      "Epoch 30/90\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.3302 - accuracy: 0.6591\n",
      "Epoch 31/90\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 1.3187 - accuracy: 0.6818\n",
      "Epoch 32/90\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.2898 - accuracy: 0.7045\n",
      "Epoch 33/90\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 1.2848 - accuracy: 0.6591\n",
      "Epoch 34/90\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.2601 - accuracy: 0.7273\n",
      "Epoch 35/90\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.2559 - accuracy: 0.6818\n",
      "Epoch 36/90\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.2433 - accuracy: 0.7045\n",
      "Epoch 37/90\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.1896 - accuracy: 0.7500\n",
      "Epoch 38/90\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.2017 - accuracy: 0.7500\n",
      "Epoch 39/90\n",
      "1/1 [==============================] - 0s 280ms/step - loss: nan - accuracy: 0.7045\n",
      "Epoch 40/90\n",
      "1/1 [==============================] - 0s 300ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/90\n",
      "1/1 [==============================] - 0s 264ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/90\n",
      "1/1 [==============================] - 0s 298ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/90\n",
      "1/1 [==============================] - 0s 295ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/90\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/90\n",
      "1/1 [==============================] - 0s 291ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/90\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/90\n",
      "1/1 [==============================] - 0s 340ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/90\n",
      "1/1 [==============================] - 0s 368ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/90\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/90\n",
      "1/1 [==============================] - 0s 364ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/90\n",
      "1/1 [==============================] - 0s 306ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/90\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/90\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/90\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/90\n",
      "1/1 [==============================] - 0s 319ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/90\n",
      "1/1 [==============================] - 0s 375ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/90\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/90\n",
      "1/1 [==============================] - 0s 395ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/90\n",
      "1/1 [==============================] - 0s 448ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/90\n",
      "1/1 [==============================] - 0s 376ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/90\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/90\n",
      "1/1 [==============================] - 0s 389ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/90\n",
      "1/1 [==============================] - 0s 389ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/90\n",
      "1/1 [==============================] - 0s 425ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/90\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/90\n",
      "1/1 [==============================] - 0s 458ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/90\n",
      "1/1 [==============================] - 0s 395ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/90\n",
      "1/1 [==============================] - 0s 453ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/90\n",
      "1/1 [==============================] - 0s 450ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/90\n",
      "1/1 [==============================] - 0s 351ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/90\n",
      "1/1 [==============================] - 0s 489ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/90\n",
      "1/1 [==============================] - 0s 426ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/90\n",
      "1/1 [==============================] - 0s 414ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/90\n",
      "1/1 [==============================] - 0s 420ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 75/90\n",
      "1/1 [==============================] - 0s 347ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 76/90\n",
      "1/1 [==============================] - 0s 345ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 77/90\n",
      "1/1 [==============================] - 0s 427ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 78/90\n",
      "1/1 [==============================] - 0s 373ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 79/90\n",
      "1/1 [==============================] - 0s 329ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 80/90\n",
      "1/1 [==============================] - 0s 347ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 81/90\n",
      "1/1 [==============================] - 0s 400ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 82/90\n",
      "1/1 [==============================] - 1s 517ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 83/90\n",
      "1/1 [==============================] - 0s 324ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 84/90\n",
      "1/1 [==============================] - 0s 390ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 85/90\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 86/90\n",
      "1/1 [==============================] - 1s 664ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 87/90\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 88/90\n",
      "1/1 [==============================] - 0s 377ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 89/90\n",
      "1/1 [==============================] - 0s 389ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 90/90\n",
      "1/1 [==============================] - 0s 338ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c1d4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:04:07,441]\u001b[0m Trial 88 finished with value: 0.5 and parameters: {'embedding_output_dim': 251, 'num_epochs': 90}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/58\n",
      "1/1 [==============================] - 10s 10s/step - loss: 11.1335 - accuracy: 0.1364\n",
      "Epoch 2/58\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 8.3392 - accuracy: 0.4091\n",
      "Epoch 3/58\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 8.5583 - accuracy: 0.4318\n",
      "Epoch 4/58\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 8.5414 - accuracy: 0.4318\n",
      "Epoch 5/58\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 8.5309 - accuracy: 0.4318\n",
      "Epoch 6/58\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 8.5298 - accuracy: 0.4318\n",
      "Epoch 7/58\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 8.5377 - accuracy: 0.4318\n",
      "Epoch 8/58\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 8.5297 - accuracy: 0.4318\n",
      "Epoch 9/58\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 8.5309 - accuracy: 0.4318\n",
      "Epoch 10/58\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 8.5278 - accuracy: 0.4318\n",
      "Epoch 11/58\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 8.5254 - accuracy: 0.4318\n",
      "Epoch 12/58\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 8.5296 - accuracy: 0.4318\n",
      "Epoch 13/58\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 8.5263 - accuracy: 0.4318\n",
      "Epoch 14/58\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 8.5245 - accuracy: 0.4318\n",
      "Epoch 15/58\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 8.5190 - accuracy: 0.4318\n",
      "Epoch 16/58\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 8.5237 - accuracy: 0.4318\n",
      "Epoch 17/58\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 8.5189 - accuracy: 0.4318\n",
      "Epoch 18/58\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 8.5207 - accuracy: 0.4318\n",
      "Epoch 19/58\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 8.5165 - accuracy: 0.4318\n",
      "Epoch 20/58\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 8.5158 - accuracy: 0.4318\n",
      "Epoch 21/58\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 8.5170 - accuracy: 0.4318\n",
      "Epoch 22/58\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 8.5153 - accuracy: 0.4318\n",
      "Epoch 23/58\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 8.5135 - accuracy: 0.4318\n",
      "Epoch 24/58\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 8.5115 - accuracy: 0.4318\n",
      "Epoch 25/58\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 8.5096 - accuracy: 0.4318\n",
      "Epoch 26/58\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 8.5167 - accuracy: 0.4318\n",
      "Epoch 27/58\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 8.5088 - accuracy: 0.4318\n",
      "Epoch 28/58\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 8.5113 - accuracy: 0.4318\n",
      "Epoch 29/58\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 8.5162 - accuracy: 0.4318\n",
      "Epoch 30/58\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 8.5084 - accuracy: 0.4318\n",
      "Epoch 31/58\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 8.5088 - accuracy: 0.4091\n",
      "Epoch 32/58\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 8.5068 - accuracy: 0.4318\n",
      "Epoch 33/58\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 8.5187 - accuracy: 0.4318\n",
      "Epoch 34/58\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 8.5161 - accuracy: 0.4318\n",
      "Epoch 35/58\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 8.5096 - accuracy: 0.4318\n",
      "Epoch 36/58\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 8.5132 - accuracy: 0.4091\n",
      "Epoch 37/58\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 8.4996 - accuracy: 0.4318\n",
      "Epoch 38/58\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 8.5161 - accuracy: 0.4091\n",
      "Epoch 39/58\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 8.5051 - accuracy: 0.4091\n",
      "Epoch 40/58\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 8.5102 - accuracy: 0.4318\n",
      "Epoch 41/58\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 8.5062 - accuracy: 0.4318\n",
      "Epoch 42/58\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 8.5178 - accuracy: 0.4318\n",
      "Epoch 43/58\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 8.5029 - accuracy: 0.4091\n",
      "Epoch 44/58\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 8.5010 - accuracy: 0.4318\n",
      "Epoch 45/58\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 8.4997 - accuracy: 0.4318\n",
      "Epoch 46/58\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 8.5032 - accuracy: 0.4318\n",
      "Epoch 47/58\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 8.5050 - accuracy: 0.4318\n",
      "Epoch 48/58\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 8.4980 - accuracy: 0.4318\n",
      "Epoch 49/58\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 8.8297 - accuracy: 0.4318\n",
      "Epoch 50/58\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 8.5100 - accuracy: 0.4318\n",
      "Epoch 51/58\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 8.4947 - accuracy: 0.4545\n",
      "Epoch 52/58\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 8.4999 - accuracy: 0.4318\n",
      "Epoch 53/58\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 8.5160 - accuracy: 0.4091\n",
      "Epoch 54/58\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 8.5123 - accuracy: 0.4091\n",
      "Epoch 55/58\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 8.5076 - accuracy: 0.4545\n",
      "Epoch 56/58\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 8.5103 - accuracy: 0.4318\n",
      "Epoch 57/58\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 8.5036 - accuracy: 0.4545\n",
      "Epoch 58/58\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 8.4946 - accuracy: 0.4545\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff561296790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.9896 - accuracy: 0.3182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:04:36,862]\u001b[0m Trial 89 finished with value: 0.3181818127632141 and parameters: {'embedding_output_dim': 225, 'num_epochs': 58}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/38\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.8938 - accuracy: 0.0682\n",
      "Epoch 2/38\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.5355 - accuracy: 0.4091\n",
      "Epoch 3/38\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.3534 - accuracy: 0.5227\n",
      "Epoch 4/38\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.2461 - accuracy: 0.5682\n",
      "Epoch 5/38\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.1600 - accuracy: 0.6364\n",
      "Epoch 6/38\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.1293 - accuracy: 0.6136\n",
      "Epoch 7/38\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.0555 - accuracy: 0.6136\n",
      "Epoch 8/38\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0404 - accuracy: 0.6364\n",
      "Epoch 9/38\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.9921 - accuracy: 0.6591\n",
      "Epoch 10/38\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 1.9788 - accuracy: 0.6591\n",
      "Epoch 11/38\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.9679 - accuracy: 0.6818\n",
      "Epoch 12/38\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 1.9379 - accuracy: 0.6591\n",
      "Epoch 13/38\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 1.6297 - accuracy: 0.6364\n",
      "Epoch 14/38\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.6015 - accuracy: 0.6364\n",
      "Epoch 15/38\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 1.5372 - accuracy: 0.6364\n",
      "Epoch 16/38\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.5590 - accuracy: 0.6136\n",
      "Epoch 17/38\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 1.5914 - accuracy: 0.6364\n",
      "Epoch 18/38\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.5592 - accuracy: 0.6136\n",
      "Epoch 19/38\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.5808 - accuracy: 0.6591\n",
      "Epoch 20/38\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.5786 - accuracy: 0.5909\n",
      "Epoch 21/38\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.5561 - accuracy: 0.6136\n",
      "Epoch 22/38\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.5287 - accuracy: 0.6591\n",
      "Epoch 23/38\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 1.4884 - accuracy: 0.6364\n",
      "Epoch 24/38\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.4788 - accuracy: 0.6136\n",
      "Epoch 25/38\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.4361 - accuracy: 0.6591\n",
      "Epoch 26/38\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.4218 - accuracy: 0.6136\n",
      "Epoch 27/38\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.3884 - accuracy: 0.6136\n",
      "Epoch 28/38\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.3714 - accuracy: 0.6591\n",
      "Epoch 29/38\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.3444 - accuracy: 0.6818\n",
      "Epoch 30/38\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.3341 - accuracy: 0.6591\n",
      "Epoch 31/38\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 1.3283 - accuracy: 0.6591\n",
      "Epoch 32/38\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.3109 - accuracy: 0.6818\n",
      "Epoch 33/38\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.2917 - accuracy: 0.6818\n",
      "Epoch 34/38\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.2715 - accuracy: 0.6818\n",
      "Epoch 35/38\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.2841 - accuracy: 0.6818\n",
      "Epoch 36/38\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1.2817 - accuracy: 0.6818\n",
      "Epoch 37/38\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.2534 - accuracy: 0.6818\n",
      "Epoch 38/38\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.2451 - accuracy: 0.7045\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c344c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0045 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:04:57,697]\u001b[0m Trial 90 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 195, 'num_epochs': 38}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.7098 - accuracy: 0.2955\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 1.7946 - accuracy: 0.4545\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.8721 - accuracy: 0.4318\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 1.8084 - accuracy: 0.4318\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 1.5263 - accuracy: 0.4545\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 1.4660 - accuracy: 0.4545\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.4557 - accuracy: 0.4545\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.4275 - accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.4001 - accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 1.3703 - accuracy: 0.4773\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 1.3028 - accuracy: 0.5682\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 1.2823 - accuracy: 0.5682\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 1.2849 - accuracy: 0.5909\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.2202 - accuracy: 0.6136\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 1.2017 - accuracy: 0.6136\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.1908 - accuracy: 0.6364\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.1676 - accuracy: 0.6136\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 1.1308 - accuracy: 0.6364\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.1442 - accuracy: 0.6591\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 1.0756 - accuracy: 0.6364\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.0614 - accuracy: 0.6591\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.0244 - accuracy: 0.7045\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.9992 - accuracy: 0.6818\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.9710 - accuracy: 0.7045\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.9474 - accuracy: 0.7273\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.9810 - accuracy: 0.6136\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.9128 - accuracy: 0.6818\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.8935 - accuracy: 0.7500\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.8911 - accuracy: 0.7273\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.8632 - accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.8633 - accuracy: 0.7273\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 1.2354 - accuracy: 0.6818\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.8770 - accuracy: 0.7045\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8452 - accuracy: 0.7500\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.1879 - accuracy: 0.7273\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.1758 - accuracy: 0.6818\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.1315 - accuracy: 0.7273\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.5196 - accuracy: 0.7045\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 1.8143 - accuracy: 0.7045\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 1.5213 - accuracy: 0.7045\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.8254 - accuracy: 0.7273\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1.8066 - accuracy: 0.7500\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 317ms/step - loss: nan - accuracy: 0.7273\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 352ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 304ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 304ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 294ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 351ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 380ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 385ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5404c83a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:05:25,165]\u001b[0m Trial 91 finished with value: 0.5 and parameters: {'embedding_output_dim': 231, 'num_epochs': 50}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/43\n",
      "1/1 [==============================] - 9s 9s/step - loss: 11.0661 - accuracy: 0.0909\n",
      "Epoch 2/43\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 6.1044 - accuracy: 0.4318\n",
      "Epoch 3/43\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 4.6495 - accuracy: 0.4318\n",
      "Epoch 4/43\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 4.5911 - accuracy: 0.4545\n",
      "Epoch 5/43\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 4.5888 - accuracy: 0.5000\n",
      "Epoch 6/43\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 4.5803 - accuracy: 0.6136\n",
      "Epoch 7/43\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 4.5926 - accuracy: 0.6591\n",
      "Epoch 8/43\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 4.5766 - accuracy: 0.5682\n",
      "Epoch 9/43\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 4.5834 - accuracy: 0.5227\n",
      "Epoch 10/43\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 4.5731 - accuracy: 0.5455\n",
      "Epoch 11/43\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 4.5670 - accuracy: 0.5227\n",
      "Epoch 12/43\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 4.5600 - accuracy: 0.5682\n",
      "Epoch 13/43\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 4.5587 - accuracy: 0.5682\n",
      "Epoch 14/43\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 4.5537 - accuracy: 0.5455\n",
      "Epoch 15/43\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 4.5406 - accuracy: 0.6364\n",
      "Epoch 16/43\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 4.5318 - accuracy: 0.6136\n",
      "Epoch 17/43\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 4.5314 - accuracy: 0.6591\n",
      "Epoch 18/43\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 4.5091 - accuracy: 0.6364\n",
      "Epoch 19/43\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 4.4831 - accuracy: 0.6364\n",
      "Epoch 20/43\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 4.4827 - accuracy: 0.6591\n",
      "Epoch 21/43\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 4.4744 - accuracy: 0.6591\n",
      "Epoch 22/43\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 4.4404 - accuracy: 0.6364\n",
      "Epoch 23/43\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 4.4209 - accuracy: 0.6364\n",
      "Epoch 24/43\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 4.3968 - accuracy: 0.6364\n",
      "Epoch 25/43\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 4.3851 - accuracy: 0.6364\n",
      "Epoch 26/43\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 4.1487 - accuracy: 0.6136\n",
      "Epoch 27/43\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 4.0934 - accuracy: 0.6136\n",
      "Epoch 28/43\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 4.0737 - accuracy: 0.6136\n",
      "Epoch 29/43\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 4.0750 - accuracy: 0.6136\n",
      "Epoch 30/43\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 4.0974 - accuracy: 0.6136\n",
      "Epoch 31/43\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 4.0791 - accuracy: 0.6136\n",
      "Epoch 32/43\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 4.1022 - accuracy: 0.6364\n",
      "Epoch 33/43\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 4.0714 - accuracy: 0.6364\n",
      "Epoch 34/43\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 4.0399 - accuracy: 0.6364\n",
      "Epoch 35/43\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 4.0347 - accuracy: 0.6591\n",
      "Epoch 36/43\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 4.0143 - accuracy: 0.6591\n",
      "Epoch 37/43\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 3.9960 - accuracy: 0.6591\n",
      "Epoch 38/43\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 3.9863 - accuracy: 0.6364\n",
      "Epoch 39/43\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 3.9666 - accuracy: 0.6364\n",
      "Epoch 40/43\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 3.9641 - accuracy: 0.6591\n",
      "Epoch 41/43\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 3.9453 - accuracy: 0.6818\n",
      "Epoch 42/43\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 3.9176 - accuracy: 0.6591\n",
      "Epoch 43/43\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 3.9174 - accuracy: 0.6591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c1d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.1772 - accuracy: 0.7727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:05:50,021]\u001b[0m Trial 92 finished with value: 0.7727272510528564 and parameters: {'embedding_output_dim': 240, 'num_epochs': 43}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/74\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.9452 - accuracy: 0.0227\n",
      "Epoch 2/74\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 5.7462 - accuracy: 0.4091\n",
      "Epoch 3/74\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 3.5768 - accuracy: 0.3409\n",
      "Epoch 4/74\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 2.7150 - accuracy: 0.3409\n",
      "Epoch 5/74\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 2.6522 - accuracy: 0.4091\n",
      "Epoch 6/74\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 2.6107 - accuracy: 0.5227\n",
      "Epoch 7/74\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 2.5631 - accuracy: 0.5682\n",
      "Epoch 8/74\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 2.5147 - accuracy: 0.5682\n",
      "Epoch 9/74\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 2.4646 - accuracy: 0.5909\n",
      "Epoch 10/74\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 2.4229 - accuracy: 0.5682\n",
      "Epoch 11/74\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 2.0604 - accuracy: 0.5682\n",
      "Epoch 12/74\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 2.2920 - accuracy: 0.6136\n",
      "Epoch 13/74\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 1.9854 - accuracy: 0.6364\n",
      "Epoch 14/74\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 1.9667 - accuracy: 0.6364\n",
      "Epoch 15/74\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.8975 - accuracy: 0.6364\n",
      "Epoch 16/74\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 1.9139 - accuracy: 0.6364\n",
      "Epoch 17/74\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.1824 - accuracy: 0.6364\n",
      "Epoch 18/74\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 2.1573 - accuracy: 0.6364\n",
      "Epoch 19/74\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.8296 - accuracy: 0.6364\n",
      "Epoch 20/74\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 1.8337 - accuracy: 0.6136\n",
      "Epoch 21/74\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.7950 - accuracy: 0.6364\n",
      "Epoch 22/74\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.7543 - accuracy: 0.6364\n",
      "Epoch 23/74\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.7348 - accuracy: 0.6364\n",
      "Epoch 24/74\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.6876 - accuracy: 0.6818\n",
      "Epoch 25/74\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.6876 - accuracy: 0.6591\n",
      "Epoch 26/74\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 1.6589 - accuracy: 0.6591\n",
      "Epoch 27/74\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 1.6328 - accuracy: 0.6591\n",
      "Epoch 28/74\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 1.6407 - accuracy: 0.6364\n",
      "Epoch 29/74\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 1.6097 - accuracy: 0.6591\n",
      "Epoch 30/74\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 1.5948 - accuracy: 0.7045\n",
      "Epoch 31/74\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.5927 - accuracy: 0.6591\n",
      "Epoch 32/74\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 1.5656 - accuracy: 0.6364\n",
      "Epoch 33/74\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 1.5700 - accuracy: 0.6818\n",
      "Epoch 34/74\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.5212 - accuracy: 0.7727\n",
      "Epoch 35/74\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 1.5392 - accuracy: 0.6818\n",
      "Epoch 36/74\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 1.5113 - accuracy: 0.7045\n",
      "Epoch 37/74\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.5171 - accuracy: 0.7045\n",
      "Epoch 38/74\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 1.4797 - accuracy: 0.7045\n",
      "Epoch 39/74\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.4531 - accuracy: 0.7273\n",
      "Epoch 40/74\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.4136 - accuracy: 0.7273\n",
      "Epoch 41/74\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 1.7731 - accuracy: 0.6818\n",
      "Epoch 42/74\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 2.4830 - accuracy: 0.6818\n",
      "Epoch 43/74\n",
      "1/1 [==============================] - 0s 294ms/step - loss: nan - accuracy: 0.6591\n",
      "Epoch 44/74\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/74\n",
      "1/1 [==============================] - 0s 357ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/74\n",
      "1/1 [==============================] - 0s 290ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/74\n",
      "1/1 [==============================] - 0s 349ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/74\n",
      "1/1 [==============================] - 0s 389ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/74\n",
      "1/1 [==============================] - 0s 329ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/74\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/74\n",
      "1/1 [==============================] - 0s 285ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/74\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/74\n",
      "1/1 [==============================] - 0s 427ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/74\n",
      "1/1 [==============================] - 0s 309ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/74\n",
      "1/1 [==============================] - 0s 325ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/74\n",
      "1/1 [==============================] - 0s 325ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/74\n",
      "1/1 [==============================] - 0s 304ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/74\n",
      "1/1 [==============================] - 0s 250ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/74\n",
      "1/1 [==============================] - 0s 296ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/74\n",
      "1/1 [==============================] - 0s 302ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/74\n",
      "1/1 [==============================] - 0s 246ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/74\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/74\n",
      "1/1 [==============================] - 0s 282ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 64/74\n",
      "1/1 [==============================] - 0s 276ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 65/74\n",
      "1/1 [==============================] - 0s 262ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 66/74\n",
      "1/1 [==============================] - 0s 428ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 67/74\n",
      "1/1 [==============================] - 0s 334ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 68/74\n",
      "1/1 [==============================] - 0s 282ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 69/74\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 70/74\n",
      "1/1 [==============================] - 0s 342ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 71/74\n",
      "1/1 [==============================] - 0s 319ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 72/74\n",
      "1/1 [==============================] - 0s 354ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 73/74\n",
      "1/1 [==============================] - 0s 379ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 74/74\n",
      "1/1 [==============================] - 0s 354ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c1481f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:06:24,521]\u001b[0m Trial 93 finished with value: 0.5 and parameters: {'embedding_output_dim': 216, 'num_epochs': 74}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/52\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.6470 - accuracy: 0.1136\n",
      "Epoch 2/52\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 6.4194 - accuracy: 0.2045\n",
      "Epoch 3/52\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 3.7301 - accuracy: 0.1818\n",
      "Epoch 4/52\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 3.4969 - accuracy: 0.1818\n",
      "Epoch 5/52\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 3.4341 - accuracy: 0.2955\n",
      "Epoch 6/52\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 3.1138 - accuracy: 0.3182\n",
      "Epoch 7/52\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 3.1110 - accuracy: 0.3636\n",
      "Epoch 8/52\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.0503 - accuracy: 0.4091\n",
      "Epoch 9/52\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.7551 - accuracy: 0.5000\n",
      "Epoch 10/52\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.7102 - accuracy: 0.4318\n",
      "Epoch 11/52\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 2.6949 - accuracy: 0.4545\n",
      "Epoch 12/52\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.6680 - accuracy: 0.4773\n",
      "Epoch 13/52\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.6343 - accuracy: 0.4545\n",
      "Epoch 14/52\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.6440 - accuracy: 0.4545\n",
      "Epoch 15/52\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.6028 - accuracy: 0.4545\n",
      "Epoch 16/52\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.6136 - accuracy: 0.4545\n",
      "Epoch 17/52\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.5895 - accuracy: 0.4773\n",
      "Epoch 18/52\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.5621 - accuracy: 0.4773\n",
      "Epoch 19/52\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 2.5739 - accuracy: 0.4091\n",
      "Epoch 20/52\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.5364 - accuracy: 0.4545\n",
      "Epoch 21/52\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.5332 - accuracy: 0.5000\n",
      "Epoch 22/52\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.5141 - accuracy: 0.4545\n",
      "Epoch 23/52\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 2.5132 - accuracy: 0.4545\n",
      "Epoch 24/52\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.4626 - accuracy: 0.5000\n",
      "Epoch 25/52\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 2.4615 - accuracy: 0.4545\n",
      "Epoch 26/52\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.4120 - accuracy: 0.4545\n",
      "Epoch 27/52\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 2.4175 - accuracy: 0.4545\n",
      "Epoch 28/52\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 2.4272 - accuracy: 0.4318\n",
      "Epoch 29/52\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.3941 - accuracy: 0.4773\n",
      "Epoch 30/52\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.3725 - accuracy: 0.4773\n",
      "Epoch 31/52\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.3724 - accuracy: 0.4773\n",
      "Epoch 32/52\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.3421 - accuracy: 0.5000\n",
      "Epoch 33/52\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.3377 - accuracy: 0.4318\n",
      "Epoch 34/52\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.3377 - accuracy: 0.4773\n",
      "Epoch 35/52\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 2.3057 - accuracy: 0.4773\n",
      "Epoch 36/52\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.3039 - accuracy: 0.4545\n",
      "Epoch 37/52\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 2.2985 - accuracy: 0.5000\n",
      "Epoch 38/52\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.2810 - accuracy: 0.5000\n",
      "Epoch 39/52\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.2886 - accuracy: 0.5227\n",
      "Epoch 40/52\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.3085 - accuracy: 0.4773\n",
      "Epoch 41/52\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.2806 - accuracy: 0.4773\n",
      "Epoch 42/52\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 2.2714 - accuracy: 0.4773\n",
      "Epoch 43/52\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 2.2378 - accuracy: 0.5000\n",
      "Epoch 44/52\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 2.2426 - accuracy: 0.5000\n",
      "Epoch 45/52\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 2.2343 - accuracy: 0.5455\n",
      "Epoch 46/52\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.2235 - accuracy: 0.5455\n",
      "Epoch 47/52\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.2214 - accuracy: 0.5455\n",
      "Epoch 48/52\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.2108 - accuracy: 0.5455\n",
      "Epoch 49/52\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.9471 - accuracy: 0.5227\n",
      "Epoch 50/52\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.2112 - accuracy: 0.5227\n",
      "Epoch 51/52\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.2027 - accuracy: 0.5682\n",
      "Epoch 52/52\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.9247 - accuracy: 0.5682\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff52c3f7d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.9946 - accuracy: 0.5909\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:06:48,175]\u001b[0m Trial 94 finished with value: 0.5909090638160706 and parameters: {'embedding_output_dim': 190, 'num_epochs': 52}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/67\n",
      "1/1 [==============================] - 9s 9s/step - loss: 11.8219 - accuracy: 0.0227\n",
      "Epoch 2/67\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.8263 - accuracy: 0.2500\n",
      "Epoch 3/67\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.9279 - accuracy: 0.3636\n",
      "Epoch 4/67\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 4.4704 - accuracy: 0.4091\n",
      "Epoch 5/67\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 3.9234 - accuracy: 0.5227\n",
      "Epoch 6/67\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.8102 - accuracy: 0.5909\n",
      "Epoch 7/67\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 3.9541 - accuracy: 0.5227\n",
      "Epoch 8/67\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 3.2545 - accuracy: 0.5227\n",
      "Epoch 9/67\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 3.5137 - accuracy: 0.5455\n",
      "Epoch 10/67\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 3.2184 - accuracy: 0.5455\n",
      "Epoch 11/67\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 3.5948 - accuracy: 0.5000\n",
      "Epoch 12/67\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 3.2913 - accuracy: 0.4545\n",
      "Epoch 13/67\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.1214 - accuracy: 0.5909\n",
      "Epoch 14/67\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.9626 - accuracy: 0.5455\n",
      "Epoch 15/67\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.6666 - accuracy: 0.5682\n",
      "Epoch 16/67\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.7058 - accuracy: 0.6136\n",
      "Epoch 17/67\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.1324 - accuracy: 0.6136\n",
      "Epoch 18/67\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.0639 - accuracy: 0.5682\n",
      "Epoch 19/67\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.0838 - accuracy: 0.5455\n",
      "Epoch 20/67\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.0980 - accuracy: 0.6136\n",
      "Epoch 21/67\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0303 - accuracy: 0.6591\n",
      "Epoch 22/67\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.0430 - accuracy: 0.5909\n",
      "Epoch 23/67\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.0047 - accuracy: 0.6818\n",
      "Epoch 24/67\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.0041 - accuracy: 0.5682\n",
      "Epoch 25/67\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.9860 - accuracy: 0.5909\n",
      "Epoch 26/67\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 1.9853 - accuracy: 0.6364\n",
      "Epoch 27/67\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 1.9928 - accuracy: 0.5909\n",
      "Epoch 28/67\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.9297 - accuracy: 0.6364\n",
      "Epoch 29/67\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.9527 - accuracy: 0.6136\n",
      "Epoch 30/67\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.9380 - accuracy: 0.6591\n",
      "Epoch 31/67\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.8802 - accuracy: 0.6591\n",
      "Epoch 32/67\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 1.9015 - accuracy: 0.6136\n",
      "Epoch 33/67\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.8635 - accuracy: 0.6136\n",
      "Epoch 34/67\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.7966 - accuracy: 0.6364\n",
      "Epoch 35/67\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.8541 - accuracy: 0.5909\n",
      "Epoch 36/67\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.7966 - accuracy: 0.6364\n",
      "Epoch 37/67\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.7592 - accuracy: 0.6136\n",
      "Epoch 38/67\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.8227 - accuracy: 0.6136\n",
      "Epoch 39/67\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.7640 - accuracy: 0.6136\n",
      "Epoch 40/67\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.7602 - accuracy: 0.5909\n",
      "Epoch 41/67\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.7626 - accuracy: 0.6591\n",
      "Epoch 42/67\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.6558 - accuracy: 0.6364\n",
      "Epoch 43/67\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.7967 - accuracy: 0.6364\n",
      "Epoch 44/67\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.7028 - accuracy: 0.6136\n",
      "Epoch 45/67\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.6553 - accuracy: 0.6136\n",
      "Epoch 46/67\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.6684 - accuracy: 0.6591\n",
      "Epoch 47/67\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.6880 - accuracy: 0.6364\n",
      "Epoch 48/67\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.6852 - accuracy: 0.6364\n",
      "Epoch 49/67\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.6564 - accuracy: 0.6591\n",
      "Epoch 50/67\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.6590 - accuracy: 0.6136\n",
      "Epoch 51/67\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.6749 - accuracy: 0.6364\n",
      "Epoch 52/67\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.5936 - accuracy: 0.6136\n",
      "Epoch 53/67\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.6287 - accuracy: 0.6591\n",
      "Epoch 54/67\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.6743 - accuracy: 0.6591\n",
      "Epoch 55/67\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.5700 - accuracy: 0.6591\n",
      "Epoch 56/67\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.6195 - accuracy: 0.6591\n",
      "Epoch 57/67\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.6129 - accuracy: 0.5909\n",
      "Epoch 58/67\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6070 - accuracy: 0.6136\n",
      "Epoch 59/67\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.5570 - accuracy: 0.6591\n",
      "Epoch 60/67\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.5628 - accuracy: 0.6364\n",
      "Epoch 61/67\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.5204 - accuracy: 0.6364\n",
      "Epoch 62/67\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.5792 - accuracy: 0.6364\n",
      "Epoch 63/67\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5207 - accuracy: 0.6364\n",
      "Epoch 64/67\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8486 - accuracy: 0.6591\n",
      "Epoch 65/67\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.4848 - accuracy: 0.6364\n",
      "Epoch 66/67\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.5223 - accuracy: 0.6591\n",
      "Epoch 67/67\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.8155 - accuracy: 0.6364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff54015e8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.3510 - accuracy: 0.7273\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:07:09,696]\u001b[0m Trial 95 finished with value: 0.7272727489471436 and parameters: {'embedding_output_dim': 42, 'num_epochs': 67}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/63\n",
      "1/1 [==============================] - 9s 9s/step - loss: nan - accuracy: 0.1136\n",
      "Epoch 2/63\n",
      "1/1 [==============================] - 0s 109ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 3/63\n",
      "1/1 [==============================] - 0s 131ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 4/63\n",
      "1/1 [==============================] - 0s 145ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 5/63\n",
      "1/1 [==============================] - 0s 150ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 6/63\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 7/63\n",
      "1/1 [==============================] - 0s 206ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 8/63\n",
      "1/1 [==============================] - 0s 138ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 9/63\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 10/63\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 11/63\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 12/63\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 13/63\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 14/63\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 15/63\n",
      "1/1 [==============================] - 0s 163ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 16/63\n",
      "1/1 [==============================] - 0s 166ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 17/63\n",
      "1/1 [==============================] - 0s 152ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 18/63\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 19/63\n",
      "1/1 [==============================] - 0s 153ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 20/63\n",
      "1/1 [==============================] - 0s 166ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 21/63\n",
      "1/1 [==============================] - 0s 143ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 22/63\n",
      "1/1 [==============================] - 0s 158ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 23/63\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 24/63\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 25/63\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 26/63\n",
      "1/1 [==============================] - 0s 161ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 27/63\n",
      "1/1 [==============================] - 0s 179ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 28/63\n",
      "1/1 [==============================] - 0s 177ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 29/63\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 30/63\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 31/63\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 32/63\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 33/63\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 34/63\n",
      "1/1 [==============================] - 0s 140ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 35/63\n",
      "1/1 [==============================] - 0s 173ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 36/63\n",
      "1/1 [==============================] - 0s 251ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 37/63\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 38/63\n",
      "1/1 [==============================] - 0s 125ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 39/63\n",
      "1/1 [==============================] - 0s 146ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 40/63\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 41/63\n",
      "1/1 [==============================] - 0s 150ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 42/63\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 43/63\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 44/63\n",
      "1/1 [==============================] - 0s 139ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 45/63\n",
      "1/1 [==============================] - 0s 195ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 46/63\n",
      "1/1 [==============================] - 0s 212ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 47/63\n",
      "1/1 [==============================] - 0s 127ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 48/63\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 49/63\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 50/63\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 51/63\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 52/63\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 53/63\n",
      "1/1 [==============================] - 0s 147ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 54/63\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 55/63\n",
      "1/1 [==============================] - 0s 165ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 56/63\n",
      "1/1 [==============================] - 0s 188ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 57/63\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 58/63\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 59/63\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 60/63\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 61/63\n",
      "1/1 [==============================] - 0s 143ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 62/63\n",
      "1/1 [==============================] - 0s 162ms/step - loss: nan - accuracy: 0.2727\n",
      "Epoch 63/63\n",
      "1/1 [==============================] - 0s 152ms/step - loss: nan - accuracy: 0.2727\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff560c038b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:07:30,635]\u001b[0m Trial 96 finished with value: 0.5 and parameters: {'embedding_output_dim': 65, 'num_epochs': 63}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/71\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.8640 - accuracy: 0.0909\n",
      "Epoch 2/71\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 4.3744 - accuracy: 0.4318\n",
      "Epoch 3/71\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 3.3554 - accuracy: 0.6136\n",
      "Epoch 4/71\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.9087 - accuracy: 0.5909\n",
      "Epoch 5/71\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.9604 - accuracy: 0.5682\n",
      "Epoch 6/71\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.6280 - accuracy: 0.6364\n",
      "Epoch 7/71\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.6883 - accuracy: 0.4318\n",
      "Epoch 8/71\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.8040 - accuracy: 0.4091\n",
      "Epoch 9/71\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.7772 - accuracy: 0.4091\n",
      "Epoch 10/71\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.7498 - accuracy: 0.3636\n",
      "Epoch 11/71\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.7497 - accuracy: 0.2727\n",
      "Epoch 12/71\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.7840 - accuracy: 0.3182\n",
      "Epoch 13/71\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.7047 - accuracy: 0.3864\n",
      "Epoch 14/71\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.7516 - accuracy: 0.3182\n",
      "Epoch 15/71\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.8003 - accuracy: 0.3182\n",
      "Epoch 16/71\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.7974 - accuracy: 0.3409\n",
      "Epoch 17/71\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.8210 - accuracy: 0.3864\n",
      "Epoch 18/71\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.7022 - accuracy: 0.3636\n",
      "Epoch 19/71\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.7309 - accuracy: 0.3182\n",
      "Epoch 20/71\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.7472 - accuracy: 0.2955\n",
      "Epoch 21/71\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.7331 - accuracy: 0.2727\n",
      "Epoch 22/71\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.7341 - accuracy: 0.3636\n",
      "Epoch 23/71\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.7187 - accuracy: 0.3182\n",
      "Epoch 24/71\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.7280 - accuracy: 0.3409\n",
      "Epoch 25/71\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.6674 - accuracy: 0.3409\n",
      "Epoch 26/71\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.6651 - accuracy: 0.3409\n",
      "Epoch 27/71\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.6864 - accuracy: 0.3409\n",
      "Epoch 28/71\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.6578 - accuracy: 0.3636\n",
      "Epoch 29/71\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.5933 - accuracy: 0.3864\n",
      "Epoch 30/71\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.6863 - accuracy: 0.2955\n",
      "Epoch 31/71\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.6450 - accuracy: 0.3636\n",
      "Epoch 32/71\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.6238 - accuracy: 0.3409\n",
      "Epoch 33/71\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.6210 - accuracy: 0.4091\n",
      "Epoch 34/71\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.6097 - accuracy: 0.4545\n",
      "Epoch 35/71\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.6150 - accuracy: 0.4545\n",
      "Epoch 36/71\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.6059 - accuracy: 0.3864\n",
      "Epoch 37/71\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.6136 - accuracy: 0.4091\n",
      "Epoch 38/71\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.6185 - accuracy: 0.4091\n",
      "Epoch 39/71\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.5793 - accuracy: 0.4318\n",
      "Epoch 40/71\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.5548 - accuracy: 0.4091\n",
      "Epoch 41/71\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.5375 - accuracy: 0.3864\n",
      "Epoch 42/71\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.5459 - accuracy: 0.4318\n",
      "Epoch 43/71\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.5608 - accuracy: 0.3864\n",
      "Epoch 44/71\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.5271 - accuracy: 0.4773\n",
      "Epoch 45/71\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.4847 - accuracy: 0.4773\n",
      "Epoch 46/71\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.5182 - accuracy: 0.4318\n",
      "Epoch 47/71\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.4837 - accuracy: 0.4545\n",
      "Epoch 48/71\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.4683 - accuracy: 0.5000\n",
      "Epoch 49/71\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.5137 - accuracy: 0.4773\n",
      "Epoch 50/71\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.4973 - accuracy: 0.5000\n",
      "Epoch 51/71\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2.4441 - accuracy: 0.4773\n",
      "Epoch 52/71\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2.4855 - accuracy: 0.4318\n",
      "Epoch 53/71\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.4344 - accuracy: 0.5000\n",
      "Epoch 54/71\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.4238 - accuracy: 0.4773\n",
      "Epoch 55/71\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.4650 - accuracy: 0.4773\n",
      "Epoch 56/71\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.4683 - accuracy: 0.4545\n",
      "Epoch 57/71\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 2.4174 - accuracy: 0.5227\n",
      "Epoch 58/71\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.4074 - accuracy: 0.6136\n",
      "Epoch 59/71\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.4075 - accuracy: 0.5455\n",
      "Epoch 60/71\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 2.3945 - accuracy: 0.5455\n",
      "Epoch 61/71\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.3519 - accuracy: 0.5909\n",
      "Epoch 62/71\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 2.3627 - accuracy: 0.5682\n",
      "Epoch 63/71\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.3570 - accuracy: 0.5455\n",
      "Epoch 64/71\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.3616 - accuracy: 0.5909\n",
      "Epoch 65/71\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.3353 - accuracy: 0.6591\n",
      "Epoch 66/71\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.3444 - accuracy: 0.5227\n",
      "Epoch 67/71\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.3449 - accuracy: 0.5455\n",
      "Epoch 68/71\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.2849 - accuracy: 0.6136\n",
      "Epoch 69/71\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.3021 - accuracy: 0.5909\n",
      "Epoch 70/71\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.2985 - accuracy: 0.6136\n",
      "Epoch 71/71\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.2856 - accuracy: 0.6136\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5610e04c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5048 - accuracy: 0.6818\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:07:52,971]\u001b[0m Trial 97 finished with value: 0.6818181872367859 and parameters: {'embedding_output_dim': 52, 'num_epochs': 71}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/34\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.9263 - accuracy: 0.2500\n",
      "Epoch 2/34\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.7702 - accuracy: 0.4773\n",
      "Epoch 3/34\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.3640 - accuracy: 0.4545\n",
      "Epoch 4/34\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.5581 - accuracy: 0.4545\n",
      "Epoch 5/34\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.1575 - accuracy: 0.4545\n",
      "Epoch 6/34\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.5806 - accuracy: 0.4318\n",
      "Epoch 7/34\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.9269 - accuracy: 0.4318\n",
      "Epoch 8/34\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.9013 - accuracy: 0.4545\n",
      "Epoch 9/34\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.0370 - accuracy: 0.3636\n",
      "Epoch 10/34\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.9572 - accuracy: 0.3409\n",
      "Epoch 11/34\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0472 - accuracy: 0.3409\n",
      "Epoch 12/34\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.9833 - accuracy: 0.3182\n",
      "Epoch 13/34\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.9792 - accuracy: 0.2955\n",
      "Epoch 14/34\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0031 - accuracy: 0.2500\n",
      "Epoch 15/34\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.9733 - accuracy: 0.2500\n",
      "Epoch 16/34\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 2.0026 - accuracy: 0.1591\n",
      "Epoch 17/34\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.9298 - accuracy: 0.2045\n",
      "Epoch 18/34\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.0048 - accuracy: 0.1591\n",
      "Epoch 19/34\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.9935 - accuracy: 0.0455\n",
      "Epoch 20/34\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.9401 - accuracy: 0.0909\n",
      "Epoch 21/34\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.9232 - accuracy: 0.1364\n",
      "Epoch 22/34\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.9362 - accuracy: 0.0909\n",
      "Epoch 23/34\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.8855 - accuracy: 0.1591\n",
      "Epoch 24/34\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.9020 - accuracy: 0.0909\n",
      "Epoch 25/34\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.8915 - accuracy: 0.0455\n",
      "Epoch 26/34\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.9006 - accuracy: 0.0455\n",
      "Epoch 27/34\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.8801 - accuracy: 0.2273\n",
      "Epoch 28/34\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.8591 - accuracy: 0.1136\n",
      "Epoch 29/34\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.8655 - accuracy: 0.1591\n",
      "Epoch 30/34\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.8509 - accuracy: 0.2045\n",
      "Epoch 31/34\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.8777 - accuracy: 0.1591\n",
      "Epoch 32/34\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.8267 - accuracy: 0.2045\n",
      "Epoch 33/34\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.9003 - accuracy: 0.2045\n",
      "Epoch 34/34\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.8488 - accuracy: 0.2045\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff578c03f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.8297 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:08:10,808]\u001b[0m Trial 98 finished with value: 0.0 and parameters: {'embedding_output_dim': 136, 'num_epochs': 34}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/55\n",
      "1/1 [==============================] - 9s 9s/step - loss: 8.3565 - accuracy: 0.0227\n",
      "Epoch 2/55\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 3.3699 - accuracy: 0.5227\n",
      "Epoch 3/55\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.6923 - accuracy: 0.5000\n",
      "Epoch 4/55\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.4881 - accuracy: 0.5909\n",
      "Epoch 5/55\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.5123 - accuracy: 0.5227\n",
      "Epoch 6/55\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.4663 - accuracy: 0.5909\n",
      "Epoch 7/55\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.4477 - accuracy: 0.5455\n",
      "Epoch 8/55\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.4059 - accuracy: 0.5909\n",
      "Epoch 9/55\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2.3652 - accuracy: 0.5909\n",
      "Epoch 10/55\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.3351 - accuracy: 0.6364\n",
      "Epoch 11/55\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.3092 - accuracy: 0.5909\n",
      "Epoch 12/55\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.2983 - accuracy: 0.6364\n",
      "Epoch 13/55\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.2744 - accuracy: 0.6364\n",
      "Epoch 14/55\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.2695 - accuracy: 0.6136\n",
      "Epoch 15/55\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.2706 - accuracy: 0.6136\n",
      "Epoch 16/55\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.2154 - accuracy: 0.6136\n",
      "Epoch 17/55\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.1840 - accuracy: 0.6591\n",
      "Epoch 18/55\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.1957 - accuracy: 0.6364\n",
      "Epoch 19/55\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.2178 - accuracy: 0.6364\n",
      "Epoch 20/55\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 2.1559 - accuracy: 0.6136\n",
      "Epoch 21/55\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.1688 - accuracy: 0.6136\n",
      "Epoch 22/55\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.1456 - accuracy: 0.6591\n",
      "Epoch 23/55\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.1360 - accuracy: 0.6136\n",
      "Epoch 24/55\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.1456 - accuracy: 0.6364\n",
      "Epoch 25/55\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.1182 - accuracy: 0.6364\n",
      "Epoch 26/55\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.1118 - accuracy: 0.6364\n",
      "Epoch 27/55\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.1368 - accuracy: 0.6364\n",
      "Epoch 28/55\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.0901 - accuracy: 0.6364\n",
      "Epoch 29/55\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.0947 - accuracy: 0.6364\n",
      "Epoch 30/55\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.0343 - accuracy: 0.6591\n",
      "Epoch 31/55\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.0302 - accuracy: 0.6136\n",
      "Epoch 32/55\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 2.0532 - accuracy: 0.6364\n",
      "Epoch 33/55\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0027 - accuracy: 0.6364\n",
      "Epoch 34/55\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0037 - accuracy: 0.6136\n",
      "Epoch 35/55\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0084 - accuracy: 0.6364\n",
      "Epoch 36/55\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.9933 - accuracy: 0.6136\n",
      "Epoch 37/55\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.9839 - accuracy: 0.6364\n",
      "Epoch 38/55\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.9664 - accuracy: 0.6364\n",
      "Epoch 39/55\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.9740 - accuracy: 0.6364\n",
      "Epoch 40/55\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.9431 - accuracy: 0.6364\n",
      "Epoch 41/55\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.9524 - accuracy: 0.6364\n",
      "Epoch 42/55\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.9392 - accuracy: 0.6818\n",
      "Epoch 43/55\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.9247 - accuracy: 0.6591\n",
      "Epoch 44/55\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.9140 - accuracy: 0.6364\n",
      "Epoch 45/55\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.8974 - accuracy: 0.6591\n",
      "Epoch 46/55\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.8822 - accuracy: 0.6818\n",
      "Epoch 47/55\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.8738 - accuracy: 0.6591\n",
      "Epoch 48/55\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.8653 - accuracy: 0.6818\n",
      "Epoch 49/55\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1.8950 - accuracy: 0.6818\n",
      "Epoch 50/55\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.8932 - accuracy: 0.6591\n",
      "Epoch 51/55\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.8613 - accuracy: 0.6818\n",
      "Epoch 52/55\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.8464 - accuracy: 0.6591\n",
      "Epoch 53/55\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.8613 - accuracy: 0.6364\n",
      "Epoch 54/55\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.8222 - accuracy: 0.7045\n",
      "Epoch 55/55\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - accuracy: 0.6591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5402aadc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-08-01 21:08:30,098]\u001b[0m Trial 99 finished with value: 0.5 and parameters: {'embedding_output_dim': 83, 'num_epochs': 55}. Best is trial 2 with value: 0.8181818127632141.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t = 'Como conseguir dinheiro'.split(' ')\n",
    "t2 = [word2idx[word] for word in t]\n",
    "t3 = model.predict(t2)\n",
    "[idx2tag[np.argmax(cat)] for cat in t3]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "interpreter": {
   "hash": "11952d6ef341716fa9615f45cd192d3e9c3fce0851a7ac02304594f37d763982"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}